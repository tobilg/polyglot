{
  "dialect": "redshift",
  "identity": [
    {
      "sql": "SELECT COSH(1.5)",
      "expected": null
    },
    {
      "sql": "ROUND(CAST(a AS DOUBLE PRECISION) / CAST(b AS DOUBLE PRECISION), 2)",
      "expected": null
    },
    {
      "sql": "DATEDIFF(days, a, b)",
      "expected": "DATEDIFF(DAY, a, b)"
    },
    {
      "sql": "SELECT GETBIT(FROM_HEX('4d'), 2)",
      "expected": null
    },
    {
      "sql": "SELECT EXP(1)",
      "expected": null
    },
    {
      "sql": "ALTER TABLE table_name ALTER COLUMN bla TYPE VARCHAR",
      "expected": null
    },
    {
      "sql": "SELECT CAST(value AS FLOAT(8))",
      "expected": null
    },
    {
      "sql": "1 div",
      "expected": "1 AS div"
    },
    {
      "sql": "LISTAGG(DISTINCT foo, ', ')",
      "expected": null
    },
    {
      "sql": "CREATE MATERIALIZED VIEW orders AUTO REFRESH YES AS SELECT 1",
      "expected": null
    },
    {
      "sql": "SELECT DATEADD(DAY, 1, 'today')",
      "expected": null
    },
    {
      "sql": "SELECT * FROM #x",
      "expected": null
    },
    {
      "sql": "SELECT INTERVAL '5 DAY'",
      "expected": null
    },
    {
      "sql": "foo$",
      "expected": null
    },
    {
      "sql": "CAST('bla' AS SUPER)",
      "expected": null
    },
    {
      "sql": "CREATE TABLE real1 (realcol REAL)",
      "expected": null
    },
    {
      "sql": "CAST('foo' AS HLLSKETCH)",
      "expected": null
    },
    {
      "sql": "'abc' SIMILAR TO '(b|c)%'",
      "expected": null
    },
    {
      "sql": "CREATE TABLE datetable (start_date DATE, end_date DATE)",
      "expected": null
    },
    {
      "sql": "SELECT APPROXIMATE AS y",
      "expected": null
    },
    {
      "sql": "CREATE TABLE t (c BIGINT IDENTITY(0, 1))",
      "expected": null
    },
    {
      "sql": "COPY test_staging_tbl FROM 's3://your/bucket/prefix/here' IAM_ROLE default FORMAT AS AVRO 'auto'",
      "expected": null
    },
    {
      "sql": "COPY test_staging_tbl FROM 's3://your/bucket/prefix/here' IAM_ROLE default FORMAT AS JSON 's3://jsonpaths_file'",
      "expected": null
    },
    {
      "sql": "SELECT * FROM venue WHERE (venuecity, venuestate) IN (('Miami', 'FL'), ('Tampa', 'FL')) ORDER BY venueid",
      "expected": null
    },
    {
      "sql": "SELECT tablename, \"column\" FROM pg_table_def WHERE \"column\" LIKE '%start\\\\_%' LIMIT 5",
      "expected": null
    },
    {
      "sql": "SELECT JSON_EXTRACT_PATH_TEXT('{\"f2\":{\"f3\":1},\"f4\":{\"f5\":99,\"f6\":\"star\"}', 'f4', 'f6', TRUE)",
      "expected": null
    },
    {
      "sql": "SELECT CONCAT('abc', 'def')",
      "expected": "SELECT 'abc' || 'def'"
    },
    {
      "sql": "SELECT CONCAT_WS('DELIM', 'abc', 'def', 'ghi')",
      "expected": "SELECT 'abc' || 'DELIM' || 'def' || 'DELIM' || 'ghi'"
    },
    {
      "sql": "SELECT TOP 1 x FROM y",
      "expected": "SELECT x FROM y LIMIT 1"
    },
    {
      "sql": "SELECT DATE_DIFF('month', CAST('2020-02-29 00:00:00' AS TIMESTAMP), CAST('2020-03-02 00:00:00' AS TIMESTAMP))",
      "expected": "SELECT DATEDIFF(MONTH, CAST('2020-02-29 00:00:00' AS TIMESTAMP), CAST('2020-03-02 00:00:00' AS TIMESTAMP))"
    },
    {
      "sql": "SELECT * FROM x WHERE y = DATEADD('month', -1, DATE_TRUNC('month', (SELECT y FROM #temp_table)))",
      "expected": "SELECT * FROM x WHERE y = DATEADD(MONTH, -1, DATE_TRUNC('MONTH', (SELECT y FROM #temp_table)))"
    },
    {
      "sql": "SELECT 'a''b'",
      "expected": "SELECT 'a\\'b'"
    },
    {
      "sql": "CREATE TABLE t (c BIGINT GENERATED BY DEFAULT AS IDENTITY (0, 1))",
      "expected": "CREATE TABLE t (c BIGINT IDENTITY(0, 1))"
    },
    {
      "sql": "SELECT DATEADD(HOUR, 0, CAST('2020-02-02 01:03:05.124' AS TIMESTAMP))",
      "expected": null
    },
    {
      "sql": "SELECT DATEDIFF(SECOND, '2020-02-02 00:00:00.000', '2020-02-02 01:03:05.124')",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE VIEW v1 AS SELECT id, AVG(average_metric1) AS m1, AVG(average_metric2) AS m2 FROM t GROUP BY id WITH NO SCHEMA BINDING",
      "expected": null
    },
    {
      "sql": "SELECT caldate + INTERVAL '1 SECOND' AS dateplus FROM date WHERE caldate = '12-31-2008'",
      "expected": null
    },
    {
      "sql": "SELECT COUNT(*) FROM event WHERE eventname LIKE '%Ring%' OR eventname LIKE '%Die%'",
      "expected": null
    },
    {
      "sql": "CREATE TABLE SOUP (LIKE other_table) DISTKEY(soup1) SORTKEY(soup2) DISTSTYLE ALL",
      "expected": null
    },
    {
      "sql": "CREATE TABLE sales (salesid INTEGER NOT NULL) DISTKEY(listid) COMPOUND SORTKEY(listid, sellerid) DISTSTYLE AUTO",
      "expected": null
    },
    {
      "sql": "COPY customer FROM 's3://mybucket/customer' IAM_ROLE 'arn:aws:iam::0123456789012:role/MyRedshiftRole' REGION 'us-east-1' FORMAT orc",
      "expected": null
    },
    {
      "sql": "COPY customer FROM 's3://mybucket/mydata' CREDENTIALS 'aws_iam_role=arn:aws:iam::<aws-account-id>:role/<role-name>;master_symmetric_key=<root-key>' emptyasnull blanksasnull timeformat 'YYYY-MM-DD HH:MI:SS'",
      "expected": null
    },
    {
      "sql": "UNLOAD ('select * from venue') TO 's3://mybucket/unload/' IAM_ROLE 'arn:aws:iam::0123456789012:role/MyRedshiftRole'",
      "expected": null
    },
    {
      "sql": "CREATE TABLE SOUP (SOUP1 VARCHAR(50) NOT NULL ENCODE ZSTD, SOUP2 VARCHAR(70) NULL ENCODE DELTA)",
      "expected": null
    },
    {
      "sql": "SELECT DATEADD('day', ndays, caldate)",
      "expected": "SELECT DATEADD(DAY, ndays, caldate)"
    },
    {
      "sql": "CONVERT(INT, x)",
      "expected": "CAST(x AS INTEGER)"
    },
    {
      "sql": "SELECT DATE_ADD('day', 1, DATE('2023-01-01'))",
      "expected": "SELECT DATEADD(DAY, 1, DATE('2023-01-01'))"
    },
    {
      "sql": "SELECT\n  c_name,\n  orders.o_orderkey AS orderkey,\n  index AS orderkey_index\nFROM customer_orders_lineitem AS c, c.c_orders AS orders AT index\nORDER BY\n  orderkey_index",
      "expected": null
    },
    {
      "sql": "SELECT attr AS attr, JSON_TYPEOF(val) AS value_type FROM customer_orders_lineitem AS c, UNPIVOT c.c_orders[0] WHERE c_custkey = 9451",
      "expected": null
    },
    {
      "sql": "SELECT attr AS attr, JSON_TYPEOF(val) AS value_type FROM customer_orders_lineitem AS c, UNPIVOT c.c_orders AS val AT attr WHERE c_custkey = 9451",
      "expected": null
    },
    {
      "sql": "SELECT JSON_PARSE('[]')",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY(1, 2, 3)",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY[1, 2, 3]",
      "expected": null
    },
    {
      "sql": "SELECT CONVERT_TIMEZONE('America/New_York', '2024-08-06 09:10:00.000')",
      "expected": "SELECT CONVERT_TIMEZONE('UTC', 'America/New_York', '2024-08-06 09:10:00.000')"
    },
    {
      "sql": "INSERT INTO t (a) VALUES (1), (2), (3)",
      "expected": null
    },
    {
      "sql": "INSERT INTO t (a, b) VALUES (1, 2), (3, 4)",
      "expected": null
    },
    {
      "sql": "CREATE TABLE table_backup BACKUP NO AS SELECT * FROM event",
      "expected": null
    },
    {
      "sql": "CREATE TABLE table_backup BACKUP YES AS SELECT * FROM event",
      "expected": null
    },
    {
      "sql": "CREATE TABLE table_backup (i INTEGER, b VARCHAR) BACKUP NO",
      "expected": null
    },
    {
      "sql": "CREATE TABLE table_backup (i INTEGER, b VARCHAR) BACKUP YES",
      "expected": null
    },
    {
      "sql": "select foo, bar from table_1 minus select foo, bar from table_2",
      "expected": "SELECT foo, bar FROM table_1 EXCEPT SELECT foo, bar FROM table_2"
    },
    {
      "sql": "CREATE TABLE SOUP (LIKE other_table) DISTKEY(soup1) SORTKEY(soup2) DISTSTYLE ALL",
      "expected": null
    },
    {
      "sql": "ALTER TABLE s.t ALTER SORTKEY (c)",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER SORTKEY AUTO",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER SORTKEY NONE",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER SORTKEY (c1, c2)",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER SORTKEY (c1, c2)",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER COMPOUND SORTKEY (c1, c2)",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER DISTSTYLE ALL",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER DISTSTYLE EVEN",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER DISTSTYLE AUTO",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER DISTSTYLE KEY DISTKEY c",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t SET TABLE PROPERTIES ('a' = '5', 'b' = 'c')",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t SET LOCATION 's3://bucket/folder/'",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t SET FILE FORMAT AVRO",
      "expected": null
    },
    {
      "sql": "ALTER TABLE t ALTER DISTKEY c",
      "expected": "ALTER TABLE t ALTER DISTSTYLE KEY DISTKEY c"
    },
    {
      "sql": "SELECT c.*, o FROM bloo AS c, c.c_orders AS o",
      "expected": null
    },
    {
      "sql": "SELECT c.*, o, l FROM bloo AS c, c.c_orders AS o, o.o_lineitems AS l",
      "expected": null
    },
    {
      "sql": "select a.foo, b.bar, a.baz from a, b where a.baz = b.baz (+)",
      "expected": "SELECT a.foo, b.bar, a.baz FROM a, b WHERE a.baz = b.baz (+)"
    },
    {
      "sql": "GRANT SELECT ON TABLE sales TO fred",
      "expected": null
    },
    {
      "sql": "GRANT ALL ON SCHEMA qa_tickit TO GROUP qa_users",
      "expected": null
    },
    {
      "sql": "GRANT ALL ON TABLE qa_tickit.sales TO GROUP qa_users",
      "expected": null
    },
    {
      "sql": "GRANT ALL ON TABLE qa_tickit.sales TO GROUP qa_users, GROUP ro_users",
      "expected": null
    },
    {
      "sql": "GRANT ALL ON view_date TO view_user",
      "expected": null
    },
    {
      "sql": "GRANT SELECT(cust_name, cust_phone), UPDATE(cust_contact_preference) ON cust_profile TO GROUP sales_group",
      "expected": null
    },
    {
      "sql": "GRANT ALL(cust_name, cust_phone, cust_contact_preference) ON cust_profile TO GROUP sales_admin",
      "expected": null
    },
    {
      "sql": "GRANT USAGE ON DATABASE sales_db TO Bob",
      "expected": null
    },
    {
      "sql": "GRANT USAGE ON SCHEMA sales_schema TO ROLE Analyst_role",
      "expected": null
    },
    {
      "sql": "GRANT SELECT ON sales_db.sales_schema.tickit_sales_redshift TO Bob",
      "expected": null
    },
    {
      "sql": "REVOKE SELECT ON TABLE sales FROM fred",
      "expected": null
    },
    {
      "sql": "REVOKE ALL ON SCHEMA qa_tickit FROM GROUP qa_users",
      "expected": null
    },
    {
      "sql": "REVOKE USAGE ON DATABASE sales_db FROM Bob",
      "expected": null
    },
    {
      "sql": "REVOKE USAGE ON SCHEMA sales_schema FROM ROLE Analyst_role",
      "expected": null
    },
    {
      "sql": "ANALYZE TBL(col1, col2)",
      "expected": null
    },
    {
      "sql": "ANALYZE VERBOSE TBL",
      "expected": null
    },
    {
      "sql": "ANALYZE TBL PREDICATE COLUMNS",
      "expected": null
    },
    {
      "sql": "ANALYZE TBL ALL COLUMNS",
      "expected": null
    },
    {
      "sql": "DATE_PART(year, \"somecol\")",
      "expected": "EXTRACT(year FROM \"somecol\")"
    },
    {
      "sql": "1::\"int\"",
      "expected": "CAST(1 AS INTEGER)"
    }
  ],
  "transpilation": [
    {
      "sql": "SELECT SPLIT_TO_ARRAY('12,345,6789')",
      "read": {},
      "write": {
        "postgres": "SELECT STRING_TO_ARRAY('12,345,6789', ',')",
        "redshift": "SELECT SPLIT_TO_ARRAY('12,345,6789', ',')"
      }
    },
    {
      "sql": "GETDATE()",
      "read": {
        "duckdb": "CURRENT_TIMESTAMP"
      },
      "write": {
        "duckdb": "CURRENT_TIMESTAMP",
        "redshift": "GETDATE()"
      }
    },
    {
      "sql": "SELECT JSON_EXTRACT_PATH_TEXT('{ \"farm\": {\"barn\": { \"color\": \"red\", \"feed stocked\": true }}}', 'farm', 'barn', 'color')",
      "read": {},
      "write": {
        "bigquery": "SELECT JSON_EXTRACT_SCALAR('{ \"farm\": {\"barn\": { \"color\": \"red\", \"feed stocked\": true }}}', '$.farm.barn.color')",
        "databricks": "SELECT '{ \"farm\": {\"barn\": { \"color\": \"red\", \"feed stocked\": true }}}':farm.barn.color",
        "duckdb": "SELECT '{ \"farm\": {\"barn\": { \"color\": \"red\", \"feed stocked\": true }}}' ->> '$.farm.barn.color'",
        "postgres": "SELECT JSON_EXTRACT_PATH_TEXT('{ \"farm\": {\"barn\": { \"color\": \"red\", \"feed stocked\": true }}}', 'farm', 'barn', 'color')",
        "presto": "SELECT JSON_EXTRACT_SCALAR('{ \"farm\": {\"barn\": { \"color\": \"red\", \"feed stocked\": true }}}', '$.farm.barn.color')",
        "redshift": "SELECT JSON_EXTRACT_PATH_TEXT('{ \"farm\": {\"barn\": { \"color\": \"red\", \"feed stocked\": true }}}', 'farm', 'barn', 'color')",
        "spark": "SELECT GET_JSON_OBJECT('{ \"farm\": {\"barn\": { \"color\": \"red\", \"feed stocked\": true }}}', '$.farm.barn.color')",
        "sqlite": "SELECT '{ \"farm\": {\"barn\": { \"color\": \"red\", \"feed stocked\": true }}}' ->> '$.farm.barn.color'"
      }
    },
    {
      "sql": "LISTAGG(sellerid, ', ')",
      "read": {
        "duckdb": "STRING_AGG(sellerid, ', ')",
        "databricks": "STRING_AGG(sellerid, ', ')"
      },
      "write": {
        "duckdb": "LISTAGG(sellerid, ', ')",
        "redshift": "LISTAGG(sellerid, ', ')",
        "spark, version=3.0.0": "ARRAY_JOIN(COLLECT_LIST(sellerid), ', ')",
        "spark, version=4.0.0": "LISTAGG(sellerid, ', ')",
        "spark": "LISTAGG(sellerid, ', ')",
        "databricks": "LISTAGG(sellerid, ', ')"
      }
    },
    {
      "sql": "SELECT APPROXIMATE COUNT(DISTINCT y)",
      "read": {
        "spark": "SELECT APPROX_COUNT_DISTINCT(y)"
      },
      "write": {
        "redshift": "SELECT APPROXIMATE COUNT(DISTINCT y)",
        "spark": "SELECT APPROX_COUNT_DISTINCT(y)"
      }
    },
    {
      "sql": "x ~* 'pat'",
      "read": {},
      "write": {
        "redshift": "x ~* 'pat'",
        "snowflake": "REGEXP_LIKE(x, 'pat', 'i')"
      }
    },
    {
      "sql": "SELECT CAST('01:03:05.124' AS TIME(2) WITH TIME ZONE)",
      "read": {
        "postgres": "SELECT CAST('01:03:05.124' AS TIMETZ(2))"
      },
      "write": {
        "postgres": "SELECT CAST('01:03:05.124' AS TIMETZ(2))",
        "redshift": "SELECT CAST('01:03:05.124' AS TIME(2) WITH TIME ZONE)"
      }
    },
    {
      "sql": "SELECT CAST('2020-02-02 01:03:05.124' AS TIMESTAMP(2) WITH TIME ZONE)",
      "read": {
        "postgres": "SELECT CAST('2020-02-02 01:03:05.124' AS TIMESTAMPTZ(2))"
      },
      "write": {
        "postgres": "SELECT CAST('2020-02-02 01:03:05.124' AS TIMESTAMPTZ(2))",
        "redshift": "SELECT CAST('2020-02-02 01:03:05.124' AS TIMESTAMP(2) WITH TIME ZONE)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2008-03-31', 1)",
      "read": {},
      "write": {
        "bigquery": "SELECT DATE_ADD(CAST('2008-03-31' AS DATETIME), INTERVAL 1 MONTH)",
        "duckdb": "SELECT CAST('2008-03-31' AS TIMESTAMP) + INTERVAL 1 MONTH",
        "redshift": "SELECT DATEADD(MONTH, 1, '2008-03-31')",
        "trino": "SELECT DATE_ADD('MONTH', 1, CAST('2008-03-31' AS TIMESTAMP))",
        "tsql": "SELECT DATEADD(MONTH, 1, CAST('2008-03-31' AS DATETIME2))"
      }
    },
    {
      "sql": "SELECT STRTOL('abc', 16)",
      "read": {
        "trino": "SELECT FROM_BASE('abc', 16)"
      },
      "write": {
        "redshift": "SELECT STRTOL('abc', 16)",
        "trino": "SELECT FROM_BASE('abc', 16)"
      }
    },
    {
      "sql": "SELECT SNAPSHOT, type",
      "read": {},
      "write": {
        "redshift": "SELECT \"SNAPSHOT\", \"type\""
      }
    },
    {
      "sql": "x is true",
      "read": {},
      "write": {
        "redshift": "x IS TRUE",
        "presto": "x"
      }
    },
    {
      "sql": "x is false",
      "read": {},
      "write": {
        "redshift": "x IS FALSE",
        "presto": "NOT x"
      }
    },
    {
      "sql": "x is not false",
      "read": {},
      "write": {
        "redshift": "NOT x IS FALSE",
        "presto": "NOT NOT x"
      }
    },
    {
      "sql": "LEN(x)",
      "read": {},
      "write": {
        "redshift": "LENGTH(x)",
        "presto": "LENGTH(x)"
      }
    },
    {
      "sql": "x LIKE 'abc' || '%'",
      "read": {
        "duckdb": "STARTS_WITH(x, 'abc')"
      },
      "write": {
        "redshift": "x LIKE 'abc' || '%'"
      }
    },
    {
      "sql": "SELECT SYSDATE",
      "read": {},
      "write": {
        "postgres": "SELECT CURRENT_TIMESTAMP",
        "redshift": "SELECT SYSDATE"
      }
    },
    {
      "sql": "SELECT DATE_PART(minute, timestamp '2023-01-04 04:05:06.789')",
      "read": {},
      "write": {
        "postgres": "SELECT EXTRACT(minute FROM CAST('2023-01-04 04:05:06.789' AS TIMESTAMP))",
        "redshift": "SELECT EXTRACT(minute FROM CAST('2023-01-04 04:05:06.789' AS TIMESTAMP))",
        "snowflake": "SELECT DATE_PART(minute, CAST('2023-01-04 04:05:06.789' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT DATE_PART(month, date '20220502')",
      "read": {},
      "write": {
        "postgres": "SELECT EXTRACT(month FROM CAST('20220502' AS DATE))",
        "redshift": "SELECT EXTRACT(month FROM CAST('20220502' AS DATE))",
        "snowflake": "SELECT DATE_PART(month, CAST('20220502' AS DATE))"
      }
    },
    {
      "sql": "create table \"group\" (\"col\" char(10))",
      "read": {},
      "write": {
        "redshift": "CREATE TABLE \"group\" (\"col\" CHAR(10))",
        "mysql": "CREATE TABLE `group` (`col` CHAR(10))"
      }
    },
    {
      "sql": "create table if not exists city_slash_id(\"city/id\" integer not null, state char(2) not null)",
      "read": {},
      "write": {
        "redshift": "CREATE TABLE IF NOT EXISTS city_slash_id (\"city/id\" INTEGER NOT NULL, state CHAR(2) NOT NULL)",
        "presto": "CREATE TABLE IF NOT EXISTS city_slash_id (\"city/id\" INTEGER NOT NULL, state CHAR(2) NOT NULL)"
      }
    },
    {
      "sql": "SELECT ST_AsEWKT(ST_GeomFromEWKT('SRID=4326;POINT(10 20)')::geography)",
      "read": {},
      "write": {
        "redshift": "SELECT ST_ASEWKT(CAST(ST_GEOMFROMEWKT('SRID=4326;POINT(10 20)') AS GEOGRAPHY))",
        "bigquery": "SELECT ST_AsEWKT(CAST(ST_GeomFromEWKT('SRID=4326;POINT(10 20)') AS GEOGRAPHY))"
      }
    },
    {
      "sql": "SELECT ST_AsEWKT(ST_GeogFromText('LINESTRING(110 40, 2 3, -10 80, -7 9)')::geometry)",
      "read": {},
      "write": {
        "redshift": "SELECT ST_ASEWKT(CAST(ST_GEOGFROMTEXT('LINESTRING(110 40, 2 3, -10 80, -7 9)') AS GEOMETRY))"
      }
    },
    {
      "sql": "SELECT 'abc'::BINARY",
      "read": {},
      "write": {
        "redshift": "SELECT CAST('abc' AS VARBYTE)"
      }
    },
    {
      "sql": "CREATE TABLE a (b BINARY VARYING(10))",
      "read": {},
      "write": {
        "redshift": "CREATE TABLE a (b VARBYTE(10))"
      }
    },
    {
      "sql": "SELECT 'abc'::CHARACTER",
      "read": {},
      "write": {
        "redshift": "SELECT CAST('abc' AS CHAR)"
      }
    },
    {
      "sql": "SELECT DISTINCT ON (a) a, b FROM x ORDER BY c DESC",
      "read": {},
      "write": {
        "bigquery": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "databricks": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "drill": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "hive": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "mysql": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY CASE WHEN c IS NULL THEN 1 ELSE 0 END DESC, c DESC) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "oracle": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC) AS _row_number FROM x) _t WHERE _row_number = 1",
        "presto": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "redshift": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "snowflake": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "spark": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "sqlite": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "starrocks": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY CASE WHEN c IS NULL THEN 1 ELSE 0 END DESC, c DESC) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "tableau": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "teradata": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "trino": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY c DESC NULLS FIRST) AS _row_number FROM x) AS _t WHERE _row_number = 1",
        "tsql": "SELECT a, b FROM (SELECT a AS a, b AS b, ROW_NUMBER() OVER (PARTITION BY a ORDER BY CASE WHEN c IS NULL THEN 1 ELSE 0 END DESC, c DESC) AS _row_number FROM x) AS _t WHERE _row_number = 1"
      }
    },
    {
      "sql": "DECODE(x, a, b, c, d)",
      "read": {},
      "write": {
        "duckdb": "CASE WHEN x = a OR (x IS NULL AND a IS NULL) THEN b WHEN x = c OR (x IS NULL AND c IS NULL) THEN d END",
        "oracle": "DECODE(x, a, b, c, d)",
        "redshift": "DECODE(x, a, b, c, d)",
        "snowflake": "DECODE(x, a, b, c, d)",
        "spark": "DECODE(x, a, b, c, d)"
      }
    },
    {
      "sql": "NVL(a, b, c, d)",
      "read": {},
      "write": {
        "redshift": "COALESCE(a, b, c, d)",
        "mysql": "COALESCE(a, b, c, d)",
        "postgres": "COALESCE(a, b, c, d)"
      }
    },
    {
      "sql": "DATEDIFF('day', a, b)",
      "read": {},
      "write": {
        "bigquery": "DATE_DIFF(CAST(b AS DATETIME), CAST(a AS DATETIME), DAY)",
        "duckdb": "DATE_DIFF('DAY', CAST(a AS TIMESTAMP), CAST(b AS TIMESTAMP))",
        "hive": "DATEDIFF(b, a)",
        "redshift": "DATEDIFF(DAY, a, b)",
        "presto": "DATE_DIFF('DAY', CAST(a AS TIMESTAMP), CAST(b AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT DATEADD(month, 18, '2008-02-28')",
      "read": {},
      "write": {
        "bigquery": "SELECT DATE_ADD(CAST('2008-02-28' AS DATETIME), INTERVAL 18 MONTH)",
        "duckdb": "SELECT CAST('2008-02-28' AS TIMESTAMP) + INTERVAL 18 MONTH",
        "hive": "SELECT ADD_MONTHS('2008-02-28', 18)",
        "mysql": "SELECT DATE_ADD('2008-02-28', INTERVAL 18 MONTH)",
        "postgres": "SELECT CAST('2008-02-28' AS TIMESTAMP) + INTERVAL '18 MONTH'",
        "presto": "SELECT DATE_ADD('MONTH', 18, CAST('2008-02-28' AS TIMESTAMP))",
        "redshift": "SELECT DATEADD(MONTH, 18, '2008-02-28')",
        "snowflake": "SELECT DATEADD(MONTH, 18, CAST('2008-02-28' AS TIMESTAMP))",
        "tsql": "SELECT DATEADD(MONTH, 18, CAST('2008-02-28' AS DATETIME2))",
        "spark": "SELECT DATE_ADD(MONTH, 18, '2008-02-28')",
        "spark2": "SELECT ADD_MONTHS('2008-02-28', 18)",
        "databricks": "SELECT DATE_ADD(MONTH, 18, '2008-02-28')"
      }
    },
    {
      "sql": "SELECT DATEDIFF(week, '2009-01-01', '2009-12-31')",
      "read": {},
      "write": {
        "bigquery": "SELECT DATE_DIFF(CAST('2009-12-31' AS DATETIME), CAST('2009-01-01' AS DATETIME), WEEK)",
        "duckdb": "SELECT DATE_DIFF('WEEK', CAST('2009-01-01' AS TIMESTAMP), CAST('2009-12-31' AS TIMESTAMP))",
        "hive": "SELECT CAST(DATEDIFF('2009-12-31', '2009-01-01') / 7 AS INT)",
        "postgres": "SELECT CAST(EXTRACT(days FROM (CAST('2009-12-31' AS TIMESTAMP) - CAST('2009-01-01' AS TIMESTAMP))) / 7 AS BIGINT)",
        "presto": "SELECT DATE_DIFF('WEEK', CAST('2009-01-01' AS TIMESTAMP), CAST('2009-12-31' AS TIMESTAMP))",
        "redshift": "SELECT DATEDIFF(WEEK, '2009-01-01', '2009-12-31')",
        "snowflake": "SELECT DATEDIFF(WEEK, '2009-01-01', '2009-12-31')",
        "tsql": "SELECT DATEDIFF(WEEK, '2009-01-01', '2009-12-31')"
      }
    },
    {
      "sql": "SELECT EXTRACT(EPOCH FROM CURRENT_DATE)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(EPOCH, CURRENT_DATE)",
        "redshift": "SELECT EXTRACT(EPOCH FROM CURRENT_DATE)"
      }
    },
    {
      "sql": "SELECT * FROM (SELECT 1, 2) AS t",
      "read": {},
      "write": {
        "mysql": "SELECT * FROM (SELECT 1, 2) AS t",
        "presto": "SELECT * FROM (SELECT 1, 2) AS t"
      }
    },
    {
      "sql": "CREATE TABLE t1 (LIKE t2)",
      "read": {},
      "write": {
        "postgres": "CREATE TABLE t1 (LIKE t2)",
        "presto": "CREATE TABLE t1 (LIKE t2)",
        "redshift": "CREATE TABLE t1 (LIKE t2)",
        "trino": "CREATE TABLE t1 (LIKE t2)"
      }
    },
    {
      "sql": "CREATE TABLE t1 (col VARCHAR, LIKE t2)",
      "read": {},
      "write": {
        "postgres": "CREATE TABLE t1 (col VARCHAR, LIKE t2)",
        "presto": "CREATE TABLE t1 (col VARCHAR, LIKE t2)",
        "redshift": "CREATE TABLE t1 (col VARCHAR, LIKE t2)",
        "trino": "CREATE TABLE t1 (col VARCHAR, LIKE t2)"
      }
    },
    {
      "sql": "ALTER TABLE db.t1 RENAME TO db.t2",
      "read": {},
      "write": {
        "spark": "ALTER TABLE db.t1 RENAME TO db.t2",
        "redshift": "ALTER TABLE db.t1 RENAME TO t2"
      }
    },
    {
      "sql": "CREATE TABLE \"TEST\" (\"cola\" VARCHAR(MAX))",
      "read": {
        "redshift": "CREATE TABLE TEST (cola VARCHAR(max))",
        "tsql": "CREATE TABLE TEST (cola VARCHAR(max))"
      },
      "write": {
        "redshift": "CREATE TABLE \"TEST\" (\"cola\" VARCHAR(MAX))"
      }
    },
    {
      "sql": "CREATE OR REPLACE VIEW v1 AS SELECT cola, colb FROM t1 WITH NO SCHEMA BINDING",
      "read": {},
      "write": {
        "redshift": "CREATE OR REPLACE VIEW v1 AS SELECT cola, colb FROM t1 WITH NO SCHEMA BINDING"
      }
    },
    {
      "sql": "TIME_TO_STR(a, '%Y-%m-%d %H:%M:%S.%f')",
      "read": {},
      "write": {
        "redshift": "TO_CHAR(a, 'YYYY-MM-DD HH24:MI:SS.US')"
      }
    },
    {
      "sql": "SELECT * FROM t FETCH FIRST 1 ROWS ONLY",
      "read": {},
      "write": {
        "redshift": "SELECT * FROM t LIMIT 1",
        "postgres": "SELECT * FROM t FETCH FIRST 1 ROWS ONLY"
      }
    },
    {
      "sql": "SELECT REGEXP_SUBSTR(abc, 'pattern(group)', 2) FROM table",
      "read": {},
      "write": {
        "redshift": "SELECT REGEXP_SUBSTR(abc, 'pattern(group)', 2) FROM \"table\"",
        "duckdb": "SELECT REGEXP_EXTRACT(SUBSTRING(abc, 2), 'pattern(group)') FROM \"table\""
      }
    }
  ]
}