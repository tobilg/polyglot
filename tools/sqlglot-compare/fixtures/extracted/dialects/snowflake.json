{
  "dialect": "snowflake",
  "identity": [
    {
      "sql": "SELECT session",
      "expected": null
    },
    {
      "sql": "x::nvarchar()",
      "expected": "CAST(x AS VARCHAR)"
    },
    {
      "sql": "SELECT DATE_PART(EPOCH_MILLISECOND, CURRENT_TIMESTAMP()) AS a",
      "expected": null
    },
    {
      "sql": "SELECT GET(a, b)",
      "expected": null
    },
    {
      "sql": "SELECT HASH_AGG(a, b, c, d)",
      "expected": null
    },
    {
      "sql": "SELECT GREATEST(1, 2, 3, NULL)",
      "expected": null
    },
    {
      "sql": "SELECT GREATEST_IGNORE_NULLS(1, 2, 3, NULL)",
      "expected": null
    },
    {
      "sql": "SELECT LEAST(5, NULL, 7, 3)",
      "expected": null
    },
    {
      "sql": "SELECT LEAST_IGNORE_NULLS(5, NULL, 7, 3)",
      "expected": null
    },
    {
      "sql": "SELECT MAX(x)",
      "expected": null
    },
    {
      "sql": "SELECT COUNT(x)",
      "expected": null
    },
    {
      "sql": "SELECT MIN(amount)",
      "expected": null
    },
    {
      "sql": "SELECT MODE(x)",
      "expected": null
    },
    {
      "sql": "SELECT MODE(status) OVER (PARTITION BY region) FROM orders",
      "expected": null
    },
    {
      "sql": "SELECT TAN(x)",
      "expected": null
    },
    {
      "sql": "SELECT COS(x)",
      "expected": null
    },
    {
      "sql": "SELECT SINH(1.5)",
      "expected": null
    },
    {
      "sql": "SELECT MOD(x, y)",
      "expected": "SELECT x % y"
    },
    {
      "sql": "SELECT ROUND(x)",
      "expected": null
    },
    {
      "sql": "SELECT ROUND(123.456, -1)",
      "expected": null
    },
    {
      "sql": "SELECT ROUND(123.456, 2, 'HALF_AWAY_FROM_ZERO')",
      "expected": null
    },
    {
      "sql": "SELECT FLOOR(x)",
      "expected": null
    },
    {
      "sql": "SELECT FLOOR(135.135, 1)",
      "expected": null
    },
    {
      "sql": "SELECT FLOOR(x, -1)",
      "expected": null
    },
    {
      "sql": "SELECT PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY salary) FROM employees",
      "expected": null
    },
    {
      "sql": "SELECT APPROX_TOP_K(col) FROM t",
      "expected": "SELECT APPROX_TOP_K(col, 1) FROM t"
    },
    {
      "sql": "SELECT APPROX_TOP_K(category, 3) FROM t",
      "expected": null
    },
    {
      "sql": "SELECT MINHASH(5, col)",
      "expected": null
    },
    {
      "sql": "SELECT MINHASH(5, col1, col2)",
      "expected": null
    },
    {
      "sql": "SELECT MINHASH(5, *)",
      "expected": null
    },
    {
      "sql": "SELECT MINHASH_COMBINE(minhash_col)",
      "expected": null
    },
    {
      "sql": "SELECT APPROXIMATE_SIMILARITY(minhash_col)",
      "expected": null
    },
    {
      "sql": "SELECT APPROXIMATE_JACCARD_INDEX(minhash_col)",
      "expected": "SELECT APPROXIMATE_SIMILARITY(minhash_col)"
    },
    {
      "sql": "SELECT APPROX_PERCENTILE_ACCUMULATE(col)",
      "expected": null
    },
    {
      "sql": "SELECT APPROX_PERCENTILE_ESTIMATE(state, 0.5)",
      "expected": null
    },
    {
      "sql": "SELECT APPROX_TOP_K_ACCUMULATE(col, 10)",
      "expected": null
    },
    {
      "sql": "SELECT APPROX_TOP_K_COMBINE(state, 2)",
      "expected": null
    },
    {
      "sql": "SELECT APPROX_TOP_K_COMBINE(state)",
      "expected": null
    },
    {
      "sql": "SELECT APPROX_TOP_K_ESTIMATE(state_column, 4)",
      "expected": null
    },
    {
      "sql": "SELECT APPROX_TOP_K_ESTIMATE(state_column)",
      "expected": null
    },
    {
      "sql": "SELECT APPROX_PERCENTILE_COMBINE(state_column)",
      "expected": null
    },
    {
      "sql": "SELECT EQUAL_NULL(1, 2)",
      "expected": null
    },
    {
      "sql": "SELECT EXP(1)",
      "expected": null
    },
    {
      "sql": "SELECT FACTORIAL(5)",
      "expected": null
    },
    {
      "sql": "SELECT BIT_LENGTH('abc')",
      "expected": null
    },
    {
      "sql": "SELECT BIT_LENGTH(x'A1B2')",
      "expected": null
    },
    {
      "sql": "SELECT BITMAP_BUCKET_NUMBER(32769)",
      "expected": null
    },
    {
      "sql": "SELECT BITMAP_CONSTRUCT_AGG(value)",
      "expected": null
    },
    {
      "sql": "SELECT BITMAP_COUNT(BITMAP_CONSTRUCT_AGG(value)) FROM TABLE(FLATTEN(INPUT => ARRAY_CONSTRUCT(1, 2, 3, 5)))",
      "expected": "SELECT BITMAP_COUNT(BITMAP_CONSTRUCT_AGG(value)) FROM TABLE(FLATTEN(INPUT => [1, 2, 3, 5]))"
    },
    {
      "sql": "SELECT BOOLAND(1, -2)",
      "expected": null
    },
    {
      "sql": "SELECT BOOLXOR(2, 0)",
      "expected": null
    },
    {
      "sql": "SELECT BOOLOR(1, 0)",
      "expected": null
    },
    {
      "sql": "SELECT TO_BOOLEAN('true')",
      "expected": null
    },
    {
      "sql": "SELECT TO_BOOLEAN(1)",
      "expected": null
    },
    {
      "sql": "SELECT IS_NULL_VALUE(GET_PATH(payload, 'field'))",
      "expected": null
    },
    {
      "sql": "SELECT RTRIMMED_LENGTH(' ABCD ')",
      "expected": null
    },
    {
      "sql": "SELECT HEX_DECODE_STRING('48656C6C6F')",
      "expected": null
    },
    {
      "sql": "SELECT HEX_ENCODE('Hello World')",
      "expected": null
    },
    {
      "sql": "SELECT HEX_ENCODE('Hello World', 1)",
      "expected": null
    },
    {
      "sql": "SELECT HEX_ENCODE('Hello World', 0)",
      "expected": null
    },
    {
      "sql": "SELECT IFNULL(col1, col2)",
      "expected": "SELECT COALESCE(col1, col2)"
    },
    {
      "sql": "SELECT NEXT_DAY('2025-10-15', 'FRIDAY')",
      "expected": null
    },
    {
      "sql": "SELECT NVL2(col1, col2, col3)",
      "expected": null
    },
    {
      "sql": "SELECT NVL(col1, col2)",
      "expected": "SELECT COALESCE(col1, col2)"
    },
    {
      "sql": "SELECT CHR(8364)",
      "expected": null
    },
    {
      "sql": "SELECT CHECK_JSON('{\"key\": \"value\"}')",
      "expected": null
    },
    {
      "sql": "SELECT CHECK_XML('<root><key attribute=\"attr\">value</key></root>')",
      "expected": null
    },
    {
      "sql": "SELECT CHECK_XML('<root><key attribute=\"attr\">value</key></root>', TRUE)",
      "expected": null
    },
    {
      "sql": "SELECT COMPRESS('Hello World', 'ZLIB')",
      "expected": null
    },
    {
      "sql": "SELECT DECOMPRESS_BINARY('compressed_data', 'SNAPPY')",
      "expected": null
    },
    {
      "sql": "SELECT DECOMPRESS_STRING('compressed_data', 'ZSTD')",
      "expected": null
    },
    {
      "sql": "SELECT LPAD('Hello', 10, '*')",
      "expected": null
    },
    {
      "sql": "SELECT LPAD(tbl.bin_col, 10)",
      "expected": null
    },
    {
      "sql": "SELECT RPAD('Hello', 10, '*')",
      "expected": null
    },
    {
      "sql": "SELECT RPAD(tbl.bin_col, 10)",
      "expected": null
    },
    {
      "sql": "SELECT SOUNDEX(column_name)",
      "expected": null
    },
    {
      "sql": "SELECT SOUNDEX_P123(column_name)",
      "expected": null
    },
    {
      "sql": "SELECT ABS(x)",
      "expected": null
    },
    {
      "sql": "SELECT ASIN(0.5)",
      "expected": null
    },
    {
      "sql": "SELECT ASINH(0.5)",
      "expected": null
    },
    {
      "sql": "SELECT ATAN(0.5)",
      "expected": null
    },
    {
      "sql": "SELECT ATAN2(0.5, 0.3)",
      "expected": null
    },
    {
      "sql": "SELECT ATANH(0.5)",
      "expected": null
    },
    {
      "sql": "SELECT CBRT(27.0)",
      "expected": null
    },
    {
      "sql": "SELECT POW(2, 3)",
      "expected": "SELECT POWER(2, 3)"
    },
    {
      "sql": "SELECT POW(2.5, 3.0)",
      "expected": "SELECT POWER(2.5, 3.0)"
    },
    {
      "sql": "SELECT SQUARE(2.5)",
      "expected": "SELECT POWER(2.5, 2)"
    },
    {
      "sql": "SELECT SIGN(x)",
      "expected": null
    },
    {
      "sql": "SELECT COSH(1.5)",
      "expected": null
    },
    {
      "sql": "SELECT TANH(0.5)",
      "expected": null
    },
    {
      "sql": "SELECT JAROWINKLER_SIMILARITY('hello', 'world')",
      "expected": null
    },
    {
      "sql": "SELECT TRANSLATE(column_name, 'abc', '123')",
      "expected": null
    },
    {
      "sql": "SELECT UNICODE(column_name)",
      "expected": null
    },
    {
      "sql": "SELECT WIDTH_BUCKET(col, 0, 100, 10)",
      "expected": null
    },
    {
      "sql": "SELECT SPLIT_PART('11.22.33', '.', 1)",
      "expected": null
    },
    {
      "sql": "SELECT PI()",
      "expected": null
    },
    {
      "sql": "SELECT DEGREES(PI() / 3)",
      "expected": null
    },
    {
      "sql": "SELECT DEGREES(1)",
      "expected": null
    },
    {
      "sql": "SELECT RADIANS(180)",
      "expected": null
    },
    {
      "sql": "SELECT REGR_AVGX(y, x)",
      "expected": null
    },
    {
      "sql": "SELECT REGR_AVGY(y, x)",
      "expected": null
    },
    {
      "sql": "SELECT REGR_COUNT(y, x)",
      "expected": null
    },
    {
      "sql": "SELECT REGR_INTERCEPT(y, x)",
      "expected": null
    },
    {
      "sql": "SELECT REGR_R2(y, x)",
      "expected": null
    },
    {
      "sql": "SELECT REGR_SXX(y, x)",
      "expected": null
    },
    {
      "sql": "SELECT REGR_SXY(y, x)",
      "expected": null
    },
    {
      "sql": "SELECT REGR_SYY(y, x)",
      "expected": null
    },
    {
      "sql": "SELECT REGR_SLOPE(y, x)",
      "expected": null
    },
    {
      "sql": "SELECT RANDOM()",
      "expected": null
    },
    {
      "sql": "SELECT RANDOM(123)",
      "expected": null
    },
    {
      "sql": "SELECT RANDSTR(123, 456)",
      "expected": null
    },
    {
      "sql": "SELECT RANDSTR(123, RANDOM())",
      "expected": null
    },
    {
      "sql": "SELECT NORMAL(0, 1, RANDOM())",
      "expected": null
    },
    {
      "sql": "SELECT GROUPING_ID(a, b) AS g_id FROM x GROUP BY ROLLUP (a, b)",
      "expected": null
    },
    {
      "sql": "PARSE_URL('https://example.com/path')",
      "expected": null
    },
    {
      "sql": "PARSE_URL('https://example.com/path', 1)",
      "expected": null
    },
    {
      "sql": "SELECT XMLGET(object_col, 'level2')",
      "expected": null
    },
    {
      "sql": "SELECT XMLGET(object_col, 'level3', 1)",
      "expected": null
    },
    {
      "sql": "SELECT {*} FROM my_table",
      "expected": null
    },
    {
      "sql": "SELECT {my_table.*} FROM my_table",
      "expected": null
    },
    {
      "sql": "SELECT {* ILIKE 'col1%'} FROM my_table",
      "expected": null
    },
    {
      "sql": "SELECT {* EXCLUDE (col1)} FROM my_table",
      "expected": null
    },
    {
      "sql": "SELECT {* EXCLUDE (col1, col2)} FROM my_table",
      "expected": null
    },
    {
      "sql": "SELECT a, b, COUNT(*) FROM x GROUP BY ALL LIMIT 100",
      "expected": null
    },
    {
      "sql": "STRTOK_TO_ARRAY('a b c')",
      "expected": null
    },
    {
      "sql": "STRTOK_TO_ARRAY('a.b.c', '.')",
      "expected": null
    },
    {
      "sql": "GET(a, b)",
      "expected": null
    },
    {
      "sql": "INSERT INTO test VALUES (x'48FAF43B0AFCEF9B63EE3A93EE2AC2')",
      "expected": null
    },
    {
      "sql": "SELECT STAR(tbl, exclude := [foo])",
      "expected": null
    },
    {
      "sql": "SELECT CAST([1, 2, 3] AS VECTOR(FLOAT, 3))",
      "expected": null
    },
    {
      "sql": "SELECT VECTOR_COSINE_SIMILARITY(a, b)",
      "expected": null
    },
    {
      "sql": "SELECT VECTOR_INNER_PRODUCT(a, b)",
      "expected": null
    },
    {
      "sql": "SELECT VECTOR_L1_DISTANCE(a, b)",
      "expected": null
    },
    {
      "sql": "SELECT VECTOR_L2_DISTANCE(a, b)",
      "expected": null
    },
    {
      "sql": "SELECT CONNECT_BY_ROOT test AS test_column_alias",
      "expected": null
    },
    {
      "sql": "INTERVAL '4 years, 5 months, 3 hours'",
      "expected": null
    },
    {
      "sql": "ALTER TABLE table1 CLUSTER BY (name DESC)",
      "expected": null
    },
    {
      "sql": "SELECT rename, replace",
      "expected": null
    },
    {
      "sql": "SELECT TIMEADD(HOUR, 2, CAST('09:05:03' AS TIME))",
      "expected": null
    },
    {
      "sql": "SELECT CAST(OBJECT_CONSTRUCT('a', 1) AS MAP(VARCHAR, INT))",
      "expected": null
    },
    {
      "sql": "SELECT MAP_CAT(CAST(col AS MAP(VARCHAR, VARCHAR)), CAST(col AS MAP(VARCHAR, VARCHAR)))",
      "expected": null
    },
    {
      "sql": "SELECT MAP_CONTAINS_KEY('k1', CAST(col AS MAP(VARCHAR, VARCHAR)))",
      "expected": null
    },
    {
      "sql": "SELECT MAP_DELETE(CAST(col AS MAP(VARCHAR, VARCHAR)), 'k1')",
      "expected": null
    },
    {
      "sql": "SELECT MAP_INSERT(CAST(col AS MAP(VARCHAR, VARCHAR)), 'b', '2')",
      "expected": null
    },
    {
      "sql": "SELECT MAP_KEYS(CAST(col AS MAP(VARCHAR, VARCHAR)))",
      "expected": null
    },
    {
      "sql": "SELECT MAP_PICK(CAST(col AS MAP(VARCHAR, VARCHAR)), 'a', 'c')",
      "expected": null
    },
    {
      "sql": "SELECT MAP_SIZE(CAST(col AS MAP(VARCHAR, VARCHAR)))",
      "expected": null
    },
    {
      "sql": "SELECT CAST(OBJECT_CONSTRUCT('a', 1) AS OBJECT(a CHAR NOT NULL))",
      "expected": null
    },
    {
      "sql": "SELECT CAST([1, 2, 3] AS ARRAY(INT))",
      "expected": null
    },
    {
      "sql": "SELECT CAST(obj AS OBJECT(x CHAR) RENAME FIELDS)",
      "expected": null
    },
    {
      "sql": "SELECT CAST(obj AS OBJECT(x CHAR, y VARCHAR) ADD FIELDS)",
      "expected": null
    },
    {
      "sql": "SELECT TO_TIMESTAMP(x) FROM t",
      "expected": null
    },
    {
      "sql": "SELECT TO_TIMESTAMP_NTZ(x) FROM t",
      "expected": null
    },
    {
      "sql": "SELECT TO_TIMESTAMP_LTZ(x) FROM t",
      "expected": null
    },
    {
      "sql": "SELECT TO_TIMESTAMP_TZ(x) FROM t",
      "expected": null
    },
    {
      "sql": "TO_DECIMAL(expr)",
      "expected": "TO_NUMBER(expr)"
    },
    {
      "sql": "TO_DECIMAL(expr, fmt)",
      "expected": "TO_NUMBER(expr, fmt)"
    },
    {
      "sql": "TO_DECIMAL(expr, fmt, precision, scale)",
      "expected": "TO_NUMBER(expr, fmt, precision, scale)"
    },
    {
      "sql": "TO_NUMBER(expr)",
      "expected": null
    },
    {
      "sql": "TO_NUMBER(expr, fmt)",
      "expected": null
    },
    {
      "sql": "TO_NUMBER(expr, fmt, precision, scale)",
      "expected": null
    },
    {
      "sql": "TO_DECFLOAT('123.456')",
      "expected": null
    },
    {
      "sql": "TO_DECFLOAT('1,234.56', '999,999.99')",
      "expected": null
    },
    {
      "sql": "TRY_TO_DECFLOAT('123.456')",
      "expected": null
    },
    {
      "sql": "TRY_TO_DECFLOAT('1,234.56', '999,999.99')",
      "expected": null
    },
    {
      "sql": "TRY_TO_DECIMAL('123.45')",
      "expected": "TRY_TO_NUMBER('123.45')"
    },
    {
      "sql": "TRY_TO_DECIMAL('123.45', '999.99')",
      "expected": "TRY_TO_NUMBER('123.45', '999.99')"
    },
    {
      "sql": "TRY_TO_DECIMAL('123.45', '999.99', 10, 2)",
      "expected": "TRY_TO_NUMBER('123.45', '999.99', 10, 2)"
    },
    {
      "sql": "TRY_TO_DOUBLE('123.456', '999.99')",
      "expected": null
    },
    {
      "sql": "TO_FILE(object_col)",
      "expected": null
    },
    {
      "sql": "TO_FILE('file.csv')",
      "expected": null
    },
    {
      "sql": "TO_FILE('file.csv', 'relativepath/')",
      "expected": null
    },
    {
      "sql": "TRY_TO_FILE(object_col)",
      "expected": null
    },
    {
      "sql": "TRY_TO_FILE('file.csv')",
      "expected": null
    },
    {
      "sql": "TRY_TO_FILE('file.csv', 'relativepath/')",
      "expected": null
    },
    {
      "sql": "TRY_TO_NUMBER('123.45')",
      "expected": null
    },
    {
      "sql": "TRY_TO_NUMBER('123.45', '999.99')",
      "expected": null
    },
    {
      "sql": "TRY_TO_NUMBER('123.45', '999.99', 10, 2)",
      "expected": null
    },
    {
      "sql": "TO_NUMERIC('123.45')",
      "expected": "TO_NUMBER('123.45')"
    },
    {
      "sql": "TO_NUMERIC('123.45', '999.99')",
      "expected": "TO_NUMBER('123.45', '999.99')"
    },
    {
      "sql": "TO_NUMERIC('123.45', '999.99', 10, 2)",
      "expected": "TO_NUMBER('123.45', '999.99', 10, 2)"
    },
    {
      "sql": "TRY_TO_NUMERIC('123.45')",
      "expected": "TRY_TO_NUMBER('123.45')"
    },
    {
      "sql": "TRY_TO_NUMERIC('123.45', '999.99')",
      "expected": "TRY_TO_NUMBER('123.45', '999.99')"
    },
    {
      "sql": "TRY_TO_NUMERIC('123.45', '999.99', 10, 2)",
      "expected": "TRY_TO_NUMBER('123.45', '999.99', 10, 2)"
    },
    {
      "sql": "TRY_TO_TIME('12:30:00', 'AUTO')",
      "expected": null
    },
    {
      "sql": "TRY_TO_TIMESTAMP('2024-01-15 12:30:00', 'AUTO')",
      "expected": null
    },
    {
      "sql": "ALTER TABLE authors ADD CONSTRAINT c1 UNIQUE (id, email)",
      "expected": null
    },
    {
      "sql": "RM @parquet_stage",
      "expected": null
    },
    {
      "sql": "REMOVE @parquet_stage",
      "expected": null
    },
    {
      "sql": "SELECT TIMESTAMP_FROM_PARTS(2024, 5, 9, 14, 30, 45)",
      "expected": null
    },
    {
      "sql": "SELECT TIMESTAMP_FROM_PARTS(2024, 5, 9, 14, 30, 45, 123)",
      "expected": null
    },
    {
      "sql": "SELECT TIMESTAMP_LTZ_FROM_PARTS(2013, 4, 5, 12, 00, 00)",
      "expected": null
    },
    {
      "sql": "SELECT TIMESTAMP_TZ_FROM_PARTS(2013, 4, 5, 12, 00, 00)",
      "expected": null
    },
    {
      "sql": "SELECT TIMESTAMP_TZ_FROM_PARTS(2013, 4, 5, 12, 00, 00, 0, 'America/Los_Angeles')",
      "expected": null
    },
    {
      "sql": "SELECT TIMESTAMP_FROM_PARTS(CAST('2024-05-09' AS DATE), CAST('14:30:45' AS TIME))",
      "expected": null
    },
    {
      "sql": "SELECT TIMESTAMP_NTZ_FROM_PARTS(TO_DATE('2013-04-05'), TO_TIME('12:00:00'))",
      "expected": "SELECT TIMESTAMP_FROM_PARTS(CAST('2013-04-05' AS DATE), CAST('12:00:00' AS TIME))"
    },
    {
      "sql": "SELECT TIMESTAMP_NTZ_FROM_PARTS(2013, 4, 5, 12, 00, 00, 987654321)",
      "expected": "SELECT TIMESTAMP_FROM_PARTS(2013, 4, 5, 12, 00, 00, 987654321)"
    },
    {
      "sql": "SELECT DATE_FROM_PARTS(1977, 8, 7)",
      "expected": null
    },
    {
      "sql": "SELECT GET_PATH(v, 'attr[0].name') FROM vartab",
      "expected": null
    },
    {
      "sql": "SELECT TO_ARRAY(CAST(x AS ARRAY))",
      "expected": null
    },
    {
      "sql": "SELECT TO_ARRAY(CAST(['test'] AS VARIANT))",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY_UNIQUE_AGG(x)",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY_APPEND([1, 2, 3], 4)",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY_CAT([1, 2], [3, 4])",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY_PREPEND([2, 3, 4], 1)",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY_REMOVE([1, 2, 3], 2)",
      "expected": null
    },
    {
      "sql": "SELECT AI_AGG(review, 'Summarize the reviews')",
      "expected": null
    },
    {
      "sql": "SELECT AI_SUMMARIZE_AGG(review)",
      "expected": null
    },
    {
      "sql": "SELECT AI_CLASSIFY('text', ['travel', 'cooking'])",
      "expected": null
    },
    {
      "sql": "SELECT OBJECT_CONSTRUCT()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_ACCOUNT()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_ACCOUNT_NAME()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_AVAILABLE_ROLES()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_CLIENT()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_IP_ADDRESS()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_DATABASE()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_SCHEMAS()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_SECONDARY_ROLES()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_SESSION()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_STATEMENT()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_VERSION()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_TRANSACTION()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_WAREHOUSE()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_ORGANIZATION_USER()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_REGION()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_ROLE()",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_ROLE_TYPE()",
      "expected": null
    },
    {
      "sql": "SELECT DAY(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "SELECT DAYOFMONTH(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "SELECT DAYOFYEAR(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "SELECT MONTH(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "SELECT QUARTER(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "SELECT WEEK(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "SELECT WEEKISO(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "WEEKOFYEAR(tstamp)",
      "expected": "WEEK(tstamp)"
    },
    {
      "sql": "SELECT YEAR(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "SELECT YEAROFWEEK(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "SELECT YEAROFWEEKISO(CURRENT_TIMESTAMP())",
      "expected": null
    },
    {
      "sql": "SELECT SUM(amount) FROM mytable GROUP BY ALL",
      "expected": null
    },
    {
      "sql": "SELECT STDDEV(x)",
      "expected": null
    },
    {
      "sql": "SELECT STDDEV(x) OVER (PARTITION BY 1)",
      "expected": null
    },
    {
      "sql": "SELECT STDDEV_POP(x)",
      "expected": null
    },
    {
      "sql": "SELECT STDDEV_POP(x) OVER (PARTITION BY 1)",
      "expected": null
    },
    {
      "sql": "SELECT STDDEV_SAMP(x)",
      "expected": "SELECT STDDEV(x)"
    },
    {
      "sql": "SELECT STDDEV_SAMP(x) OVER (PARTITION BY 1)",
      "expected": "SELECT STDDEV(x) OVER (PARTITION BY 1)"
    },
    {
      "sql": "SELECT KURTOSIS(x)",
      "expected": null
    },
    {
      "sql": "SELECT KURTOSIS(x) OVER (PARTITION BY 1)",
      "expected": null
    },
    {
      "sql": "WITH x AS (SELECT 1 AS foo) SELECT foo FROM IDENTIFIER('x')",
      "expected": null
    },
    {
      "sql": "WITH x AS (SELECT 1 AS foo) SELECT IDENTIFIER('foo') FROM x",
      "expected": null
    },
    {
      "sql": "INITCAP('iqamqinterestedqinqthisqtopic', 'q')",
      "expected": null
    },
    {
      "sql": "OBJECT_CONSTRUCT(*)",
      "expected": null
    },
    {
      "sql": "SELECT CAST('2021-01-01' AS DATE) + INTERVAL '1 DAY'",
      "expected": null
    },
    {
      "sql": "SELECT HLL(*)",
      "expected": null
    },
    {
      "sql": "SELECT HLL(a)",
      "expected": null
    },
    {
      "sql": "SELECT HLL(DISTINCT t.a)",
      "expected": null
    },
    {
      "sql": "SELECT HLL(a, b, c)",
      "expected": null
    },
    {
      "sql": "SELECT HLL(DISTINCT a, b, c)",
      "expected": null
    },
    {
      "sql": "$x",
      "expected": null
    },
    {
      "sql": "a$b",
      "expected": null
    },
    {
      "sql": "SELECT REGEXP_LIKE(a, b, c)",
      "expected": null
    },
    {
      "sql": "CREATE TABLE foo (bar DOUBLE AUTOINCREMENT START 0 INCREMENT 1)",
      "expected": null
    },
    {
      "sql": "COMMENT IF EXISTS ON TABLE foo IS 'bar'",
      "expected": null
    },
    {
      "sql": "SELECT CONVERT_TIMEZONE('UTC', 'America/Los_Angeles', col)",
      "expected": null
    },
    {
      "sql": "SELECT CURRENT_ORGANIZATION_NAME()",
      "expected": null
    },
    {
      "sql": "ALTER TABLE a SWAP WITH b",
      "expected": null
    },
    {
      "sql": "SELECT MATCH_CONDITION",
      "expected": null
    },
    {
      "sql": "SELECT OBJECT_AGG(key, value) FROM tbl",
      "expected": null
    },
    {
      "sql": "1 /* /* */",
      "expected": null
    },
    {
      "sql": "TO_TIMESTAMP(col, fmt)",
      "expected": null
    },
    {
      "sql": "SELECT TO_CHAR(CAST('12:05:05' AS TIME))",
      "expected": null
    },
    {
      "sql": "SELECT TRIM(COALESCE(TO_CHAR(CAST(c AS TIME)), '')) FROM t",
      "expected": null
    },
    {
      "sql": "SELECT GET_PATH(PARSE_JSON(foo), 'bar')",
      "expected": null
    },
    {
      "sql": "SELECT PARSE_IP('192.168.1.1', 'INET')",
      "expected": null
    },
    {
      "sql": "SELECT PARSE_IP('192.168.1.1', 'INET', 0)",
      "expected": null
    },
    {
      "sql": "SELECT GET_PATH(foo, 'bar')",
      "expected": null
    },
    {
      "sql": "SELECT a, exclude, b FROM xxx",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY_SORT(x, TRUE, FALSE)",
      "expected": null
    },
    {
      "sql": "SELECT BOOLXOR_AGG(col) FROM tbl",
      "expected": null
    },
    {
      "sql": "SELECT PERCENTILE_DISC(0.9) WITHIN GROUP (ORDER BY col) OVER (PARTITION BY category)",
      "expected": null
    },
    {
      "sql": "SELECT STRTOK('hello world')",
      "expected": "SELECT SPLIT_PART('hello world', ' ', 1)"
    },
    {
      "sql": "SELECT STRTOK('hello world', ' ')",
      "expected": "SELECT SPLIT_PART('hello world', ' ', 1)"
    },
    {
      "sql": "SELECT STRTOK('hello world', ' ', 2)",
      "expected": "SELECT SPLIT_PART('hello world', ' ', 2)"
    },
    {
      "sql": "SELECT AI_CLASSIFY('text', ['travel', 'cooking'], OBJECT_CONSTRUCT('output_mode', 'multi'))",
      "expected": null
    },
    {
      "sql": "SELECT * FROM table AT (TIMESTAMP => '2024-07-24') UNPIVOT(a FOR b IN (c)) AS pivot_table",
      "expected": null
    },
    {
      "sql": "SELECT * FROM quarterly_sales PIVOT(SUM(amount) FOR quarter IN ('2023_Q1', '2023_Q2', '2023_Q3', '2023_Q4', '2024_Q1') DEFAULT ON NULL (0)) ORDER BY empid",
      "expected": null
    },
    {
      "sql": "SELECT * FROM quarterly_sales PIVOT(SUM(amount) FOR quarter IN (SELECT DISTINCT quarter FROM ad_campaign_types_by_quarter WHERE television = TRUE ORDER BY quarter)) ORDER BY empid",
      "expected": null
    },
    {
      "sql": "SELECT * FROM quarterly_sales PIVOT(SUM(amount) FOR quarter IN (ANY ORDER BY quarter)) ORDER BY empid",
      "expected": null
    },
    {
      "sql": "SELECT * FROM quarterly_sales PIVOT(SUM(amount) FOR quarter IN (ANY)) ORDER BY empid",
      "expected": null
    },
    {
      "sql": "MERGE INTO my_db AS ids USING (SELECT new_id FROM my_model WHERE NOT col IS NULL) AS new_ids ON ids.type = new_ids.type AND ids.source = new_ids.source WHEN NOT MATCHED THEN INSERT VALUES (new_ids.new_id)",
      "expected": null
    },
    {
      "sql": "INSERT OVERWRITE TABLE t SELECT 1",
      "expected": "INSERT OVERWRITE INTO t SELECT 1"
    },
    {
      "sql": "DESCRIBE TABLE \"SNOWFLAKE_SAMPLE_DATA\".\"TPCDS_SF100TCL\".\"WEB_SITE\" type=stage",
      "expected": null
    },
    {
      "sql": "SELECT * FROM DATA AS DATA_L ASOF JOIN DATA AS DATA_R MATCH_CONDITION (DATA_L.VAL > DATA_R.VAL) ON DATA_L.ID = DATA_R.ID",
      "expected": null
    },
    {
      "sql": "SELECT TO_TIMESTAMP('2025-01-16T14:45:30.123+0500', 'yyyy-mm-DDThh24:mi:ss.ff9tzhtzm')",
      "expected": null
    },
    {
      "sql": "SELECT * REPLACE (CAST(col AS TEXT) AS scol) FROM t",
      "expected": "SELECT * REPLACE (CAST(col AS VARCHAR) AS scol) FROM t"
    },
    {
      "sql": "GET(value, 'foo')::VARCHAR",
      "expected": "CAST(GET(value, 'foo') AS VARCHAR)"
    },
    {
      "sql": "SELECT 1 put",
      "expected": "SELECT 1 AS put"
    },
    {
      "sql": "SELECT 1 get",
      "expected": "SELECT 1 AS get"
    },
    {
      "sql": "WITH t (SELECT 1 AS c) SELECT c FROM t",
      "expected": "WITH t AS (SELECT 1 AS c) SELECT c FROM t"
    },
    {
      "sql": "GET_PATH(json_data, '$id')",
      "expected": "GET_PATH(json_data, '[\"$id\"]')"
    },
    {
      "sql": "CAST(x AS GEOGRAPHY)",
      "expected": "TO_GEOGRAPHY(x)"
    },
    {
      "sql": "CAST(x AS GEOMETRY)",
      "expected": "TO_GEOMETRY(x)"
    },
    {
      "sql": "transform(x, a int -> a + a + 1)",
      "expected": "TRANSFORM(x, a -> CAST(a AS INT) + CAST(a AS INT) + 1)"
    },
    {
      "sql": "SELECT * FROM s WHERE c NOT IN (1, 2, 3)",
      "expected": "SELECT * FROM s WHERE NOT c IN (1, 2, 3)"
    },
    {
      "sql": "SELECT * FROM s WHERE c NOT IN (SELECT * FROM t)",
      "expected": "SELECT * FROM s WHERE c <> ALL (SELECT * FROM t)"
    },
    {
      "sql": "SELECT * FROM t1 INNER JOIN t2 USING (t1.col)",
      "expected": "SELECT * FROM t1 INNER JOIN t2 USING (col)"
    },
    {
      "sql": "CURRENT_TIMESTAMP - INTERVAL '1 w' AND (1 = 1)",
      "expected": "CURRENT_TIMESTAMP() - INTERVAL '1 WEEK' AND (1 = 1)"
    },
    {
      "sql": "REGEXP_REPLACE('target', 'pattern', '\n')",
      "expected": "REGEXP_REPLACE('target', 'pattern', '\\n')"
    },
    {
      "sql": "SELECT a:from::STRING, a:from || ' test' ",
      "expected": "SELECT CAST(GET_PATH(a, 'from') AS VARCHAR), GET_PATH(a, 'from') || ' test'"
    },
    {
      "sql": "SELECT a:select",
      "expected": "SELECT GET_PATH(a, 'select')"
    },
    {
      "sql": "x:from",
      "expected": "GET_PATH(x, 'from')"
    },
    {
      "sql": "value:values::string::int",
      "expected": "CAST(CAST(GET_PATH(value, 'values') AS VARCHAR) AS INT)"
    },
    {
      "sql": "SELECT GET_PATH(PARSE_JSON('{\"y\": [{\"z\": 1}]}'), 'y[0]:z')",
      "expected": "SELECT GET_PATH(PARSE_JSON('{\"y\": [{\"z\": 1}]}'), 'y[0].z')"
    },
    {
      "sql": "SELECT p FROM t WHERE p:val NOT IN ('2')",
      "expected": "SELECT p FROM t WHERE NOT GET_PATH(p, 'val') IN ('2')"
    },
    {
      "sql": "SELECT PARSE_JSON('{\"x\": \"hello\"}'):x LIKE 'hello'",
      "expected": "SELECT GET_PATH(PARSE_JSON('{\"x\": \"hello\"}'), 'x') LIKE 'hello'"
    },
    {
      "sql": "SELECT data:x LIKE 'hello' FROM some_table",
      "expected": "SELECT GET_PATH(data, 'x') LIKE 'hello' FROM some_table"
    },
    {
      "sql": "SELECT SUM({ fn CONVERT(123, SQL_DOUBLE) })",
      "expected": "SELECT SUM(CAST(123 AS DOUBLE))"
    },
    {
      "sql": "SELECT SUM({ fn CONVERT(123, SQL_VARCHAR) })",
      "expected": "SELECT SUM(CAST(123 AS VARCHAR))"
    },
    {
      "sql": "SELECT TIMESTAMPFROMPARTS(d, t)",
      "expected": "SELECT TIMESTAMP_FROM_PARTS(d, t)"
    },
    {
      "sql": "SELECT v:attr[0].name FROM vartab",
      "expected": "SELECT GET_PATH(v, 'attr[0].name') FROM vartab"
    },
    {
      "sql": "SELECT v:\"fruit\" FROM vartab",
      "expected": "SELECT GET_PATH(v, 'fruit') FROM vartab"
    },
    {
      "sql": "v:attr[0]:name",
      "expected": "GET_PATH(v, 'attr[0].name')"
    },
    {
      "sql": "a.x:from.b:c.d::int",
      "expected": "CAST(GET_PATH(a.x, 'from.b.c.d') AS INT)"
    },
    {
      "sql": "SELECT PARSE_JSON('{\"food\":{\"fruit\":\"banana\"}}'):food.fruit::VARCHAR",
      "expected": "SELECT CAST(GET_PATH(PARSE_JSON('{\"food\":{\"fruit\":\"banana\"}}'), 'food.fruit') AS VARCHAR)"
    },
    {
      "sql": "SELECT * FROM t, UNNEST(x) WITH ORDINALITY",
      "expected": "SELECT * FROM t, TABLE(FLATTEN(INPUT => x)) AS _t0(seq, key, path, index, value, this)"
    },
    {
      "sql": "CREATE TABLE foo (ID INT COMMENT $$some comment$$)",
      "expected": "CREATE TABLE foo (ID INT COMMENT 'some comment')"
    },
    {
      "sql": "SELECT state, city, SUM(retail_price * quantity) AS gross_revenue FROM sales GROUP BY ALL",
      "expected": null
    },
    {
      "sql": "SELECT * FROM foo window",
      "expected": "SELECT * FROM foo AS window"
    },
    {
      "sql": "SELECT RLIKE(a, $$regular expression with \\ characters: \\d{2}-\\d{3}-\\d{4}$$, 'i') FROM log_source",
      "expected": "SELECT REGEXP_LIKE(a, 'regular expression with \\\\ characters: \\\\d{2}-\\\\d{3}-\\\\d{4}', 'i') FROM log_source"
    },
    {
      "sql": "SELECT $$a ' \\ \\t \\x21 z $ $$",
      "expected": "SELECT 'a \\' \\\\ \\\\t \\\\x21 z $ '"
    },
    {
      "sql": "SELECT {'test': 'best'}::VARIANT",
      "expected": "SELECT CAST(OBJECT_CONSTRUCT('test', 'best') AS VARIANT)"
    },
    {
      "sql": "SELECT {fn DAYNAME('2022-5-13')}",
      "expected": "SELECT DAYNAME('2022-5-13')"
    },
    {
      "sql": "SELECT {fn LOG(5)}",
      "expected": "SELECT LN(5)"
    },
    {
      "sql": "SELECT {fn CEILING(5.3)}",
      "expected": "SELECT CEIL(5.3)"
    },
    {
      "sql": "SELECT CEIL(3.14)",
      "expected": null
    },
    {
      "sql": "SELECT CEIL(3.14, 1)",
      "expected": null
    },
    {
      "sql": "CAST(x AS BYTEINT)",
      "expected": "CAST(x AS INT)"
    },
    {
      "sql": "CAST(x AS CHAR VARYING)",
      "expected": "CAST(x AS VARCHAR)"
    },
    {
      "sql": "CAST(x AS CHARACTER VARYING)",
      "expected": "CAST(x AS VARCHAR)"
    },
    {
      "sql": "CAST(x AS NCHAR VARYING)",
      "expected": "CAST(x AS VARCHAR)"
    },
    {
      "sql": "CREATE OR REPLACE TEMPORARY TABLE x (y NUMBER IDENTITY(0, 1))",
      "expected": "CREATE OR REPLACE TEMPORARY TABLE x (y DECIMAL(38, 0) AUTOINCREMENT START 0 INCREMENT 1)"
    },
    {
      "sql": "CREATE TEMPORARY TABLE x (y NUMBER AUTOINCREMENT(0, 1))",
      "expected": "CREATE TEMPORARY TABLE x (y DECIMAL(38, 0) AUTOINCREMENT START 0 INCREMENT 1)"
    },
    {
      "sql": "CREATE OR REPLACE TABLE x (y NUMBER(38, 0) NOT NULL AUTOINCREMENT START 1 INCREMENT 1 ORDER)",
      "expected": "CREATE OR REPLACE TABLE x (y DECIMAL(38, 0) NOT NULL AUTOINCREMENT START 1 INCREMENT 1 ORDER)"
    },
    {
      "sql": "CREATE OR REPLACE TABLE x (y NUMBER(38, 0) NOT NULL AUTOINCREMENT START 1 INCREMENT 1 NOORDER)",
      "expected": "CREATE OR REPLACE TABLE x (y DECIMAL(38, 0) NOT NULL AUTOINCREMENT START 1 INCREMENT 1 NOORDER)"
    },
    {
      "sql": "CREATE TABLE x (y NUMBER IDENTITY START 0 INCREMENT 1)",
      "expected": "CREATE TABLE x (y DECIMAL(38, 0) AUTOINCREMENT START 0 INCREMENT 1)"
    },
    {
      "sql": "ALTER TABLE foo ADD COLUMN id INT identity(1, 1)",
      "expected": "ALTER TABLE foo ADD id INT AUTOINCREMENT START 1 INCREMENT 1"
    },
    {
      "sql": "SELECT DAYOFWEEK('2016-01-02T23:39:20.123-07:00'::TIMESTAMP)",
      "expected": "SELECT DAYOFWEEK(CAST('2016-01-02T23:39:20.123-07:00' AS TIMESTAMP))"
    },
    {
      "sql": "SELECT * FROM xxx WHERE col ilike '%Don''t%'",
      "expected": "SELECT * FROM xxx WHERE col ILIKE '%Don\\'t%'"
    },
    {
      "sql": "SELECT * EXCLUDE a, b FROM xxx",
      "expected": "SELECT * EXCLUDE (a), b FROM xxx"
    },
    {
      "sql": "SELECT * RENAME a AS b, c AS d FROM xxx",
      "expected": "SELECT * RENAME (a AS b), c AS d FROM xxx"
    },
    {
      "sql": "SELECT * FROM xxx, yyy, zzz,",
      "expected": "SELECT * FROM xxx, yyy, zzz"
    },
    {
      "sql": "SELECT * FROM xxx, yyy, zzz, WHERE foo = bar",
      "expected": "SELECT * FROM xxx, yyy, zzz WHERE foo = bar"
    },
    {
      "sql": "SELECT * FROM xxx, yyy, zzz",
      "expected": "SELECT * FROM xxx, yyy, zzz"
    },
    {
      "sql": "SELECT TIMESTAMPNTZFROMPARTS(2013, 4, 5, 12, 00, 00)",
      "expected": "SELECT TIMESTAMP_FROM_PARTS(2013, 4, 5, 12, 00, 00)"
    },
    {
      "sql": "OBJECT_CONSTRUCT(a, b, c, d)",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY_CONSTRUCT('foo')::VARIANT[0]",
      "expected": "SELECT CAST(['foo'] AS VARIANT)[0]"
    },
    {
      "sql": "SELECT UUID_STRING(), UUID_STRING('fe971b24-9572-4005-b22f-351e9c09274d', 'foo')",
      "expected": null
    },
    {
      "sql": "EDITDISTANCE(col1, col2)",
      "expected": null
    },
    {
      "sql": "SELECT BITNOT(a)",
      "expected": null
    },
    {
      "sql": "SELECT BIT_NOT(a)",
      "expected": "SELECT BITNOT(a)"
    },
    {
      "sql": "SELECT BITAND(a, b)",
      "expected": null
    },
    {
      "sql": "SELECT BITAND(a, b, 'LEFT')",
      "expected": null
    },
    {
      "sql": "SELECT BIT_AND(a, b)",
      "expected": "SELECT BITAND(a, b)"
    },
    {
      "sql": "SELECT BIT_AND(a, b, 'LEFT')",
      "expected": "SELECT BITAND(a, b, 'LEFT')"
    },
    {
      "sql": "SELECT BITOR(a, b)",
      "expected": null
    },
    {
      "sql": "SELECT BITOR(a, b, 'LEFT')",
      "expected": null
    },
    {
      "sql": "SELECT BIT_OR(a, b)",
      "expected": "SELECT BITOR(a, b)"
    },
    {
      "sql": "SELECT BIT_OR(a, b, 'RIGHT')",
      "expected": "SELECT BITOR(a, b, 'RIGHT')"
    },
    {
      "sql": "SELECT BITXOR(a, b)",
      "expected": null
    },
    {
      "sql": "SELECT BITXOR(a, b, 'LEFT')",
      "expected": null
    },
    {
      "sql": "SELECT BIT_XOR(a, b)",
      "expected": "SELECT BITXOR(a, b)"
    },
    {
      "sql": "SELECT BIT_XOR(a, b, 'LEFT')",
      "expected": "SELECT BITXOR(a, b, 'LEFT')"
    },
    {
      "sql": "CREATE TABLE t (id INT PRIMARY KEY AUTOINCREMENT)",
      "expected": null
    },
    {
      "sql": "TO_JSON(OBJECT_CONSTRUCT('name', 'Alice'))",
      "expected": null
    },
    {
      "sql": "ALTER TABLE foo ADD col1 VARCHAR(512), col2 VARCHAR(512)",
      "expected": null
    },
    {
      "sql": "ALTER TABLE foo ADD col1 VARCHAR NOT NULL TAG (key1='value_1'), col2 VARCHAR NOT NULL TAG (key2='value_2')",
      "expected": null
    },
    {
      "sql": "ALTER TABLE foo ADD IF NOT EXISTS col1 INT, col2 INT",
      "expected": null
    },
    {
      "sql": "ALTER TABLE foo ADD IF NOT EXISTS col1 INT, IF NOT EXISTS col2 INT",
      "expected": null
    },
    {
      "sql": "ALTER TABLE foo ADD col1 INT, IF NOT EXISTS col2 INT",
      "expected": null
    },
    {
      "sql": "ALTER TABLE IF EXISTS foo ADD IF NOT EXISTS col1 INT",
      "expected": null
    },
    {
      "sql": "SELECT HOUR(CAST('08:50:57' AS TIME))",
      "expected": null
    },
    {
      "sql": "SELECT MINUTE(CAST('08:50:57' AS TIME))",
      "expected": null
    },
    {
      "sql": "SELECT SECOND(CAST('08:50:57' AS TIME))",
      "expected": null
    },
    {
      "sql": "SELECT HOUR(CAST('2024-05-09 08:50:57' AS TIMESTAMP))",
      "expected": null
    },
    {
      "sql": "SELECT MONTHNAME(CAST('2024-05-09' AS DATE))",
      "expected": null
    },
    {
      "sql": "SELECT PREVIOUS_DAY(CAST('2024-05-09' AS DATE), 'MONDAY')",
      "expected": null
    },
    {
      "sql": "SELECT TIME_FROM_PARTS(14, 30, 45)",
      "expected": null
    },
    {
      "sql": "SELECT TIME_FROM_PARTS(14, 30, 45, 123)",
      "expected": null
    },
    {
      "sql": "SELECT MONTHS_BETWEEN(CAST('2019-03-15' AS DATE), CAST('2019-02-15' AS DATE))",
      "expected": null
    },
    {
      "sql": "SELECT MONTHS_BETWEEN(CAST('2019-03-01 02:00:00' AS TIMESTAMP), CAST('2019-02-15 01:00:00' AS TIMESTAMP))",
      "expected": null
    },
    {
      "sql": "SELECT TIME_SLICE(CAST('2024-05-09 08:50:57.891' AS TIMESTAMP), 15, 'MINUTE')",
      "expected": null
    },
    {
      "sql": "SELECT TIME_SLICE(CAST('2024-05-09' AS DATE), 1, 'DAY')",
      "expected": null
    },
    {
      "sql": "SELECT TIME_SLICE(CAST('2024-05-09 08:50:57.891' AS TIMESTAMP), 1, 'HOUR', 'start')",
      "expected": null
    },
    {
      "sql": "SELECT * EXCLUDE foo RENAME bar AS baz FROM tbl",
      "expected": "SELECT * EXCLUDE (foo) RENAME (bar AS baz) FROM tbl"
    },
    {
      "sql": "SELECT LIKE(col, 'pattern')",
      "expected": "SELECT col LIKE 'pattern'"
    },
    {
      "sql": "SELECT ILIKE(col, 'pattern')",
      "expected": "SELECT col ILIKE 'pattern'"
    },
    {
      "sql": "SELECT LIKE(col, 'pattern', '\\\\')",
      "expected": "SELECT col LIKE 'pattern' ESCAPE '\\\\'"
    },
    {
      "sql": "SELECT ILIKE(col, 'pattern', '\\\\')",
      "expected": "SELECT col ILIKE 'pattern' ESCAPE '\\\\'"
    },
    {
      "sql": "SELECT LIKE(col, 'pattern', '!')",
      "expected": "SELECT col LIKE 'pattern' ESCAPE '!'"
    },
    {
      "sql": "SELECT ILIKE(col, 'pattern', '!')",
      "expected": "SELECT col ILIKE 'pattern' ESCAPE '!'"
    },
    {
      "sql": "SELECT BASE64_DECODE_BINARY('SGVsbG8=')",
      "expected": null
    },
    {
      "sql": "SELECT BASE64_DECODE_BINARY('SGVsbG8=')",
      "expected": null
    },
    {
      "sql": "SELECT BASE64_DECODE_STRING('SGVsbG8gV29ybGQ=')",
      "expected": null
    },
    {
      "sql": "SELECT BASE64_DECODE_STRING('SGVsbG8gV29ybGQ=', '+/=')",
      "expected": null
    },
    {
      "sql": "SELECT BASE64_ENCODE('Hello World')",
      "expected": null
    },
    {
      "sql": "SELECT TRY_BASE64_DECODE_BINARY('SGVsbG8=')",
      "expected": null
    },
    {
      "sql": "SELECT TRY_BASE64_DECODE_BINARY('SGVsbG8=', '+/=')",
      "expected": null
    },
    {
      "sql": "SELECT TRY_BASE64_DECODE_STRING('SGVsbG8gV29ybGQ=')",
      "expected": null
    },
    {
      "sql": "SELECT TRY_BASE64_DECODE_STRING('SGVsbG8gV29ybGQ=', '+/=')",
      "expected": null
    },
    {
      "sql": "SELECT TRY_HEX_DECODE_BINARY('48656C6C6F')",
      "expected": null
    },
    {
      "sql": "SELECT TRY_HEX_DECODE_STRING('48656C6C6F')",
      "expected": null
    },
    {
      "sql": "SELECT ARRAY_CONTAINS(1, [1])",
      "expected": null
    },
    {
      "sql": "SYSTIMESTAMP()",
      "expected": "CURRENT_TIMESTAMP()"
    },
    {
      "sql": "GETDATE()",
      "expected": "CURRENT_TIMESTAMP()"
    },
    {
      "sql": "LOCALTIMESTAMP",
      "expected": "CURRENT_TIMESTAMP"
    },
    {
      "sql": "LOCALTIMESTAMP()",
      "expected": "CURRENT_TIMESTAMP()"
    },
    {
      "sql": "LOCALTIMESTAMP(3)",
      "expected": "CURRENT_TIMESTAMP(3)"
    },
    {
      "sql": "SELECT * FROM @\"mystage\"",
      "expected": null
    },
    {
      "sql": "SELECT * FROM @\"myschema\".\"mystage\"/file.gz",
      "expected": null
    },
    {
      "sql": "SELECT * FROM @\"my_DB\".\"schEMA1\".mystage/file.gz",
      "expected": null
    },
    {
      "sql": "SELECT metadata$filename FROM @s1/",
      "expected": null
    },
    {
      "sql": "SELECT * FROM @~",
      "expected": null
    },
    {
      "sql": "SELECT * FROM @~/some/path/to/file.csv",
      "expected": null
    },
    {
      "sql": "SELECT * FROM @mystage",
      "expected": null
    },
    {
      "sql": "SELECT * FROM '@mystage'",
      "expected": null
    },
    {
      "sql": "SELECT * FROM @namespace.mystage/path/to/file.json.gz",
      "expected": null
    },
    {
      "sql": "SELECT * FROM @namespace.%table_name/path/to/file.json.gz",
      "expected": null
    },
    {
      "sql": "SELECT * FROM '@external/location' (FILE_FORMAT => 'path.to.csv')",
      "expected": null
    },
    {
      "sql": "PUT file:///dir/tmp.csv @%table",
      "expected": null
    },
    {
      "sql": "SELECT * FROM (SELECT a FROM @foo)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM (SELECT * FROM '@external/location' (FILE_FORMAT => 'path.to.csv'))",
      "expected": null
    },
    {
      "sql": "SELECT * FROM @foo/bar (FILE_FORMAT => ds_sandbox.test.my_csv_format, PATTERN => 'test') AS bla",
      "expected": null
    },
    {
      "sql": "SELECT t.$1, t.$2 FROM @mystage1 (FILE_FORMAT => 'myformat', PATTERN => '.*data.*[.]csv.gz') AS t",
      "expected": null
    },
    {
      "sql": "SELECT parse_json($1):a.b FROM @mystage2/data1.json.gz",
      "expected": "SELECT GET_PATH(PARSE_JSON($1), 'a.b') FROM @mystage2/data1.json.gz"
    },
    {
      "sql": "SELECT * FROM @mystage t (c1)",
      "expected": "SELECT * FROM @mystage AS t(c1)"
    },
    {
      "sql": "SELECT * FROM @foo/bar (PATTERN => 'test', FILE_FORMAT => ds_sandbox.test.my_csv_format) AS bla",
      "expected": "SELECT * FROM @foo/bar (FILE_FORMAT => ds_sandbox.test.my_csv_format, PATTERN => 'test') AS bla"
    },
    {
      "sql": "SELECT * FROM @test.public.thing/location/somefile.csv( FILE_FORMAT => 'fmt' )",
      "expected": "SELECT * FROM @test.public.thing/location/somefile.csv (FILE_FORMAT => 'fmt')"
    },
    {
      "sql": "SELECT * FROM testtable TABLESAMPLE BERNOULLI (20.3)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM testtable TABLESAMPLE SYSTEM (3) SEED (82)",
      "expected": null
    },
    {
      "sql": "SELECT a FROM test PIVOT(SUM(x) FOR y IN ('z', 'q')) AS x TABLESAMPLE BERNOULLI (0.1)",
      "expected": null
    },
    {
      "sql": "SELECT i, j FROM table1 AS t1 INNER JOIN table2 AS t2 TABLESAMPLE BERNOULLI (50) WHERE t2.j = t1.i",
      "expected": null
    },
    {
      "sql": "SELECT * FROM (SELECT * FROM t1 JOIN t2 ON t1.a = t2.c) TABLESAMPLE BERNOULLI (1)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM testtable TABLESAMPLE (10 ROWS)",
      "expected": "SELECT * FROM testtable TABLESAMPLE BERNOULLI (10 ROWS)"
    },
    {
      "sql": "SELECT * FROM testtable TABLESAMPLE (100)",
      "expected": "SELECT * FROM testtable TABLESAMPLE BERNOULLI (100)"
    },
    {
      "sql": "SELECT * FROM testtable SAMPLE (10)",
      "expected": "SELECT * FROM testtable TABLESAMPLE BERNOULLI (10)"
    },
    {
      "sql": "SELECT * FROM testtable SAMPLE ROW (0)",
      "expected": "SELECT * FROM testtable TABLESAMPLE ROW (0)"
    },
    {
      "sql": "SELECT a FROM test SAMPLE BLOCK (0.5) SEED (42)",
      "expected": "SELECT a FROM test TABLESAMPLE BLOCK (0.5) SEED (42)"
    },
    {
      "sql": "SELECT user_id, value FROM table_name SAMPLE BERNOULLI ($s) SEED (0)",
      "expected": "SELECT user_id, value FROM table_name TABLESAMPLE BERNOULLI ($s) SEED (0)"
    },
    {
      "sql": "SELECT CAST('12:00:00' AS TIME)",
      "expected": null
    },
    {
      "sql": "SELECT DATE_PART(month, a)",
      "expected": null
    },
    {
      "sql": "CAST(a AS TIMESTAMP_NTZ)",
      "expected": "CAST(a AS TIMESTAMPNTZ)"
    },
    {
      "sql": "CAST(a AS TIMESTAMP_LTZ)",
      "expected": "CAST(a AS TIMESTAMPLTZ)"
    },
    {
      "sql": "DATEDIFF(DAY, CAST('2007-12-25' AS DATE), CAST('2008-12-25' AS DATE))",
      "expected": null
    },
    {
      "sql": "TIMEDIFF(DAY, CAST('2007-12-25' AS DATE), CAST('2008-12-25' AS DATE))",
      "expected": "DATEDIFF(DAY, CAST('2007-12-25' AS DATE), CAST('2008-12-25' AS DATE))"
    },
    {
      "sql": "TIMESTAMPDIFF(DAY, CAST('2007-12-25' AS DATE), CAST('2008-12-25' AS DATE))",
      "expected": "DATEDIFF(DAY, CAST('2007-12-25' AS DATE), CAST('2008-12-25' AS DATE))"
    },
    {
      "sql": "DATEADD(y, 5, x)",
      "expected": "DATEADD(YEAR, 5, x)"
    },
    {
      "sql": "DATEADD(y, 5, x)",
      "expected": "DATEADD(YEAR, 5, x)"
    },
    {
      "sql": "DATE_PART(yyy, x)",
      "expected": "DATE_PART(YEAR, x)"
    },
    {
      "sql": "DATE_TRUNC(yr, x)",
      "expected": "DATE_TRUNC('YEAR', x)"
    },
    {
      "sql": "SELECT TO_TIME(x) FROM t",
      "expected": null
    },
    {
      "sql": "SELECT TO_DATE('2019-02-28') + INTERVAL '1 day, 1 year'",
      "expected": "SELECT CAST('2019-02-28' AS DATE) + INTERVAL '1 day, 1 year'"
    },
    {
      "sql": "TRY_TO_DATE('2024-01-31', 'AUTO')",
      "expected": null
    },
    {
      "sql": "SELECT CAST(a AS VARIANT)",
      "expected": null
    },
    {
      "sql": "SELECT CAST(a AS ARRAY)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM my_table AT (STATEMENT => $query_id_var)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM my_table AT (OFFSET => -60 * 5)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM my_table BEFORE (STATEMENT => $query_id_var)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM my_table BEFORE (OFFSET => -60 * 5)",
      "expected": null
    },
    {
      "sql": "CREATE SCHEMA restored_schema CLONE my_schema AT (OFFSET => -3600)",
      "expected": null
    },
    {
      "sql": "CREATE TABLE restored_table CLONE my_table AT (TIMESTAMP => CAST('Sat, 09 May 2015 01:01:00 +0300' AS TIMESTAMPTZ))",
      "expected": null
    },
    {
      "sql": "CREATE DATABASE restored_db CLONE my_db BEFORE (STATEMENT => '8e5d0ca9-005e-44e6-b858-a8f5b37c5726')",
      "expected": null
    },
    {
      "sql": "SELECT * FROM my_table AT (TIMESTAMP => TO_TIMESTAMP(1432669154242, 3))",
      "expected": null
    },
    {
      "sql": "SELECT * FROM my_table AT (OFFSET => -60 * 5) AS T WHERE T.flag = 'valid'",
      "expected": null
    },
    {
      "sql": "SELECT * FROM my_table AT (STATEMENT => '8e5d0ca9-005e-44e6-b858-a8f5b37c5726')",
      "expected": null
    },
    {
      "sql": "SELECT * FROM my_table BEFORE (STATEMENT => '8e5d0ca9-005e-44e6-b858-a8f5b37c5726')",
      "expected": null
    },
    {
      "sql": "SELECT * FROM my_table AT (TIMESTAMP => 'Fri, 01 May 2015 16:20:00 -0700'::timestamp)",
      "expected": "SELECT * FROM my_table AT (TIMESTAMP => CAST('Fri, 01 May 2015 16:20:00 -0700' AS TIMESTAMP))"
    },
    {
      "sql": "SELECT * FROM my_table AT(TIMESTAMP => 'Fri, 01 May 2015 16:20:00 -0700'::timestamp_tz)",
      "expected": "SELECT * FROM my_table AT (TIMESTAMP => CAST('Fri, 01 May 2015 16:20:00 -0700' AS TIMESTAMPTZ))"
    },
    {
      "sql": "SELECT * FROM my_table BEFORE (TIMESTAMP => 'Fri, 01 May 2015 16:20:00 -0700'::timestamp_tz);",
      "expected": "SELECT * FROM my_table BEFORE (TIMESTAMP => CAST('Fri, 01 May 2015 16:20:00 -0700' AS TIMESTAMPTZ))"
    },
    {
      "sql": "\n            SELECT oldt.* , newt.*\n            FROM my_table BEFORE(STATEMENT => '8e5d0ca9-005e-44e6-b858-a8f5b37c5726') AS oldt\n            FULL OUTER JOIN my_table AT(STATEMENT => '8e5d0ca9-005e-44e6-b858-a8f5b37c5726') AS newt\n            ON oldt.id = newt.id\n            WHERE oldt.id IS NULL OR newt.id IS NULL;\n            ",
      "expected": "SELECT oldt.*, newt.* FROM my_table BEFORE (STATEMENT => '8e5d0ca9-005e-44e6-b858-a8f5b37c5726') AS oldt FULL OUTER JOIN my_table AT (STATEMENT => '8e5d0ca9-005e-44e6-b858-a8f5b37c5726') AS newt ON oldt.id = newt.id WHERE oldt.id IS NULL OR newt.id IS NULL"
    },
    {
      "sql": "CREATE OR REPLACE TABLE foo COPY GRANTS USING TEMPLATE (SELECT 1)",
      "expected": null
    },
    {
      "sql": "USE SECONDARY ROLES ALL",
      "expected": null
    },
    {
      "sql": "USE SECONDARY ROLES NONE",
      "expected": null
    },
    {
      "sql": "USE SECONDARY ROLES a, b, c",
      "expected": null
    },
    {
      "sql": "CREATE SECURE VIEW table1 AS (SELECT a FROM table2)",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE VIEW foo (uid) COPY GRANTS AS (SELECT 1)",
      "expected": null
    },
    {
      "sql": "CREATE TABLE geospatial_table (id INT, g GEOGRAPHY)",
      "expected": null
    },
    {
      "sql": "CREATE MATERIALIZED VIEW a COMMENT='...' AS SELECT 1 FROM x",
      "expected": null
    },
    {
      "sql": "CREATE DATABASE mytestdb_clone CLONE mytestdb",
      "expected": null
    },
    {
      "sql": "CREATE SCHEMA mytestschema_clone CLONE testschema",
      "expected": null
    },
    {
      "sql": "CREATE TABLE IDENTIFIER('foo') (COLUMN1 VARCHAR, COLUMN2 VARCHAR)",
      "expected": null
    },
    {
      "sql": "CREATE TABLE IDENTIFIER($foo) (col1 VARCHAR, col2 VARCHAR)",
      "expected": null
    },
    {
      "sql": "CREATE TAG cost_center ALLOWED_VALUES 'a', 'b'",
      "expected": null
    },
    {
      "sql": "CREATE STAGE stage1 FILE_FORMAT='format1'",
      "expected": "CREATE STAGE stage1 FILE_FORMAT=(FORMAT_NAME='format1')"
    },
    {
      "sql": "CREATE STAGE stage1 FILE_FORMAT=(FORMAT_NAME=stage1.format1)",
      "expected": null
    },
    {
      "sql": "CREATE STAGE stage1 FILE_FORMAT=(FORMAT_NAME='stage1.format1')",
      "expected": null
    },
    {
      "sql": "CREATE STAGE stage1 FILE_FORMAT=schema1.format1",
      "expected": "CREATE STAGE stage1 FILE_FORMAT=(FORMAT_NAME=schema1.format1)"
    },
    {
      "sql": "CREATE STAGE s1 URL='s3://bucket-123' FILE_FORMAT=(TYPE='JSON') CREDENTIALS=(aws_key_id='test' aws_secret_key='test')",
      "expected": null
    },
    {
      "sql": "CREATE DYNAMIC TABLE product (pre_tax_profit, taxes, after_tax_profit) TARGET_LAG='20 minutes' WAREHOUSE=mywh AS SELECT revenue - cost, (revenue - cost) * tax_rate, (revenue - cost) * (1.0 - tax_rate) FROM staging_table",
      "expected": null
    },
    {
      "sql": "ALTER TABLE db_name.schmaName.tblName ADD COLUMN_1 VARCHAR NOT NULL TAG (key1='value_1')",
      "expected": null
    },
    {
      "sql": "DROP FUNCTION my_udf (OBJECT(city VARCHAR, zipcode DECIMAL(38, 0), val ARRAY(BOOLEAN)))",
      "expected": null
    },
    {
      "sql": "CREATE TABLE orders_clone_restore CLONE orders AT (TIMESTAMP => TO_TIMESTAMP_TZ('04/05/2013 01:02:03', 'mm/dd/yyyy hh24:mi:ss'))",
      "expected": null
    },
    {
      "sql": "CREATE TABLE orders_clone_restore CLONE orders BEFORE (STATEMENT => '8e5d0ca9-005e-44e6-b858-a8f5b37c5726')",
      "expected": null
    },
    {
      "sql": "CREATE SCHEMA mytestschema_clone_restore CLONE testschema BEFORE (TIMESTAMP => TO_TIMESTAMP(40 * 365 * 86400))",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE TABLE EXAMPLE_DB.DEMO.USERS (ID DECIMAL(38, 0) NOT NULL, PRIMARY KEY (ID), FOREIGN KEY (CITY_CODE) REFERENCES EXAMPLE_DB.DEMO.CITIES (CITY_CODE))",
      "expected": null
    },
    {
      "sql": "CREATE ICEBERG TABLE my_iceberg_table (amount ARRAY(INT)) CATALOG='SNOWFLAKE' EXTERNAL_VOLUME='my_external_volume' BASE_LOCATION='my/relative/path/from/extvol'",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE FUNCTION ibis_udfs.public.object_values(\"obj\" OBJECT) RETURNS ARRAY LANGUAGE JAVASCRIPT RETURNS NULL ON NULL INPUT AS ' return Object.values(obj) '",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE FUNCTION ibis_udfs.public.object_values(\"obj\" OBJECT) RETURNS ARRAY LANGUAGE JAVASCRIPT STRICT AS ' return Object.values(obj) '",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE TABLE TEST (SOME_REF DECIMAL(38, 0) NOT NULL FOREIGN KEY REFERENCES SOME_OTHER_TABLE (ID))",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE FUNCTION my_udf(location OBJECT(city VARCHAR, zipcode DECIMAL(38, 0), val ARRAY(BOOLEAN))) RETURNS VARCHAR AS $$ SELECT 'foo' $$",
      "expected": "CREATE OR REPLACE FUNCTION my_udf(location OBJECT(city VARCHAR, zipcode DECIMAL(38, 0), val ARRAY(BOOLEAN))) RETURNS VARCHAR AS ' SELECT \\'foo\\' '"
    },
    {
      "sql": "CREATE OR REPLACE FUNCTION my_udtf(foo BOOLEAN) RETURNS TABLE(col1 ARRAY(INT)) AS $$ WITH t AS (SELECT CAST([1, 2, 3] AS ARRAY(INT)) AS c) SELECT c FROM t $$",
      "expected": "CREATE OR REPLACE FUNCTION my_udtf(foo BOOLEAN) RETURNS TABLE (col1 ARRAY(INT)) AS ' WITH t AS (SELECT CAST([1, 2, 3] AS ARRAY(INT)) AS c) SELECT c FROM t '"
    },
    {
      "sql": "CREATE SEQUENCE seq1 WITH START=1, INCREMENT=1 ORDER",
      "expected": "CREATE SEQUENCE seq1 START WITH 1 INCREMENT BY 1 ORDER"
    },
    {
      "sql": "CREATE SEQUENCE seq1 WITH START=1 INCREMENT=1 ORDER",
      "expected": "CREATE SEQUENCE seq1 START WITH 1 INCREMENT BY 1 ORDER"
    },
    {
      "sql": "create external table et2(\n  col1 date as (parse_json(metadata$external_table_partition):COL1::date),\n  col2 varchar as (parse_json(metadata$external_table_partition):COL2::varchar),\n  col3 number as (parse_json(metadata$external_table_partition):COL3::number))\n  partition by (col1,col2,col3)\n  location=@s2/logs/\n  partition_type = user_specified\n  file_format = (type = parquet compression = gzip binary_as_text = false)",
      "expected": "CREATE EXTERNAL TABLE et2 (col1 DATE AS (CAST(GET_PATH(PARSE_JSON(metadata$external_table_partition), 'COL1') AS DATE)), col2 VARCHAR AS (CAST(GET_PATH(PARSE_JSON(metadata$external_table_partition), 'COL2') AS VARCHAR)), col3 DECIMAL(38, 0) AS (CAST(GET_PATH(PARSE_JSON(metadata$external_table_partition), 'COL3') AS DECIMAL(38, 0)))) PARTITION BY (col1, col2, col3) LOCATION=@s2/logs/ partition_type=user_specified FILE_FORMAT=(type=parquet compression=gzip binary_as_text=FALSE)"
    },
    {
      "sql": "CREATE TABLE a TAG (key1='value_1', key2='value_2')",
      "expected": null
    },
    {
      "sql": "CALL a.b.c(x, y)",
      "expected": null
    },
    {
      "sql": "CREATE PROCEDURE a.b.c(x INT, y VARIANT) RETURNS OBJECT EXECUTE AS CALLER AS 'BEGIN SELECT 1; END;'",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE('MYTABLE')",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE($MYVAR)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE(?)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE(:BINDING)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE($MYVAR) WHERE COL1 = 10",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE('t1') AS f",
      "expected": null
    },
    {
      "sql": "SELECT * FROM (TABLE('t1') CROSS JOIN TABLE('t2'))",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE('t1'), LATERAL (SELECT * FROM t2)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE('t1') UNION ALL SELECT * FROM TABLE('t2')",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE('t1') TABLESAMPLE BERNOULLI (20.3)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE('MYDB.\"MYSCHEMA\".\"MYTABLE\"')",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE($$MYDB. \"MYSCHEMA\".\"MYTABLE\"$$)",
      "expected": "SELECT * FROM TABLE('MYDB. \"MYSCHEMA\".\"MYTABLE\"')"
    },
    {
      "sql": "DESCRIBE SEMANTIC VIEW TPCDS_SEMANTIC_VIEW_SM",
      "expected": null
    },
    {
      "sql": "DESC SEMANTIC VIEW TPCDS_SEMANTIC_VIEW_SM",
      "expected": "DESCRIBE SEMANTIC VIEW TPCDS_SEMANTIC_VIEW_SM"
    },
    {
      "sql": "REGEXP_SUBSTR_ALL(subject, pattern, pos, occ, param, group)",
      "expected": "REGEXP_EXTRACT_ALL(subject, pattern, pos, occ, param, group)"
    },
    {
      "sql": "SELECT SEARCH((play, line), 'dream')",
      "expected": null
    },
    {
      "sql": "SELECT SEARCH(line, 'king', ANALYZER => 'UNICODE_ANALYZER')",
      "expected": null
    },
    {
      "sql": "SELECT SEARCH(character, 'king queen', SEARCH_MODE => 'AND')",
      "expected": null
    },
    {
      "sql": "SELECT SEARCH(line, 'king', ANALYZER => 'UNICODE_ANALYZER', SEARCH_MODE => 'OR')",
      "expected": null
    },
    {
      "sql": "SELECT SEARCH(line, 'king')",
      "expected": null
    },
    {
      "sql": "SELECT SEARCH(line, 'king', ANALYZER => 'UNICODE_ANALYZER')",
      "expected": null
    },
    {
      "sql": "SELECT SEARCH(character, 'king queen', SEARCH_MODE => 'AND')",
      "expected": null
    },
    {
      "sql": "SELECT SEARCH(line, 'king', SEARCH_MODE => 'AND', ANALYZER => 'PATTERN_ANALYZER')",
      "expected": "SELECT SEARCH(line, 'king', ANALYZER => 'PATTERN_ANALYZER', SEARCH_MODE => 'AND')"
    },
    {
      "sql": "SELECT REGEXP_COUNT('hello world', 'l ')",
      "expected": null
    },
    {
      "sql": "SELECT REGEXP_COUNT('hello world', 'l', 1)",
      "expected": null
    },
    {
      "sql": "SELECT REGEXP_COUNT('hello world', 'l', 1, 'i')",
      "expected": null
    },
    {
      "sql": "SHOW USERS",
      "expected": null
    },
    {
      "sql": "SHOW TERSE USERS",
      "expected": null
    },
    {
      "sql": "SHOW USERS LIKE '_foo%' STARTS WITH 'bar' LIMIT 5 FROM 'baz'",
      "expected": null
    },
    {
      "sql": "SHOW TERSE DATABASES",
      "expected": null
    },
    {
      "sql": "SHOW TERSE DATABASES HISTORY LIKE 'foo' STARTS WITH 'bla' LIMIT 5 FROM 'bob' WITH PRIVILEGES USAGE, MODIFY",
      "expected": null
    },
    {
      "sql": "SHOW FILE FORMATS",
      "expected": null
    },
    {
      "sql": "SHOW FILE FORMATS LIKE 'foo' IN DATABASE db1",
      "expected": null
    },
    {
      "sql": "SHOW FILE FORMATS LIKE 'foo' IN SCHEMA db1.schema1",
      "expected": null
    },
    {
      "sql": "SHOW FUNCTIONS",
      "expected": null
    },
    {
      "sql": "SHOW FUNCTIONS LIKE 'foo' IN CLASS bla",
      "expected": null
    },
    {
      "sql": "SHOW PROCEDURES",
      "expected": null
    },
    {
      "sql": "SHOW PROCEDURES LIKE 'foo' IN APPLICATION app",
      "expected": null
    },
    {
      "sql": "SHOW PROCEDURES LIKE 'foo' IN APPLICATION PACKAGE pkg",
      "expected": null
    },
    {
      "sql": "SHOW STAGES",
      "expected": null
    },
    {
      "sql": "SHOW STAGES LIKE 'foo' IN DATABASE db1",
      "expected": null
    },
    {
      "sql": "SHOW STAGES LIKE 'foo' IN SCHEMA db1.schema1",
      "expected": null
    },
    {
      "sql": "SHOW WAREHOUSES",
      "expected": null
    },
    {
      "sql": "SHOW WAREHOUSES LIKE 'foo' WITH PRIVILEGES USAGE, MODIFY",
      "expected": null
    },
    {
      "sql": "show terse schemas in database db1 starts with 'a' limit 10 from 'b'",
      "expected": "SHOW TERSE SCHEMAS IN DATABASE db1 STARTS WITH 'a' LIMIT 10 FROM 'b'"
    },
    {
      "sql": "show terse objects in schema db1.schema1 starts with 'a' limit 10 from 'b'",
      "expected": "SHOW TERSE OBJECTS IN SCHEMA db1.schema1 STARTS WITH 'a' LIMIT 10 FROM 'b'"
    },
    {
      "sql": "show terse objects in db1.schema1 starts with 'a' limit 10 from 'b'",
      "expected": "SHOW TERSE OBJECTS IN SCHEMA db1.schema1 STARTS WITH 'a' LIMIT 10 FROM 'b'"
    },
    {
      "sql": "SHOW COLUMNS",
      "expected": null
    },
    {
      "sql": "SHOW COLUMNS IN TABLE dt_test",
      "expected": null
    },
    {
      "sql": "SHOW COLUMNS LIKE '_foo%' IN TABLE dt_test",
      "expected": null
    },
    {
      "sql": "SHOW COLUMNS IN VIEW",
      "expected": null
    },
    {
      "sql": "SHOW COLUMNS LIKE '_foo%' IN VIEW dt_test",
      "expected": null
    },
    {
      "sql": "SHOW TABLES LIKE 'line%' IN tpch.public",
      "expected": "SHOW TABLES LIKE 'line%' IN SCHEMA tpch.public"
    },
    {
      "sql": "SHOW TABLES HISTORY IN tpch.public",
      "expected": "SHOW TABLES HISTORY IN SCHEMA tpch.public"
    },
    {
      "sql": "show terse tables in schema db1.schema1 starts with 'a' limit 10 from 'b'",
      "expected": "SHOW TERSE TABLES IN SCHEMA db1.schema1 STARTS WITH 'a' LIMIT 10 FROM 'b'"
    },
    {
      "sql": "show terse tables in db1.schema1 starts with 'a' limit 10 from 'b'",
      "expected": "SHOW TERSE TABLES IN SCHEMA db1.schema1 STARTS WITH 'a' LIMIT 10 FROM 'b'"
    },
    {
      "sql": "SHOW PRIMARY KEYS",
      "expected": null
    },
    {
      "sql": "SHOW PRIMARY KEYS IN ACCOUNT",
      "expected": null
    },
    {
      "sql": "SHOW PRIMARY KEYS IN DATABASE",
      "expected": null
    },
    {
      "sql": "SHOW PRIMARY KEYS IN DATABASE foo",
      "expected": null
    },
    {
      "sql": "SHOW PRIMARY KEYS IN TABLE",
      "expected": null
    },
    {
      "sql": "SHOW PRIMARY KEYS IN TABLE foo",
      "expected": null
    },
    {
      "sql": "SHOW PRIMARY KEYS IN \"TEST\".\"PUBLIC\".\"foo\"",
      "expected": "SHOW PRIMARY KEYS IN TABLE \"TEST\".\"PUBLIC\".\"foo\""
    },
    {
      "sql": "SHOW TERSE PRIMARY KEYS IN \"TEST\".\"PUBLIC\".\"foo\"",
      "expected": "SHOW PRIMARY KEYS IN TABLE \"TEST\".\"PUBLIC\".\"foo\""
    },
    {
      "sql": "SHOW TERSE VIEWS",
      "expected": null
    },
    {
      "sql": "SHOW VIEWS",
      "expected": null
    },
    {
      "sql": "SHOW VIEWS LIKE 'foo%'",
      "expected": null
    },
    {
      "sql": "SHOW VIEWS IN ACCOUNT",
      "expected": null
    },
    {
      "sql": "SHOW VIEWS IN DATABASE",
      "expected": null
    },
    {
      "sql": "SHOW VIEWS IN DATABASE foo",
      "expected": null
    },
    {
      "sql": "SHOW VIEWS IN SCHEMA foo",
      "expected": null
    },
    {
      "sql": "SHOW VIEWS IN foo",
      "expected": "SHOW VIEWS IN SCHEMA foo"
    },
    {
      "sql": "SHOW UNIQUE KEYS",
      "expected": null
    },
    {
      "sql": "SHOW UNIQUE KEYS IN ACCOUNT",
      "expected": null
    },
    {
      "sql": "SHOW UNIQUE KEYS IN DATABASE",
      "expected": null
    },
    {
      "sql": "SHOW UNIQUE KEYS IN DATABASE foo",
      "expected": null
    },
    {
      "sql": "SHOW UNIQUE KEYS IN TABLE",
      "expected": null
    },
    {
      "sql": "SHOW UNIQUE KEYS IN TABLE foo",
      "expected": null
    },
    {
      "sql": "SHOW UNIQUE KEYS IN \"TEST\".\"PUBLIC\".\"foo\"",
      "expected": "SHOW UNIQUE KEYS IN SCHEMA \"TEST\".\"PUBLIC\".\"foo\""
    },
    {
      "sql": "SHOW TERSE UNIQUE KEYS IN \"TEST\".\"PUBLIC\".\"foo\"",
      "expected": "SHOW UNIQUE KEYS IN SCHEMA \"TEST\".\"PUBLIC\".\"foo\""
    },
    {
      "sql": "SHOW IMPORTED KEYS",
      "expected": null
    },
    {
      "sql": "SHOW IMPORTED KEYS IN ACCOUNT",
      "expected": null
    },
    {
      "sql": "SHOW IMPORTED KEYS IN DATABASE",
      "expected": null
    },
    {
      "sql": "SHOW IMPORTED KEYS IN DATABASE foo",
      "expected": null
    },
    {
      "sql": "SHOW IMPORTED KEYS IN TABLE",
      "expected": null
    },
    {
      "sql": "SHOW IMPORTED KEYS IN TABLE foo",
      "expected": null
    },
    {
      "sql": "SHOW IMPORTED KEYS IN \"TEST\".\"PUBLIC\".\"foo\"",
      "expected": "SHOW IMPORTED KEYS IN SCHEMA \"TEST\".\"PUBLIC\".\"foo\""
    },
    {
      "sql": "SHOW TERSE IMPORTED KEYS IN \"TEST\".\"PUBLIC\".\"foo\"",
      "expected": "SHOW IMPORTED KEYS IN SCHEMA \"TEST\".\"PUBLIC\".\"foo\""
    },
    {
      "sql": "SHOW TERSE SEQUENCES",
      "expected": null
    },
    {
      "sql": "SHOW SEQUENCES",
      "expected": null
    },
    {
      "sql": "SHOW SEQUENCES LIKE '_foo%' IN ACCOUNT",
      "expected": null
    },
    {
      "sql": "SHOW SEQUENCES LIKE '_foo%' IN DATABASE",
      "expected": null
    },
    {
      "sql": "SHOW SEQUENCES LIKE '_foo%' IN DATABASE foo",
      "expected": null
    },
    {
      "sql": "SHOW SEQUENCES LIKE '_foo%' IN SCHEMA",
      "expected": null
    },
    {
      "sql": "SHOW SEQUENCES LIKE '_foo%' IN SCHEMA foo",
      "expected": null
    },
    {
      "sql": "SHOW SEQUENCES LIKE '_foo%' IN foo",
      "expected": "SHOW SEQUENCES LIKE '_foo%' IN SCHEMA foo"
    },
    {
      "sql": "SELECT TRY_CAST(x AS DOUBLE)",
      "expected": null
    },
    {
      "sql": "SELECT TRY_CAST(FOO() AS TEXT)",
      "expected": "SELECT TRY_CAST(FOO() AS VARCHAR)"
    },
    {
      "sql": "COPY INTO test (c1) FROM (SELECT $1.c1 FROM @mystage)",
      "expected": null
    },
    {
      "sql": "COPY INTO temp FROM @random_stage/path/ FILE_FORMAT = (TYPE=CSV FIELD_DELIMITER='|' NULL_IF=('str1', 'str2') FIELD_OPTIONALLY_ENCLOSED_BY='\"' TIMESTAMP_FORMAT='TZHTZM YYYY-MM-DD HH24:MI:SS.FF9' DATE_FORMAT='TZHTZM YYYY-MM-DD HH24:MI:SS.FF9' BINARY_FORMAT=BASE64) VALIDATION_MODE = 'RETURN_3_ROWS'",
      "expected": null
    },
    {
      "sql": "COPY INTO load1 FROM @%load1/data1/ CREDENTIALS = (AWS_KEY_ID='id' AWS_SECRET_KEY='key' AWS_TOKEN='token') FILES = ('test1.csv', 'test2.csv') FORCE = TRUE",
      "expected": null
    },
    {
      "sql": "COPY INTO mytable FROM 'azure://myaccount.blob.core.windows.net/mycontainer/data/files' CREDENTIALS = (AZURE_SAS_TOKEN='token') ENCRYPTION = (TYPE='AZURE_CSE' MASTER_KEY='kPx...') FILE_FORMAT = (FORMAT_NAME=my_csv_format)",
      "expected": null
    },
    {
      "sql": "COPY INTO mytable (col1, col2) FROM 's3://mybucket/data/files' STORAGE_INTEGRATION = \"storage\" ENCRYPTION = (TYPE='NONE' MASTER_KEY='key') FILES = ('file1', 'file2') PATTERN = 'pattern' FILE_FORMAT = (FORMAT_NAME=my_csv_format NULL_IF=('')) PARSE_HEADER = TRUE",
      "expected": null
    },
    {
      "sql": "COPY INTO @my_stage/result/data FROM (SELECT * FROM orderstiny) FILE_FORMAT = (TYPE='csv')",
      "expected": null
    },
    {
      "sql": "COPY INTO mytable FILE_FORMAT = (TYPE='csv')",
      "expected": null
    },
    {
      "sql": "COPY INTO MY_DATABASE.MY_SCHEMA.MY_TABLE FROM @MY_DATABASE.MY_SCHEMA.MY_STAGE/my_path FILE_FORMAT = (FORMAT_NAME=MY_DATABASE.MY_SCHEMA.MY_FILE_FORMAT)",
      "expected": null
    },
    {
      "sql": "PUT 'file:///dir/tmp.csv' @\"my_DB\".\"schEMA1\".\"MYstage\"",
      "expected": null
    },
    {
      "sql": "PUT 'file:///dir/tmp.csv' @s1/test",
      "expected": null
    },
    {
      "sql": "PUT file:///dir/tmp.csv @%table",
      "expected": null
    },
    {
      "sql": "PUT file:///dir/tmp.csv @s1/test PARALLEL=1 AUTO_COMPRESS=FALSE source_compression=gzip OVERWRITE=TRUE",
      "expected": null
    },
    {
      "sql": "GET @\"my_DB\".\"schEMA1\".\"MYstage\" 'file:///dir/tmp.csv'",
      "expected": null
    },
    {
      "sql": "GET @%table file:///dir/tmp.csv",
      "expected": null
    },
    {
      "sql": "GET @s1/test file:///dir/tmp.csv PARALLEL=1",
      "expected": null
    },
    {
      "sql": "SELECT $1",
      "expected": null
    },
    {
      "sql": "SELECT $1.elem",
      "expected": null
    },
    {
      "sql": "SELECT $1:a.b",
      "expected": "SELECT GET_PATH($1, 'a.b')"
    },
    {
      "sql": "SELECT t.$23:a.b",
      "expected": "SELECT GET_PATH(t.$23, 'a.b')"
    },
    {
      "sql": "SELECT t.$17:a[0].b[0].c",
      "expected": "SELECT GET_PATH(t.$17, 'a[0].b[0].c')"
    },
    {
      "sql": "ALTER TABLE tbl SET DATA_RETENTION_TIME_IN_DAYS=1",
      "expected": null
    },
    {
      "sql": "ALTER TABLE tbl SET DEFAULT_DDL_COLLATION='test'",
      "expected": null
    },
    {
      "sql": "ALTER TABLE foo SET COMMENT='bar'",
      "expected": null
    },
    {
      "sql": "ALTER TABLE foo SET CHANGE_TRACKING=FALSE",
      "expected": null
    },
    {
      "sql": "ALTER TABLE table1 SET TAG foo.bar = 'baz'",
      "expected": null
    },
    {
      "sql": "ALTER TABLE IF EXISTS foo SET TAG a = 'a', b = 'b', c = 'c'",
      "expected": null
    },
    {
      "sql": "ALTER TABLE tbl SET STAGE_FILE_FORMAT = (TYPE=CSV FIELD_DELIMITER='|' NULL_IF=('') FIELD_OPTIONALLY_ENCLOSED_BY='\"' TIMESTAMP_FORMAT='TZHTZM YYYY-MM-DD HH24:MI:SS.FF9' DATE_FORMAT='TZHTZM YYYY-MM-DD HH24:MI:SS.FF9' BINARY_FORMAT=BASE64)",
      "expected": null
    },
    {
      "sql": "ALTER TABLE tbl SET STAGE_COPY_OPTIONS = (ON_ERROR=SKIP_FILE SIZE_LIMIT=5 PURGE=TRUE MATCH_BY_COLUMN_NAME=CASE_SENSITIVE)",
      "expected": null
    },
    {
      "sql": "ALTER TABLE foo UNSET TAG a, b, c",
      "expected": null
    },
    {
      "sql": "ALTER TABLE foo UNSET DATA_RETENTION_TIME_IN_DAYS, CHANGE_TRACKING",
      "expected": null
    },
    {
      "sql": "ALTER SESSION SET autocommit = FALSE, QUERY_TAG = 'qtag', JSON_INDENT = 1",
      "expected": null
    },
    {
      "sql": "ALTER SESSION UNSET autocommit, QUERY_TAG",
      "expected": null
    },
    {
      "sql": "SELECT C1 FROM t1 CHANGES (INFORMATION => APPEND_ONLY) AT (STREAM => 's1') END (TIMESTAMP => $ts2)",
      "expected": null
    },
    {
      "sql": "SELECT C1 FROM t1 CHANGES (INFORMATION => APPEND_ONLY) BEFORE (STATEMENT => 'STMT_ID') END (TIMESTAMP => $ts2)",
      "expected": null
    },
    {
      "sql": "SELECT 1 FROM some_table CHANGES (INFORMATION => APPEND_ONLY) AT (TIMESTAMP => TO_TIMESTAMP_TZ('2024-07-01 00:00:00+00:00')) END (TIMESTAMP => TO_TIMESTAMP_TZ('2024-07-01 14:28:59.999999+00:00'))",
      "expected": "SELECT 1 FROM some_table CHANGES (INFORMATION => APPEND_ONLY) AT (TIMESTAMP => CAST('2024-07-01 00:00:00+00:00' AS TIMESTAMPTZ)) END (TIMESTAMP => CAST('2024-07-01 14:28:59.999999+00:00' AS TIMESTAMPTZ))"
    },
    {
      "sql": "GRANT ALL PRIVILEGES ON FUNCTION mydb.myschema.ADD5(number) TO ROLE analyst",
      "expected": null
    },
    {
      "sql": "REVOKE ALL PRIVILEGES ON FUNCTION mydb.myschema.ADD5(number) FROM ROLE analyst",
      "expected": null
    },
    {
      "sql": "LISTAGG(data['some_field'], ',')",
      "expected": null
    },
    {
      "sql": "SELECT :1",
      "expected": null
    },
    {
      "sql": "SELECT :1, :2",
      "expected": null
    },
    {
      "sql": "SELECT :1 + :2",
      "expected": null
    },
    {
      "sql": "MAX_BY(DISTINCT selected_col, filtered_col)",
      "expected": null
    },
    {
      "sql": "MIN_BY(DISTINCT selected_col, filtered_col)",
      "expected": null
    },
    {
      "sql": "MAX_BY(selected_col, filtered_col, 5)",
      "expected": null
    },
    {
      "sql": "MIN_BY(selected_col, filtered_col, 3)",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE VIEW FOO (A, B) COPY GRANTS AS SELECT A, B FROM TBL",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE MATERIALIZED VIEW FOO COPY GRANTS (A, B) AS SELECT A, B FROM TBL",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE MATERIALIZED VIEW FOO COPY GRANTS (A, B) COMMENT='foo' TAG (a='b') AS SELECT A, B FROM TBL",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE VIEW FOO (A, B) AS SELECT A, B FROM TBL",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE MATERIALIZED VIEW FOO (A, B) AS SELECT A, B FROM TBL",
      "expected": null
    },
    {
      "sql": "SELECT * FROM SEMANTIC_VIEW(foo METRICS a.b, a.c DIMENSIONS a.b, a.c WHERE a.b > '1995-01-01')",
      "expected": "SELECT\n  *\nFROM SEMANTIC_VIEW(\n  foo\n  METRICS a.b, a.c\n  DIMENSIONS a.b, a.c\n  WHERE a.b > '1995-01-01'\n)"
    },
    {
      "sql": "CREATE SEQUENCE seq  START=5 comment = 'foo' INCREMENT=10",
      "expected": "CREATE SEQUENCE seq COMMENT='foo' START WITH 5 INCREMENT BY 10"
    },
    {
      "sql": "BITMAP_OR_AGG(x)",
      "expected": null
    },
    {
      "sql": "MD5_HEX(col)",
      "expected": "MD5(col)"
    },
    {
      "sql": "MD5(col)",
      "expected": null
    },
    {
      "sql": "MD5_BINARY(col)",
      "expected": null
    },
    {
      "sql": "MD5_NUMBER_LOWER64(col)",
      "expected": null
    },
    {
      "sql": "MD5_NUMBER_UPPER64(col)",
      "expected": null
    },
    {
      "sql": "SELECT model!mladmin",
      "expected": null
    },
    {
      "sql": "SELECT model!PREDICT(1)",
      "expected": null
    },
    {
      "sql": "SELECT m!PREDICT(INPUT_DATA => {*}) AS p FROM tbl",
      "expected": null
    },
    {
      "sql": "SELECT m!PREDICT(INPUT_DATA => {tbl.*}) AS p FROM tbl",
      "expected": null
    },
    {
      "sql": "x.y.z!PREDICT(foo, bar, baz, bla)",
      "expected": null
    },
    {
      "sql": "SELECT * FROM TABLE(model_trained_with_labeled_data!DETECT_ANOMALIES(INPUT_DATA => TABLE(view_with_data_to_analyze), TIMESTAMP_COLNAME => 'date', TARGET_COLNAME => 'sales', CONFIG_OBJECT => OBJECT_CONSTRUCT('prediction_interval', 0.99)))",
      "expected": null
    },
    {
      "sql": "GETBIT(11, 1)",
      "expected": null
    },
    {
      "sql": "TO_BINARY('48454C50', 'HEX')",
      "expected": null
    },
    {
      "sql": "TO_BINARY('48454C50')",
      "expected": null
    },
    {
      "sql": "TO_BINARY('TEST', 'UTF-8')",
      "expected": null
    },
    {
      "sql": "TO_BINARY('SEVMUA==', 'BASE64')",
      "expected": null
    },
    {
      "sql": "TRY_TO_BINARY('48454C50', 'HEX')",
      "expected": null
    },
    {
      "sql": "TRY_TO_BINARY('48454C50')",
      "expected": null
    },
    {
      "sql": "TRY_TO_BINARY('Hello', 'UTF-8')",
      "expected": null
    },
    {
      "sql": "TRY_TO_BINARY('SGVsbG8=', 'BASE64')",
      "expected": null
    },
    {
      "sql": "TRY_TO_BINARY('Hello', 'UTF-16')",
      "expected": null
    },
    {
      "sql": "TIMEADD(HOUR, 2.5, CAST('10:30:00' AS TIME))",
      "expected": null
    },
    {
      "sql": "DATEADD(HOUR, CAST(3.8 AS DECIMAL(10, 2)), CAST('2024-01-01 10:00:00' AS TIMESTAMP))",
      "expected": null
    },
    {
      "sql": "ENCRYPT(value, 'passphrase')",
      "expected": null
    },
    {
      "sql": "ENCRYPT(value, 'passphrase', 'aad')",
      "expected": null
    },
    {
      "sql": "ENCRYPT(value, 'passphrase', 'aad', 'AES-GCM')",
      "expected": null
    },
    {
      "sql": "ENCRYPT_RAW(value, key, iv)",
      "expected": null
    },
    {
      "sql": "ENCRYPT_RAW(value, key, iv, aad)",
      "expected": null
    },
    {
      "sql": "ENCRYPT_RAW(value, key, iv, aad, 'AES-GCM')",
      "expected": null
    },
    {
      "sql": "DECRYPT(encrypted, 'passphrase')",
      "expected": null
    },
    {
      "sql": "DECRYPT(encrypted, 'passphrase', 'aad')",
      "expected": null
    },
    {
      "sql": "DECRYPT(encrypted, 'passphrase', 'aad', 'AES-GCM')",
      "expected": null
    },
    {
      "sql": "DECRYPT_RAW(encrypted, key, iv)",
      "expected": null
    },
    {
      "sql": "DECRYPT_RAW(encrypted, key, iv, aad)",
      "expected": null
    },
    {
      "sql": "DECRYPT_RAW(encrypted, key, iv, aad, 'AES-GCM')",
      "expected": null
    },
    {
      "sql": "DECRYPT_RAW(encrypted, key, iv, aad, 'AES-GCM', aead)",
      "expected": null
    },
    {
      "sql": "TRY_DECRYPT(encrypted, 'passphrase')",
      "expected": null
    },
    {
      "sql": "TRY_DECRYPT(encrypted, 'passphrase', 'aad')",
      "expected": null
    },
    {
      "sql": "TRY_DECRYPT(encrypted, 'passphrase', 'aad', 'AES-GCM')",
      "expected": null
    },
    {
      "sql": "TRY_DECRYPT_RAW(encrypted, key, iv)",
      "expected": null
    },
    {
      "sql": "TRY_DECRYPT_RAW(encrypted, key, iv, aad)",
      "expected": null
    },
    {
      "sql": "TRY_DECRYPT_RAW(encrypted, key, iv, aad, 'AES-GCM')",
      "expected": null
    },
    {
      "sql": "TRY_DECRYPT_RAW(encrypted, key, iv, aad, 'AES-GCM', aead)",
      "expected": null
    },
    {
      "sql": "UPDATE test SET t = 1 FROM t1",
      "expected": null
    },
    {
      "sql": "UPDATE test SET t = 1 FROM t2 JOIN t3 ON t2.id = t3.id",
      "expected": null
    },
    {
      "sql": "UPDATE test SET t = 1 FROM (SELECT id FROM test2) AS t2 JOIN test3 AS t3 ON t2.id = t3.id",
      "expected": null
    },
    {
      "sql": "UPDATE sometesttable u FROM (SELECT 5195 AS new_count, '01bee1e5-0000-d31e-0000-e80ef02b9f27' query_id ) b SET qry_hash_count = new_count WHERE u.sample_query_id  = b.query_id",
      "expected": "UPDATE sometesttable AS u SET qry_hash_count = new_count FROM (SELECT 5195 AS new_count, '01bee1e5-0000-d31e-0000-e80ef02b9f27' AS query_id) AS b WHERE u.sample_query_id = b.query_id"
    },
    {
      "sql": "APPROX_TOP_K(C4, 3, 5)",
      "expected": null
    },
    {
      "sql": "TRY_TO_TIMESTAMP(foo)",
      "expected": null
    },
    {
      "sql": "TRY_TO_TIMESTAMP('12345')",
      "expected": null
    },
    {
      "sql": "TO_DATE('12345')",
      "expected": null
    },
    {
      "sql": "TO_DATE(x)",
      "expected": null
    },
    {
      "sql": "TRY_TO_DATE(x)",
      "expected": null
    },
    {
      "sql": "GET @s1/test 'file:///dir/tmp.csv'",
      "expected": null
    },
    {
      "sql": "GET(foo, bar)",
      "expected": null
    },
    {
      "sql": "SELECT TRY_PARSE_JSON('{\"x: 1}')",
      "expected": null
    },
    {
      "sql": "CREATE WAREHOUSE x",
      "expected": null
    },
    {
      "sql": "CREATE STREAMLIT x",
      "expected": null
    },
    {
      "sql": "CREATE TEMPORARY STAGE stage1 FILE_FORMAT=(TYPE=PARQUET)",
      "expected": null
    },
    {
      "sql": "CREATE OR REPLACE TAG IF NOT EXISTS cost_center COMMENT='cost_center tag'",
      "expected": null
    },
    {
      "sql": "CREATE TEMPORARY FILE FORMAT fileformat1 TYPE=PARQUET COMPRESSION=auto",
      "expected": null
    },
    {
      "sql": "CREATE STORAGE INTEGRATION s3_int\nTYPE=EXTERNAL_STAGE\nSTORAGE_PROVIDER='S3'\nSTORAGE_AWS_ROLE_ARN='arn:aws:iam::001234567890:role/myrole'\nENABLED=TRUE\nSTORAGE_ALLOWED_LOCATIONS=('s3://mybucket1/path1/', 's3://mybucket2/path2/')",
      "expected": null
    },
    {
      "sql": "SELECT number",
      "expected": null
    },
    {
      "sql": "SELECT TO_TIMESTAMP(123.4)",
      "expected": null
    },
    {
      "sql": "SELECT DATE_PART(year FROM CAST('2024-04-08' AS DATE))",
      "expected": "SELECT DATE_PART(year, CAST('2024-04-08' AS DATE))"
    },
    {
      "sql": "SELECT DATE_PART('month' FROM CAST('2024-04-08' AS DATE))",
      "expected": "SELECT DATE_PART('month', CAST('2024-04-08' AS DATE))"
    },
    {
      "sql": "SELECT DATE_PART(day FROM a)",
      "expected": "SELECT DATE_PART(day, a)"
    },
    {
      "sql": "SELECT SEARCH_IP(col, '192.168.0.0')",
      "expected": null
    },
    {
      "sql": "SELECT DATEADD(DAY, -7, DATEADD(t.m, 1, CAST('2023-01-03' AS DATE))) FROM (SELECT 'month' AS m) AS t",
      "expected": null
    },
    {
      "sql": "SELECT FILE_URL FROM DIRECTORY(@mystage) WHERE SIZE > 100000",
      "expected": null
    }
  ],
  "transpilation": [
    {
      "sql": "SELECT BITMAP_BIT_POSITION(10)",
      "read": {},
      "write": {
        "duckdb": "SELECT (CASE WHEN 10 > 0 THEN 10 - 1 ELSE ABS(10) END) % 32768",
        "snowflake": "SELECT BITMAP_BIT_POSITION(10)"
      }
    },
    {
      "sql": "SELECT BITMAP_CONSTRUCT_AGG(v) FROM t",
      "read": {},
      "write": {
        "snowflake": "SELECT BITMAP_CONSTRUCT_AGG(v) FROM t",
        "duckdb": "SELECT (SELECT CASE WHEN l IS NULL OR LENGTH(l) = 0 THEN NULL WHEN LENGTH(l) <> LENGTH(LIST_FILTER(l, __v -> __v BETWEEN 0 AND 32767)) THEN NULL WHEN LENGTH(l) < 5 THEN UNHEX(PRINTF('%04X', LENGTH(l)) || h || REPEAT('00', GREATEST(0, 4 - LENGTH(l)) * 2)) ELSE UNHEX('08000000000000000000' || h) END FROM (SELECT l, COALESCE(LIST_REDUCE(LIST_TRANSFORM(l, __x -> PRINTF('%02X%02X', CAST(__x AS INT) & 255, (CAST(__x AS INT) >> 8) & 255)), (__a, __b) -> __a || __b, ''), '') AS h FROM (SELECT LIST_SORT(LIST_DISTINCT(LIST(v) FILTER(WHERE NOT v IS NULL))) AS l))) FROM t"
      }
    },
    {
      "sql": "SELECT REGR_VALX(y, x)",
      "read": {},
      "write": {
        "snowflake": "SELECT REGR_VALX(y, x)",
        "duckdb": "SELECT CASE WHEN y IS NULL THEN CAST(NULL AS DOUBLE) ELSE x END"
      }
    },
    {
      "sql": "SELECT REGR_VALY(y, x)",
      "read": {},
      "write": {
        "snowflake": "SELECT REGR_VALY(y, x)",
        "duckdb": "SELECT CASE WHEN x IS NULL THEN CAST(NULL AS DOUBLE) ELSE y END"
      }
    },
    {
      "sql": "SELECT IFF(x > 5, 10, 20)",
      "read": {},
      "write": {
        "snowflake": "SELECT IFF(x > 5, 10, 20)",
        "duckdb": "SELECT CASE WHEN x > 5 THEN 10 ELSE 20 END"
      }
    },
    {
      "sql": "SELECT IFF(col IS NULL, 0, col)",
      "read": {},
      "write": {
        "snowflake": "SELECT IFF(col IS NULL, 0, col)",
        "duckdb": "SELECT CASE WHEN col IS NULL THEN 0 ELSE col END"
      }
    },
    {
      "sql": "SELECT VAR_SAMP(x)",
      "read": {},
      "write": {
        "snowflake": "SELECT VARIANCE(x)",
        "duckdb": "SELECT VARIANCE(x)",
        "postgres": "SELECT VAR_SAMP(x)"
      }
    },
    {
      "sql": "SELECT GREATEST(1, 2)",
      "read": {},
      "write": {
        "snowflake": "SELECT GREATEST(1, 2)",
        "duckdb": "SELECT CASE WHEN 1 IS NULL OR 2 IS NULL THEN NULL ELSE GREATEST(1, 2) END"
      }
    },
    {
      "sql": "SELECT GREATEST_IGNORE_NULLS(1, 2)",
      "read": {},
      "write": {
        "snowflake": "SELECT GREATEST_IGNORE_NULLS(1, 2)",
        "duckdb": "SELECT GREATEST(1, 2)"
      }
    },
    {
      "sql": "SELECT LEAST(1, 2)",
      "read": {},
      "write": {
        "snowflake": "SELECT LEAST(1, 2)",
        "duckdb": "SELECT CASE WHEN 1 IS NULL OR 2 IS NULL THEN NULL ELSE LEAST(1, 2) END"
      }
    },
    {
      "sql": "SELECT LEAST_IGNORE_NULLS(1, 2)",
      "read": {},
      "write": {
        "snowflake": "SELECT LEAST_IGNORE_NULLS(1, 2)",
        "duckdb": "SELECT LEAST(1, 2)"
      }
    },
    {
      "sql": "SELECT VAR_POP(x)",
      "read": {},
      "write": {
        "snowflake": "SELECT VARIANCE_POP(x)",
        "duckdb": "SELECT VAR_POP(x)",
        "postgres": "SELECT VAR_POP(x)"
      }
    },
    {
      "sql": "SELECT SKEW(a)",
      "read": {
        "duckdb": "SELECT SKEWNESS(a)",
        "spark": "SELECT SKEWNESS(a)",
        "trino": "SELECT SKEWNESS(a)"
      },
      "write": {
        "snowflake": "SELECT SKEW(a)",
        "duckdb": "SELECT SKEWNESS(a)",
        "spark": "SELECT SKEWNESS(a)",
        "trino": "SELECT SKEWNESS(a)"
      }
    },
    {
      "sql": "IS_NULL_VALUE(x)",
      "read": {},
      "write": {
        "duckdb": "JSON_TYPE(x) = 'NULL'",
        "snowflake": "IS_NULL_VALUE(x)"
      }
    },
    {
      "sql": "SELECT RANDSTR(10, 123)",
      "read": {},
      "write": {
        "snowflake": "SELECT RANDSTR(10, 123)",
        "duckdb": "SELECT (SELECT LISTAGG(SUBSTRING('0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz', 1 + CAST(FLOOR(random_value * 62) AS INT), 1), '') FROM (SELECT (ABS(HASH(i + 123)) % 1000) / 1000.0 AS random_value FROM RANGE(10) AS t(i)))"
      }
    },
    {
      "sql": "SELECT RANDSTR(10, RANDOM(123))",
      "read": {},
      "write": {
        "snowflake": "SELECT RANDSTR(10, RANDOM(123))",
        "duckdb": "SELECT (SELECT LISTAGG(SUBSTRING('0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz', 1 + CAST(FLOOR(random_value * 62) AS INT), 1), '') FROM (SELECT (ABS(HASH(i + 123)) % 1000) / 1000.0 AS random_value FROM RANGE(10) AS t(i)))"
      }
    },
    {
      "sql": "SELECT RANDSTR(10, RANDOM())",
      "read": {},
      "write": {
        "snowflake": "SELECT RANDSTR(10, RANDOM())",
        "duckdb": "SELECT (SELECT LISTAGG(SUBSTRING('0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz', 1 + CAST(FLOOR(random_value * 62) AS INT), 1), '') FROM (SELECT (ABS(HASH(i + RANDOM())) % 1000) / 1000.0 AS random_value FROM RANGE(10) AS t(i)))"
      }
    },
    {
      "sql": "SELECT BOOLNOT(0)",
      "read": {},
      "write": {
        "snowflake": "SELECT BOOLNOT(0)",
        "duckdb": "SELECT NOT (0)"
      }
    },
    {
      "sql": "SELECT ZIPF(1, 10, 1234)",
      "read": {},
      "write": {
        "duckdb": "SELECT (WITH rand AS (SELECT (ABS(HASH(1234)) % 1000000) / 1000000.0 AS r), weights AS (SELECT i, 1.0 / POWER(i, 1) AS w FROM RANGE(1, 10 + 1) AS t(i)), cdf AS (SELECT i, SUM(w) OVER (ORDER BY i NULLS FIRST) / SUM(w) OVER () AS p FROM weights) SELECT MIN(i) FROM cdf WHERE p >= (SELECT r FROM rand))",
        "snowflake": "SELECT ZIPF(1, 10, 1234)"
      }
    },
    {
      "sql": "SELECT ZIPF(2, 100, RANDOM())",
      "read": {},
      "write": {
        "duckdb": "SELECT (WITH rand AS (SELECT RANDOM() AS r), weights AS (SELECT i, 1.0 / POWER(i, 2) AS w FROM RANGE(1, 100 + 1) AS t(i)), cdf AS (SELECT i, SUM(w) OVER (ORDER BY i NULLS FIRST) / SUM(w) OVER () AS p FROM weights) SELECT MIN(i) FROM cdf WHERE p >= (SELECT r FROM rand))",
        "snowflake": "SELECT ZIPF(2, 100, RANDOM())"
      }
    },
    {
      "sql": "TRY_TO_BOOLEAN('true')",
      "read": {},
      "write": {
        "snowflake": "TRY_TO_BOOLEAN('true')",
        "duckdb": "CASE WHEN UPPER(CAST('true' AS TEXT)) = 'ON' THEN TRUE WHEN UPPER(CAST('true' AS TEXT)) = 'OFF' THEN FALSE ELSE TRY_CAST('true' AS BOOLEAN) END"
      }
    },
    {
      "sql": "TRY_TO_DOUBLE('123.456')",
      "read": {},
      "write": {
        "snowflake": "TRY_TO_DOUBLE('123.456')",
        "duckdb": "TRY_CAST('123.456' AS DOUBLE)"
      }
    },
    {
      "sql": "TRY_TO_DOUBLE('-4.56E-03', 'S9.99EEEE')",
      "read": {},
      "write": {
        "snowflake": "TRY_TO_DOUBLE('-4.56E-03', 'S9.99EEEE')"
      }
    },
    {
      "sql": "TRY_TO_TIME('12:30:00')",
      "read": {},
      "write": {
        "snowflake": "TRY_CAST('12:30:00' AS TIME)",
        "duckdb": "TRY_CAST('12:30:00' AS TIME)"
      }
    },
    {
      "sql": "TRY_TO_TIMESTAMP('2024-01-15 12:30:00')",
      "read": {},
      "write": {
        "snowflake": "TRY_CAST('2024-01-15 12:30:00' AS TIMESTAMP)",
        "duckdb": "TRY_CAST('2024-01-15 12:30:00' AS TIMESTAMP)"
      }
    },
    {
      "sql": "SELECT DAYOFWEEKISO('2024-01-15'::DATE)",
      "read": {},
      "write": {
        "snowflake": "SELECT DAYOFWEEKISO(CAST('2024-01-15' AS DATE))",
        "duckdb": "SELECT ISODOW(CAST('2024-01-15' AS DATE))"
      }
    },
    {
      "sql": "SELECT YEAROFWEEK('2024-12-31'::DATE)",
      "read": {},
      "write": {
        "snowflake": "SELECT YEAROFWEEK(CAST('2024-12-31' AS DATE))",
        "duckdb": "SELECT EXTRACT(ISOYEAR FROM CAST('2024-12-31' AS DATE))"
      }
    },
    {
      "sql": "SELECT YEAROFWEEKISO('2024-12-31'::DATE)",
      "read": {},
      "write": {
        "snowflake": "SELECT YEAROFWEEKISO(CAST('2024-12-31' AS DATE))",
        "duckdb": "SELECT EXTRACT(ISOYEAR FROM CAST('2024-12-31' AS DATE))"
      }
    },
    {
      "sql": "SELECT WEEKISO('2024-01-15'::DATE)",
      "read": {},
      "write": {
        "snowflake": "SELECT WEEKISO(CAST('2024-01-15' AS DATE))",
        "duckdb": "SELECT WEEKOFYEAR(CAST('2024-01-15' AS DATE))"
      }
    },
    {
      "sql": "SELECT LTRIM(RTRIM(col)) FROM t1",
      "read": {},
      "write": {
        "duckdb": "SELECT LTRIM(RTRIM(col)) FROM t1",
        "snowflake": "SELECT LTRIM(RTRIM(col)) FROM t1"
      }
    },
    {
      "sql": "SELECT value['x'] AS x FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 'x')])) AS _t0(seq, key, path, index, value, this)",
      "read": {
        "bigquery": "SELECT x FROM UNNEST([STRUCT('x' AS x)])",
        "snowflake": "SELECT value['x'] AS x FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 'x')])) AS _t0(seq, key, path, index, value, this)"
      },
      "write": {}
    },
    {
      "sql": "SELECT value['x'] AS x, value['y'] AS y, value['z'] AS z FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 1, 'y', 2, 'z', 3)])) AS _t0(seq, key, path, index, value, this)",
      "read": {
        "bigquery": "SELECT x, y, z FROM UNNEST([STRUCT(1 AS x, 2 AS y, 3 AS z)])",
        "snowflake": "SELECT value['x'] AS x, value['y'] AS y, value['z'] AS z FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 1, 'y', 2, 'z', 3)])) AS _t0(seq, key, path, index, value, this)"
      },
      "write": {}
    },
    {
      "sql": "SELECT u1['x'] AS x, u2['y'] AS y FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 1)])) AS _t0(seq, key, path, index, u1, this) CROSS JOIN TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('y', 2)])) AS _t1(seq, key, path, index, u2, this)",
      "read": {
        "bigquery": "SELECT u1.x, u2.y FROM UNNEST([STRUCT(1 AS x)]) AS u1, UNNEST([STRUCT(2 AS y)]) AS u2",
        "snowflake": "SELECT u1['x'] AS x, u2['y'] AS y FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 1)])) AS _t0(seq, key, path, index, u1, this) CROSS JOIN TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('y', 2)])) AS _t1(seq, key, path, index, u2, this)"
      },
      "write": {}
    },
    {
      "sql": "SELECT t.id, value['name'] AS name, value['age'] AS age FROM t CROSS JOIN TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('name', 'John', 'age', 30)])) AS _t0(seq, key, path, index, value, this)",
      "read": {
        "bigquery": "SELECT t.id, name, age FROM t, UNNEST([STRUCT('John' AS name, 30 AS age)])",
        "snowflake": "SELECT t.id, value['name'] AS name, value['age'] AS age FROM t CROSS JOIN TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('name', 'John', 'age', 30)])) AS _t0(seq, key, path, index, value, this)"
      },
      "write": {}
    },
    {
      "sql": "SELECT value FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 1)])) AS _t0(seq, key, path, index, value, this)",
      "read": {
        "bigquery": "SELECT value FROM UNNEST([STRUCT(1 AS x)]) AS value",
        "snowflake": "SELECT value FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 1)])) AS _t0(seq, key, path, index, value, this)"
      },
      "write": {}
    },
    {
      "sql": "SELECT t.col1, value['field1'] AS field1, other_col, value['field2'] AS field2 FROM t CROSS JOIN TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('field1', 'a', 'field2', 'b')])) AS _t0(seq, key, path, index, value, this)",
      "read": {
        "bigquery": "SELECT t.col1, field1, other_col, field2 FROM t, UNNEST([STRUCT('a' AS field1, 'b' AS field2)])",
        "snowflake": "SELECT t.col1, value['field1'] AS field1, other_col, value['field2'] AS field2 FROM t CROSS JOIN TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('field1', 'a', 'field2', 'b')])) AS _t0(seq, key, path, index, value, this)"
      },
      "write": {}
    },
    {
      "sql": "SELECT * FROM (SELECT value['x'] AS x FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 'value')])) AS _t0(seq, key, path, index, value, this))",
      "read": {
        "bigquery": "SELECT * FROM (SELECT x FROM UNNEST([STRUCT('value' AS x)]))",
        "snowflake": "SELECT * FROM (SELECT value['x'] AS x FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 'value')])) AS _t0(seq, key, path, index, value, this))"
      },
      "write": {}
    },
    {
      "sql": "SELECT value FROM TABLE(FLATTEN(INPUT => [1, 2, 3])) AS _t0(seq, key, path, index, value, this)",
      "read": {
        "bigquery": "SELECT value FROM UNNEST([1, 2, 3]) AS value",
        "snowflake": "SELECT value FROM TABLE(FLATTEN(INPUT => [1, 2, 3])) AS _t0(seq, key, path, index, value, this)"
      },
      "write": {}
    },
    {
      "sql": "SELECT * FROM t1 AS t1 CROSS JOIN t2 AS t2 LEFT JOIN t3 AS t3 ON t1.a = t3.i",
      "read": {
        "bigquery": "SELECT * FROM t1 AS t1, t2 AS t2 LEFT JOIN t3 AS t3 ON t1.a = t3.i",
        "snowflake": "SELECT * FROM t1 AS t1 CROSS JOIN t2 AS t2 LEFT JOIN t3 AS t3 ON t1.a = t3.i"
      },
      "write": {}
    },
    {
      "sql": "SELECT value['x'] AS x, yval, zval FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 'x', 'y', ['y1', 'y2', 'y3'], 'z', ['z1', 'z2', 'z3'])])) AS _t0(seq, key, path, index, value, this) CROSS JOIN TABLE(FLATTEN(INPUT => value['y'])) AS _t1(seq, key, path, index, yval, this) CROSS JOIN TABLE(FLATTEN(INPUT => value['z'])) AS _t2(seq, key, path, index, zval, this)",
      "read": {
        "bigquery": "SELECT x, yval, zval FROM UNNEST([STRUCT('x' AS x, ['y1', 'y2', 'y3'] AS y, ['z1', 'z2', 'z3'] AS z)]), UNNEST(y) AS yval, UNNEST(z) AS zval",
        "snowflake": "SELECT value['x'] AS x, yval, zval FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('x', 'x', 'y', ['y1', 'y2', 'y3'], 'z', ['z1', 'z2', 'z3'])])) AS _t0(seq, key, path, index, value, this) CROSS JOIN TABLE(FLATTEN(INPUT => value['y'])) AS _t1(seq, key, path, index, yval, this) CROSS JOIN TABLE(FLATTEN(INPUT => value['z'])) AS _t2(seq, key, path, index, zval, this)"
      },
      "write": {}
    },
    {
      "sql": "SELECT _u['foo'] AS foo, bar, baz FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('foo', 'x', 'bars', ['y', 'z'], 'bazs', ['w'])])) AS _t0(seq, key, path, index, _u, this) CROSS JOIN TABLE(FLATTEN(INPUT => _u['bars'])) AS _t1(seq, key, path, index, bar, this) CROSS JOIN TABLE(FLATTEN(INPUT => _u['bazs'])) AS _t2(seq, key, path, index, baz, this)",
      "read": {
        "bigquery": "SELECT _u.foo, bar, baz FROM UNNEST([struct('x' AS foo, ['y', 'z'] AS bars, ['w'] AS bazs)]) AS _u, UNNEST(_u.bars) AS bar, UNNEST(_u.bazs) AS baz"
      },
      "write": {}
    },
    {
      "sql": "SELECT _u, _u['foo'] AS foo, _u['bar'] AS bar FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('foo', 'x', 'bar', 'y')])) AS _t0(seq, key, path, index, _u, this)",
      "read": {
        "bigquery": "select _u, _u.foo, _u.bar from unnest([struct('x' as foo, 'y' AS bar)]) as _u"
      },
      "write": {}
    },
    {
      "sql": "SELECT _u['foo'][0].bar FROM TABLE(FLATTEN(INPUT => [OBJECT_CONSTRUCT('foo', [OBJECT_CONSTRUCT('bar', 1)])])) AS _t0(seq, key, path, index, _u, this)",
      "read": {
        "bigquery": "select _u.foo[0].bar from unnest([struct([struct(1 as bar)] as foo)]) as _u"
      },
      "write": {}
    },
    {
      "sql": "SELECT ARRAY_INTERSECTION([1, 2], [2, 3])",
      "read": {},
      "write": {
        "snowflake": "SELECT ARRAY_INTERSECTION([1, 2], [2, 3])",
        "starrocks": "SELECT ARRAY_INTERSECT([1, 2], [2, 3])"
      }
    },
    {
      "sql": "CREATE TABLE test_table (id NUMERIC NOT NULL AUTOINCREMENT)",
      "read": {},
      "write": {
        "duckdb": "CREATE TABLE test_table (id DECIMAL(38, 0) NOT NULL)",
        "snowflake": "CREATE TABLE test_table (id DECIMAL(38, 0) NOT NULL AUTOINCREMENT)"
      }
    },
    {
      "sql": "SELECT TO_TIMESTAMP('2025-01-16 14:45:30.123', 'yyyy-mm-DD hh24:mi:ss.ff6')",
      "read": {},
      "write": {
        "snowflake": "SELECT TO_TIMESTAMP('2025-01-16 14:45:30.123', 'yyyy-mm-DD hh24:mi:ss.ff6')"
      }
    },
    {
      "sql": "ARRAY_CONSTRUCT_COMPACT(1, null, 2)",
      "read": {},
      "write": {
        "spark": "ARRAY_COMPACT(ARRAY(1, NULL, 2))",
        "snowflake": "ARRAY_CONSTRUCT_COMPACT(1, NULL, 2)"
      }
    },
    {
      "sql": "ARRAY_COMPACT(arr)",
      "read": {
        "spark": "ARRAY_COMPACT(arr)",
        "databricks": "ARRAY_COMPACT(arr)",
        "snowflake": "ARRAY_COMPACT(arr)"
      },
      "write": {
        "spark": "ARRAY_COMPACT(arr)",
        "databricks": "ARRAY_COMPACT(arr)"
      }
    },
    {
      "sql": "OBJECT_CONSTRUCT_KEEP_NULL('key_1', 'one', 'key_2', NULL)",
      "read": {
        "bigquery": "JSON_OBJECT(['key_1', 'key_2'], ['one', NULL])",
        "duckdb": "JSON_OBJECT('key_1', 'one', 'key_2', NULL)"
      },
      "write": {
        "bigquery": "JSON_OBJECT('key_1', 'one', 'key_2', NULL)",
        "duckdb": "JSON_OBJECT('key_1', 'one', 'key_2', NULL)",
        "snowflake": "OBJECT_CONSTRUCT_KEEP_NULL('key_1', 'one', 'key_2', NULL)"
      }
    },
    {
      "sql": "SELECT TIME_FROM_PARTS(12, 34, 56)",
      "read": {},
      "write": {
        "duckdb": "SELECT MAKE_TIME(12, 34, 56)",
        "snowflake": "SELECT TIME_FROM_PARTS(12, 34, 56)"
      }
    },
    {
      "sql": "SELECT TIME_FROM_PARTS(12, 34, 56, 987654321)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST('00:00:00' AS TIME) + INTERVAL ((12 * 3600) + (34 * 60) + 56 + (987654321 / 1000000000.0)) SECOND",
        "snowflake": "SELECT TIME_FROM_PARTS(12, 34, 56, 987654321)"
      }
    },
    {
      "sql": "SELECT TIME_FROM_PARTS(0, 100, 0)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST('00:00:00' AS TIME) + INTERVAL ((0 * 3600) + (100 * 60) + 0) SECOND",
        "snowflake": "SELECT TIME_FROM_PARTS(0, 100, 0)"
      }
    },
    {
      "sql": "SELECT TIMESTAMP_FROM_PARTS(2013, 4, 5, 12, 00, 00)",
      "read": {
        "duckdb": "SELECT MAKE_TIMESTAMP(2013, 4, 5, 12, 00, 00)",
        "snowflake": "SELECT TIMESTAMP_NTZ_FROM_PARTS(2013, 4, 5, 12, 00, 00)"
      },
      "write": {
        "duckdb": "SELECT MAKE_TIMESTAMP(2013, 4, 5, 12, 00, 00)",
        "snowflake": "SELECT TIMESTAMP_FROM_PARTS(2013, 4, 5, 12, 00, 00)"
      }
    },
    {
      "sql": "SELECT TIMESTAMP_FROM_PARTS(TO_DATE('2023-06-15'), TO_TIME('14:30:45'))",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST('2023-06-15' AS DATE) + CAST('14:30:45' AS TIME)",
        "snowflake": "SELECT TIMESTAMP_FROM_PARTS(CAST('2023-06-15' AS DATE), CAST('14:30:45' AS TIME))"
      }
    },
    {
      "sql": "SELECT TIMESTAMP_NTZ_FROM_PARTS(TO_DATE('2023-06-15'), TO_TIME('14:30:45'))",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST('2023-06-15' AS DATE) + CAST('14:30:45' AS TIME)",
        "snowflake": "SELECT TIMESTAMP_FROM_PARTS(CAST('2023-06-15' AS DATE), CAST('14:30:45' AS TIME))"
      }
    },
    {
      "sql": "SELECT TIMESTAMP_LTZ_FROM_PARTS(2023, 6, 15, 14, 30, 45)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(MAKE_TIMESTAMP(2023, 6, 15, 14, 30, 45) AS TIMESTAMPTZ)",
        "snowflake": "SELECT TIMESTAMP_LTZ_FROM_PARTS(2023, 6, 15, 14, 30, 45)"
      }
    },
    {
      "sql": "SELECT TIMESTAMP_TZ_FROM_PARTS(2023, 6, 15, 14, 30, 45, 0, 'America/Los_Angeles')",
      "read": {},
      "write": {
        "duckdb": "SELECT MAKE_TIMESTAMP(2023, 6, 15, 14, 30, 45) AT TIME ZONE 'America/Los_Angeles'",
        "snowflake": "SELECT TIMESTAMP_TZ_FROM_PARTS(2023, 6, 15, 14, 30, 45, 0, 'America/Los_Angeles')"
      }
    },
    {
      "sql": "WITH vartab(v) AS (select parse_json('[{\"attr\": [{\"name\": \"banana\"}]}]')) SELECT GET_PATH(v, '[0].attr[0].name') FROM vartab",
      "read": {},
      "write": {
        "bigquery": "WITH vartab AS (SELECT PARSE_JSON('[{\"attr\": [{\"name\": \"banana\"}]}]') AS v) SELECT JSON_EXTRACT(v, '$[0].attr[0].name') FROM vartab",
        "duckdb": "WITH vartab(v) AS (SELECT JSON('[{\"attr\": [{\"name\": \"banana\"}]}]')) SELECT v -> '$[0].attr[0].name' FROM vartab",
        "mysql": "WITH vartab(v) AS (SELECT '[{\"attr\": [{\"name\": \"banana\"}]}]') SELECT JSON_EXTRACT(v, '$[0].attr[0].name') FROM vartab",
        "presto": "WITH vartab(v) AS (SELECT JSON_PARSE('[{\"attr\": [{\"name\": \"banana\"}]}]')) SELECT JSON_EXTRACT(v, '$[0].attr[0].name') FROM vartab",
        "snowflake": "WITH vartab(v) AS (SELECT PARSE_JSON('[{\"attr\": [{\"name\": \"banana\"}]}]')) SELECT GET_PATH(v, '[0].attr[0].name') FROM vartab",
        "tsql": "WITH vartab(v) AS (SELECT '[{\"attr\": [{\"name\": \"banana\"}]}]') SELECT ISNULL(JSON_QUERY(v, '$[0].attr[0].name'), JSON_VALUE(v, '$[0].attr[0].name')) FROM vartab"
      }
    },
    {
      "sql": "WITH vartab(v) AS (select parse_json('{\"attr\": [{\"name\": \"banana\"}]}')) SELECT GET_PATH(v, 'attr[0].name') FROM vartab",
      "read": {},
      "write": {
        "bigquery": "WITH vartab AS (SELECT PARSE_JSON('{\"attr\": [{\"name\": \"banana\"}]}') AS v) SELECT JSON_EXTRACT(v, '$.attr[0].name') FROM vartab",
        "duckdb": "WITH vartab(v) AS (SELECT JSON('{\"attr\": [{\"name\": \"banana\"}]}')) SELECT v -> '$.attr[0].name' FROM vartab",
        "mysql": "WITH vartab(v) AS (SELECT '{\"attr\": [{\"name\": \"banana\"}]}') SELECT JSON_EXTRACT(v, '$.attr[0].name') FROM vartab",
        "presto": "WITH vartab(v) AS (SELECT JSON_PARSE('{\"attr\": [{\"name\": \"banana\"}]}')) SELECT JSON_EXTRACT(v, '$.attr[0].name') FROM vartab",
        "snowflake": "WITH vartab(v) AS (SELECT PARSE_JSON('{\"attr\": [{\"name\": \"banana\"}]}')) SELECT GET_PATH(v, 'attr[0].name') FROM vartab",
        "tsql": "WITH vartab(v) AS (SELECT '{\"attr\": [{\"name\": \"banana\"}]}') SELECT ISNULL(JSON_QUERY(v, '$.attr[0].name'), JSON_VALUE(v, '$.attr[0].name')) FROM vartab"
      }
    },
    {
      "sql": "SELECT PARSE_JSON('{\"fruit\":\"banana\"}'):fruit",
      "read": {},
      "write": {
        "bigquery": "SELECT JSON_EXTRACT(PARSE_JSON('{\"fruit\":\"banana\"}'), '$.fruit')",
        "databricks": "SELECT PARSE_JSON('{\"fruit\":\"banana\"}'):fruit",
        "duckdb": "SELECT JSON('{\"fruit\":\"banana\"}') -> '$.fruit'",
        "mysql": "SELECT JSON_EXTRACT('{\"fruit\":\"banana\"}', '$.fruit')",
        "presto": "SELECT JSON_EXTRACT(JSON_PARSE('{\"fruit\":\"banana\"}'), '$.fruit')",
        "snowflake": "SELECT GET_PATH(PARSE_JSON('{\"fruit\":\"banana\"}'), 'fruit')",
        "spark": "SELECT GET_JSON_OBJECT('{\"fruit\":\"banana\"}', '$.fruit')",
        "tsql": "SELECT ISNULL(JSON_QUERY('{\"fruit\":\"banana\"}', '$.fruit'), JSON_VALUE('{\"fruit\":\"banana\"}', '$.fruit'))"
      }
    },
    {
      "sql": "SELECT TO_ARRAY(['test'])",
      "read": {},
      "write": {
        "snowflake": "SELECT TO_ARRAY(['test'])",
        "spark": "SELECT ARRAY('test')"
      }
    },
    {
      "sql": "SELECT TO_ARRAY(['test'])",
      "read": {},
      "write": {
        "snowflake": "SELECT TO_ARRAY(['test'])",
        "spark": "SELECT ARRAY('test')"
      }
    },
    {
      "sql": "WITH t(x, \"value\") AS (SELECT [1, 2, 3], 1) SELECT IFF(_u.pos = _u_2.pos_2, _u_2.\"value\", NULL) AS \"value\" FROM t CROSS JOIN TABLE(FLATTEN(INPUT => ARRAY_GENERATE_RANGE(0, (GREATEST(ARRAY_SIZE(t.x)) - 1) + 1))) AS _u(seq, key, path, index, pos, this) CROSS JOIN TABLE(FLATTEN(INPUT => t.x)) AS _u_2(seq, key, path, pos_2, \"value\", this) WHERE _u.pos = _u_2.pos_2 OR (_u.pos > (ARRAY_SIZE(t.x) - 1) AND _u_2.pos_2 = (ARRAY_SIZE(t.x) - 1))",
      "read": {
        "duckdb": "WITH t(x, \"value\") AS (SELECT [1,2,3], 1) SELECT UNNEST(t.x) AS \"value\" FROM t"
      },
      "write": {}
    },
    {
      "sql": "SELECT { 'Manitoba': 'Winnipeg', 'foo': 'bar' } AS province_capital",
      "read": {},
      "write": {
        "duckdb": "SELECT {'Manitoba': 'Winnipeg', 'foo': 'bar'} AS province_capital",
        "snowflake": "SELECT OBJECT_CONSTRUCT('Manitoba', 'Winnipeg', 'foo', 'bar') AS province_capital",
        "spark": "SELECT STRUCT('Winnipeg' AS Manitoba, 'bar' AS foo) AS province_capital"
      }
    },
    {
      "sql": "SELECT COLLATE('B', 'und:ci')",
      "read": {},
      "write": {
        "bigquery": "SELECT COLLATE('B', 'und:ci')",
        "snowflake": "SELECT COLLATE('B', 'und:ci')"
      }
    },
    {
      "sql": "SELECT To_BOOLEAN('T')",
      "read": {},
      "write": {
        "duckdb": "SELECT CASE WHEN UPPER(CAST('T' AS TEXT)) = 'ON' THEN TRUE WHEN UPPER(CAST('T' AS TEXT)) = 'OFF' THEN FALSE WHEN ISNAN(TRY_CAST('T' AS REAL)) OR ISINF(TRY_CAST('T' AS REAL)) THEN ERROR('TO_BOOLEAN: Non-numeric values NaN and INF are not supported') ELSE CAST('T' AS BOOLEAN) END"
      }
    },
    {
      "sql": "SELECT * FROM x START WITH a = b CONNECT BY c = PRIOR d",
      "read": {
        "oracle": "SELECT * FROM x START WITH a = b CONNECT BY c = PRIOR d"
      },
      "write": {
        "oracle": "SELECT * FROM x START WITH a = b CONNECT BY c = PRIOR d",
        "snowflake": "SELECT * FROM x START WITH a = b CONNECT BY c = PRIOR d"
      }
    },
    {
      "sql": "SELECT INSERT(a, 0, 0, 'b')",
      "read": {
        "mysql": "SELECT INSERT(a, 0, 0, 'b')",
        "snowflake": "SELECT INSERT(a, 0, 0, 'b')",
        "tsql": "SELECT STUFF(a, 0, 0, 'b')"
      },
      "write": {
        "mysql": "SELECT INSERT(a, 0, 0, 'b')",
        "snowflake": "SELECT INSERT(a, 0, 0, 'b')",
        "tsql": "SELECT STUFF(a, 0, 0, 'b')"
      }
    },
    {
      "sql": "ARRAY_GENERATE_RANGE(0, 3)",
      "read": {},
      "write": {
        "bigquery": "GENERATE_ARRAY(0, 3 - 1)",
        "postgres": "GENERATE_SERIES(0, 3 - 1)",
        "presto": "SEQUENCE(0, 3 - 1)",
        "snowflake": "ARRAY_GENERATE_RANGE(0, (3 - 1) + 1)"
      }
    },
    {
      "sql": "ARRAY_GENERATE_RANGE(0, 3 + 1)",
      "read": {
        "bigquery": "GENERATE_ARRAY(0, 3)",
        "postgres": "GENERATE_SERIES(0, 3)",
        "presto": "SEQUENCE(0, 3)"
      },
      "write": {}
    },
    {
      "sql": "SELECT DATE_PART('year', TIMESTAMP '2020-01-01')",
      "read": {},
      "write": {
        "hive": "SELECT EXTRACT(year FROM CAST('2020-01-01' AS TIMESTAMP))",
        "snowflake": "SELECT DATE_PART('year', CAST('2020-01-01' AS TIMESTAMP))",
        "spark": "SELECT EXTRACT(year FROM CAST('2020-01-01' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT * FROM (VALUES (0) foo(bar))",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM (VALUES (0)) AS foo(bar)"
      }
    },
    {
      "sql": "OBJECT_CONSTRUCT('a', b, 'c', d)",
      "read": {},
      "write": {
        "duckdb": "{'a': b, 'c': d}",
        "snowflake": "OBJECT_CONSTRUCT('a', b, 'c', d)"
      }
    },
    {
      "sql": "SELECT i, p, o FROM qt QUALIFY ROW_NUMBER() OVER (PARTITION BY p ORDER BY o) = 1",
      "read": {},
      "write": {
        "databricks": "SELECT i, p, o FROM qt QUALIFY ROW_NUMBER() OVER (PARTITION BY p ORDER BY o NULLS LAST) = 1",
        "hive": "SELECT i, p, o FROM (SELECT i, p, o, ROW_NUMBER() OVER (PARTITION BY p ORDER BY o NULLS LAST) AS _w FROM qt) AS _t WHERE _w = 1",
        "presto": "SELECT i, p, o FROM (SELECT i, p, o, ROW_NUMBER() OVER (PARTITION BY p ORDER BY o) AS _w FROM qt) AS _t WHERE _w = 1",
        "snowflake": "SELECT i, p, o FROM qt QUALIFY ROW_NUMBER() OVER (PARTITION BY p ORDER BY o) = 1",
        "spark": "SELECT i, p, o FROM (SELECT i, p, o, ROW_NUMBER() OVER (PARTITION BY p ORDER BY o NULLS LAST) AS _w FROM qt) AS _t WHERE _w = 1",
        "sqlite": "SELECT i, p, o FROM (SELECT i, p, o, ROW_NUMBER() OVER (PARTITION BY p ORDER BY o NULLS LAST) AS _w FROM qt) AS _t WHERE _w = 1",
        "trino": "SELECT i, p, o FROM (SELECT i, p, o, ROW_NUMBER() OVER (PARTITION BY p ORDER BY o) AS _w FROM qt) AS _t WHERE _w = 1"
      }
    },
    {
      "sql": "SELECT BOOLOR_AGG(c1), BOOLOR_AGG(c2) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT BOOL_OR(CAST(c1 AS BOOLEAN)), BOOL_OR(CAST(c2 AS BOOLEAN)) FROM test",
        "oracle": "SELECT MAX(c1), MAX(c2) FROM test",
        "postgres": "SELECT BOOL_OR(c1), BOOL_OR(c2) FROM test",
        "snowflake": "SELECT BOOLOR_AGG(c1), BOOLOR_AGG(c2) FROM test",
        "spark": "SELECT BOOL_OR(c1), BOOL_OR(c2) FROM test",
        "sqlite": "SELECT MAX(c1), MAX(c2) FROM test"
      }
    },
    {
      "sql": "SELECT BOOLAND_AGG(c1), BOOLAND_AGG(c2) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT BOOL_AND(CAST(c1 AS BOOLEAN)), BOOL_AND(CAST(c2 AS BOOLEAN)) FROM test",
        "oracle": "SELECT MIN(c1), MIN(c2) FROM test",
        "postgres": "SELECT BOOL_AND(c1), BOOL_AND(c2) FROM test",
        "snowflake": "SELECT BOOLAND_AGG(c1), BOOLAND_AGG(c2) FROM test",
        "spark": "SELECT BOOL_AND(c1), BOOL_AND(c2) FROM test",
        "sqlite": "SELECT MIN(c1), MIN(c2) FROM test",
        "mysql": "SELECT MIN(c1), MIN(c2) FROM test"
      }
    },
    {
      "sql": "SELECT BOOLXOR_AGG(c1) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT COUNT_IF(CAST(c1 AS BOOLEAN)) = 1 FROM test",
        "snowflake": "SELECT BOOLXOR_AGG(c1) FROM test"
      }
    },
    {
      "sql": "TO_CHAR(x, y)",
      "read": {
        "snowflake": "TO_VARCHAR(x, y)"
      },
      "write": {
        "databricks": "TO_CHAR(x, y)",
        "drill": "TO_CHAR(x, y)",
        "oracle": "TO_CHAR(x, y)",
        "postgres": "TO_CHAR(x, y)",
        "snowflake": "TO_CHAR(x, y)",
        "teradata": "TO_CHAR(x, y)"
      }
    },
    {
      "sql": "SQUARE(x)",
      "read": {},
      "write": {
        "bigquery": "POWER(x, 2)",
        "clickhouse": "POWER(x, 2)",
        "databricks": "POWER(x, 2)",
        "drill": "POW(x, 2)",
        "duckdb": "POWER(x, 2)",
        "hive": "POWER(x, 2)",
        "mysql": "POWER(x, 2)",
        "oracle": "POWER(x, 2)",
        "postgres": "POWER(x, 2)",
        "presto": "POWER(x, 2)",
        "redshift": "POWER(x, 2)",
        "snowflake": "POWER(x, 2)",
        "spark": "POWER(x, 2)",
        "sqlite": "POWER(x, 2)",
        "starrocks": "POWER(x, 2)",
        "teradata": "x ** 2",
        "trino": "POWER(x, 2)",
        "tsql": "POWER(x, 2)"
      }
    },
    {
      "sql": "POWER(x, 2)",
      "read": {
        "oracle": "SQUARE(x)",
        "snowflake": "SQUARE(x)",
        "tsql": "SQUARE(x)"
      },
      "write": {}
    },
    {
      "sql": "DIV0(foo, bar)",
      "read": {},
      "write": {
        "snowflake": "IFF(bar = 0 AND NOT foo IS NULL, 0, foo / bar)",
        "sqlite": "IIF(bar = 0 AND NOT foo IS NULL, 0, CAST(foo AS REAL) / bar)",
        "presto": "IF(bar = 0 AND NOT foo IS NULL, 0, CAST(foo AS DOUBLE) / bar)",
        "spark": "IF(bar = 0 AND NOT foo IS NULL, 0, foo / bar)",
        "hive": "IF(bar = 0 AND NOT foo IS NULL, 0, foo / bar)",
        "duckdb": "CASE WHEN bar = 0 AND NOT foo IS NULL THEN 0 ELSE foo / bar END"
      }
    },
    {
      "sql": "DIV0(a - b, c - d)",
      "read": {},
      "write": {
        "snowflake": "IFF((c - d) = 0 AND NOT (a - b) IS NULL, 0, (a - b) / (c - d))",
        "sqlite": "IIF((c - d) = 0 AND NOT (a - b) IS NULL, 0, CAST((a - b) AS REAL) / (c - d))",
        "presto": "IF((c - d) = 0 AND NOT (a - b) IS NULL, 0, CAST((a - b) AS DOUBLE) / (c - d))",
        "spark": "IF((c - d) = 0 AND NOT (a - b) IS NULL, 0, (a - b) / (c - d))",
        "hive": "IF((c - d) = 0 AND NOT (a - b) IS NULL, 0, (a - b) / (c - d))",
        "duckdb": "CASE WHEN (c - d) = 0 AND NOT (a - b) IS NULL THEN 0 ELSE (a - b) / (c - d) END"
      }
    },
    {
      "sql": "DIV0NULL(foo, bar)",
      "read": {},
      "write": {
        "snowflake": "IFF(bar = 0 OR bar IS NULL, 0, foo / bar)",
        "sqlite": "IIF(bar = 0 OR bar IS NULL, 0, CAST(foo AS REAL) / bar)",
        "presto": "IF(bar = 0 OR bar IS NULL, 0, CAST(foo AS DOUBLE) / bar)",
        "spark": "IF(bar = 0 OR bar IS NULL, 0, foo / bar)",
        "hive": "IF(bar = 0 OR bar IS NULL, 0, foo / bar)",
        "duckdb": "CASE WHEN bar = 0 OR bar IS NULL THEN 0 ELSE foo / bar END"
      }
    },
    {
      "sql": "DIV0NULL(a - b, c - d)",
      "read": {},
      "write": {
        "snowflake": "IFF((c - d) = 0 OR (c - d) IS NULL, 0, (a - b) / (c - d))",
        "sqlite": "IIF((c - d) = 0 OR (c - d) IS NULL, 0, CAST((a - b) AS REAL) / (c - d))",
        "presto": "IF((c - d) = 0 OR (c - d) IS NULL, 0, CAST((a - b) AS DOUBLE) / (c - d))",
        "spark": "IF((c - d) = 0 OR (c - d) IS NULL, 0, (a - b) / (c - d))",
        "hive": "IF((c - d) = 0 OR (c - d) IS NULL, 0, (a - b) / (c - d))",
        "duckdb": "CASE WHEN (c - d) = 0 OR (c - d) IS NULL THEN 0 ELSE (a - b) / (c - d) END"
      }
    },
    {
      "sql": "ZEROIFNULL(foo)",
      "read": {},
      "write": {
        "snowflake": "IFF(foo IS NULL, 0, foo)",
        "sqlite": "IIF(foo IS NULL, 0, foo)",
        "presto": "IF(foo IS NULL, 0, foo)",
        "spark": "IF(foo IS NULL, 0, foo)",
        "hive": "IF(foo IS NULL, 0, foo)",
        "duckdb": "CASE WHEN foo IS NULL THEN 0 ELSE foo END"
      }
    },
    {
      "sql": "NULLIFZERO(foo)",
      "read": {},
      "write": {
        "snowflake": "IFF(foo = 0, NULL, foo)",
        "sqlite": "IIF(foo = 0, NULL, foo)",
        "presto": "IF(foo = 0, NULL, foo)",
        "spark": "IF(foo = 0, NULL, foo)",
        "hive": "IF(foo = 0, NULL, foo)",
        "duckdb": "CASE WHEN foo = 0 THEN NULL ELSE foo END"
      }
    },
    {
      "sql": "SELECT * EXCLUDE (a, b) REPLACE (c AS d, E AS F) FROM xxx",
      "read": {
        "duckdb": "SELECT * EXCLUDE (a, b) REPLACE (c AS d, E AS F) FROM xxx"
      },
      "write": {
        "snowflake": "SELECT * EXCLUDE (a, b) REPLACE (c AS d, E AS F) FROM xxx",
        "duckdb": "SELECT * EXCLUDE (a, b) REPLACE (c AS d, E AS F) FROM xxx"
      }
    },
    {
      "sql": "SELECT PARSE_JSON('{\"a\": {\"b c\": \"foo\"}}'):a:\"b c\"",
      "read": {},
      "write": {
        "duckdb": "SELECT JSON('{\"a\": {\"b c\": \"foo\"}}') -> '$.a.\"b c\"'",
        "mysql": "SELECT JSON_EXTRACT('{\"a\": {\"b c\": \"foo\"}}', '$.a.\"b c\"')",
        "snowflake": "SELECT GET_PATH(PARSE_JSON('{\"a\": {\"b c\": \"foo\"}}'), 'a[\"b c\"]')"
      }
    },
    {
      "sql": "SELECT a FROM test WHERE a = 1 GROUP BY a HAVING a = 2 QUALIFY z ORDER BY a LIMIT 10",
      "read": {},
      "write": {
        "bigquery": "SELECT a FROM test WHERE a = 1 GROUP BY a HAVING a = 2 QUALIFY z ORDER BY a NULLS LAST LIMIT 10",
        "snowflake": "SELECT a FROM test WHERE a = 1 GROUP BY a HAVING a = 2 QUALIFY z ORDER BY a LIMIT 10"
      }
    },
    {
      "sql": "SELECT a FROM test AS t QUALIFY ROW_NUMBER() OVER (PARTITION BY a ORDER BY Z) = 1",
      "read": {},
      "write": {
        "bigquery": "SELECT a FROM test AS t QUALIFY ROW_NUMBER() OVER (PARTITION BY a ORDER BY Z NULLS LAST) = 1",
        "snowflake": "SELECT a FROM test AS t QUALIFY ROW_NUMBER() OVER (PARTITION BY a ORDER BY Z) = 1"
      }
    },
    {
      "sql": "SELECT TO_TIMESTAMP(col, 'DD-MM-YYYY HH12:MI:SS') FROM t",
      "read": {},
      "write": {
        "bigquery": "SELECT PARSE_TIMESTAMP('%d-%m-%Y %I:%M:%S', col) FROM t",
        "duckdb": "SELECT STRPTIME(col, '%d-%m-%Y %I:%M:%S') FROM t",
        "snowflake": "SELECT TO_TIMESTAMP(col, 'DD-mm-yyyy hh12:mi:ss') FROM t",
        "spark": "SELECT TO_TIMESTAMP(col, 'dd-MM-yyyy hh:mm:ss') FROM t"
      }
    },
    {
      "sql": "SELECT TO_TIMESTAMP(1659981729)",
      "read": {},
      "write": {
        "bigquery": "SELECT TIMESTAMP_SECONDS(1659981729)",
        "snowflake": "SELECT TO_TIMESTAMP(1659981729)",
        "spark": "SELECT CAST(FROM_UNIXTIME(1659981729) AS TIMESTAMP)",
        "redshift": "SELECT (TIMESTAMP 'epoch' + 1659981729 * INTERVAL '1 SECOND')"
      }
    },
    {
      "sql": "SELECT TO_TIMESTAMP(1659981729000, 3)",
      "read": {},
      "write": {
        "bigquery": "SELECT TIMESTAMP_MILLIS(1659981729000)",
        "snowflake": "SELECT TO_TIMESTAMP(1659981729000, 3)",
        "spark": "SELECT TIMESTAMP_MILLIS(1659981729000)",
        "redshift": "SELECT (TIMESTAMP 'epoch' + (1659981729000 / POWER(10, 3)) * INTERVAL '1 SECOND')"
      }
    },
    {
      "sql": "SELECT TO_TIMESTAMP(16599817290000, 4)",
      "read": {},
      "write": {
        "bigquery": "SELECT TIMESTAMP_SECONDS(CAST(16599817290000 / POWER(10, 4) AS INT64))",
        "snowflake": "SELECT TO_TIMESTAMP(16599817290000, 4)",
        "spark": "SELECT TIMESTAMP_SECONDS(16599817290000 / POWER(10, 4))",
        "redshift": "SELECT (TIMESTAMP 'epoch' + (16599817290000 / POWER(10, 4)) * INTERVAL '1 SECOND')"
      }
    },
    {
      "sql": "SELECT TO_TIMESTAMP('1659981729')",
      "read": {},
      "write": {
        "snowflake": "SELECT TO_TIMESTAMP('1659981729')",
        "spark": "SELECT CAST(FROM_UNIXTIME('1659981729') AS TIMESTAMP)"
      }
    },
    {
      "sql": "SELECT TO_TIMESTAMP(1659981729000000000, 9)",
      "read": {},
      "write": {
        "bigquery": "SELECT TIMESTAMP_SECONDS(CAST(1659981729000000000 / POWER(10, 9) AS INT64))",
        "duckdb": "SELECT TO_TIMESTAMP(1659981729000000000 / POWER(10, 9)) AT TIME ZONE 'UTC'",
        "presto": "SELECT FROM_UNIXTIME(CAST(1659981729000000000 AS DOUBLE) / POW(10, 9))",
        "snowflake": "SELECT TO_TIMESTAMP(1659981729000000000, 9)",
        "spark": "SELECT TIMESTAMP_SECONDS(1659981729000000000 / POWER(10, 9))",
        "redshift": "SELECT (TIMESTAMP 'epoch' + (1659981729000000000 / POWER(10, 9)) * INTERVAL '1 SECOND')"
      }
    },
    {
      "sql": "SELECT TO_TIMESTAMP('2013-04-05 01:02:03')",
      "read": {},
      "write": {
        "bigquery": "SELECT CAST('2013-04-05 01:02:03' AS DATETIME)",
        "snowflake": "SELECT CAST('2013-04-05 01:02:03' AS TIMESTAMP)",
        "spark": "SELECT CAST('2013-04-05 01:02:03' AS TIMESTAMP)"
      }
    },
    {
      "sql": "SELECT TO_TIMESTAMP('04/05/2013 01:02:03', 'mm/DD/yyyy hh24:mi:ss')",
      "read": {
        "bigquery": "SELECT PARSE_TIMESTAMP('%m/%d/%Y %H:%M:%S', '04/05/2013 01:02:03')",
        "duckdb": "SELECT STRPTIME('04/05/2013 01:02:03', '%m/%d/%Y %H:%M:%S')"
      },
      "write": {
        "bigquery": "SELECT PARSE_TIMESTAMP('%m/%d/%Y %T', '04/05/2013 01:02:03')",
        "snowflake": "SELECT TO_TIMESTAMP('04/05/2013 01:02:03', 'mm/DD/yyyy hh24:mi:ss')",
        "spark": "SELECT TO_TIMESTAMP('04/05/2013 01:02:03', 'MM/dd/yyyy HH:mm:ss')"
      }
    },
    {
      "sql": "TO_TIMESTAMP('2024-01-15 3:00 AM', 'YYYY-MM-DD HH12:MI PM')",
      "read": {},
      "write": {
        "duckdb": "STRPTIME('2024-01-15 3:00 AM', '%Y-%m-%d %I:%M %p')",
        "snowflake": "TO_TIMESTAMP('2024-01-15 3:00 AM', 'yyyy-mm-DD hh12:mi pm')"
      }
    },
    {
      "sql": "TO_TIMESTAMP('2024-01-15 3:00 PM', 'YYYY-MM-DD HH12:MI AM')",
      "read": {},
      "write": {
        "duckdb": "STRPTIME('2024-01-15 3:00 PM', '%Y-%m-%d %I:%M %p')",
        "snowflake": "TO_TIMESTAMP('2024-01-15 3:00 PM', 'yyyy-mm-DD hh12:mi pm')"
      }
    },
    {
      "sql": "TO_TIMESTAMP('2024-01-15 3:00 PM', 'YYYY-MM-DD HH12:MI PM')",
      "read": {},
      "write": {
        "duckdb": "STRPTIME('2024-01-15 3:00 PM', '%Y-%m-%d %I:%M %p')",
        "snowflake": "TO_TIMESTAMP('2024-01-15 3:00 PM', 'yyyy-mm-DD hh12:mi pm')"
      }
    },
    {
      "sql": "TO_TIMESTAMP('2024-01-15 3:00 AM', 'YYYY-MM-DD HH12:MI AM')",
      "read": {},
      "write": {
        "duckdb": "STRPTIME('2024-01-15 3:00 AM', '%Y-%m-%d %I:%M %p')",
        "snowflake": "TO_TIMESTAMP('2024-01-15 3:00 AM', 'yyyy-mm-DD hh12:mi pm')"
      }
    },
    {
      "sql": "SELECT IFF(TRUE, 'true', 'false')",
      "read": {},
      "write": {
        "snowflake": "SELECT IFF(TRUE, 'true', 'false')",
        "spark": "SELECT IF(TRUE, 'true', 'false')"
      }
    },
    {
      "sql": "SELECT fname, lname, age FROM person ORDER BY age DESC NULLS FIRST, fname ASC NULLS LAST, lname",
      "read": {},
      "write": {
        "duckdb": "SELECT fname, lname, age FROM person ORDER BY age DESC NULLS FIRST, fname ASC, lname",
        "postgres": "SELECT fname, lname, age FROM person ORDER BY age DESC, fname ASC, lname",
        "presto": "SELECT fname, lname, age FROM person ORDER BY age DESC NULLS FIRST, fname ASC, lname",
        "hive": "SELECT fname, lname, age FROM person ORDER BY age DESC NULLS FIRST, fname ASC NULLS LAST, lname NULLS LAST",
        "spark": "SELECT fname, lname, age FROM person ORDER BY age DESC NULLS FIRST, fname ASC NULLS LAST, lname NULLS LAST",
        "snowflake": "SELECT fname, lname, age FROM person ORDER BY age DESC, fname ASC, lname"
      }
    },
    {
      "sql": "SELECT ARRAY_AGG(DISTINCT a)",
      "read": {},
      "write": {
        "spark": "SELECT COLLECT_LIST(DISTINCT a)",
        "snowflake": "SELECT ARRAY_AGG(DISTINCT a)",
        "duckdb": "SELECT ARRAY_AGG(DISTINCT a) FILTER(WHERE a IS NOT NULL)",
        "presto": "SELECT ARRAY_AGG(DISTINCT a) FILTER(WHERE a IS NOT NULL)"
      }
    },
    {
      "sql": "SELECT ARRAY_AGG(col) WITHIN GROUP (ORDER BY sort_col)",
      "read": {},
      "write": {
        "snowflake": "SELECT ARRAY_AGG(col) WITHIN GROUP (ORDER BY sort_col)",
        "duckdb": "SELECT ARRAY_AGG(col ORDER BY sort_col) FILTER(WHERE col IS NOT NULL)"
      }
    },
    {
      "sql": "SELECT ARRAY_AGG(DISTINCT col) WITHIN GROUP (ORDER BY col DESC)",
      "read": {},
      "write": {
        "snowflake": "SELECT ARRAY_AGG(DISTINCT col) WITHIN GROUP (ORDER BY col DESC)",
        "duckdb": "SELECT ARRAY_AGG(DISTINCT col ORDER BY col DESC NULLS FIRST) FILTER(WHERE col IS NOT NULL)"
      }
    },
    {
      "sql": "ARRAY_TO_STRING(x, '')",
      "read": {
        "duckdb": "ARRAY_TO_STRING(x, '')"
      },
      "write": {
        "spark": "ARRAY_JOIN(x, '')",
        "snowflake": "ARRAY_TO_STRING(x, '')",
        "duckdb": "ARRAY_TO_STRING(x, '')"
      }
    },
    {
      "sql": "TO_ARRAY(x)",
      "read": {},
      "write": {
        "spark": "IF(x IS NULL, NULL, ARRAY(x))",
        "snowflake": "TO_ARRAY(x)"
      }
    },
    {
      "sql": "SELECT ARRAY_UNION_AGG(a)",
      "read": {},
      "write": {
        "snowflake": "SELECT ARRAY_UNION_AGG(a)"
      }
    },
    {
      "sql": "SELECT $$a$$",
      "read": {},
      "write": {
        "snowflake": "SELECT 'a'"
      }
    },
    {
      "sql": "SELECT RLIKE(a, b)",
      "read": {},
      "write": {
        "hive": "SELECT a RLIKE b",
        "snowflake": "SELECT REGEXP_LIKE(a, b)",
        "spark": "SELECT a RLIKE b"
      }
    },
    {
      "sql": "'foo' REGEXP 'bar'",
      "read": {},
      "write": {
        "snowflake": "REGEXP_LIKE('foo', 'bar')",
        "postgres": "'foo' ~ 'bar'",
        "mysql": "REGEXP_LIKE('foo', 'bar')",
        "bigquery": "REGEXP_CONTAINS('foo', 'bar')"
      }
    },
    {
      "sql": "'foo' NOT REGEXP 'bar'",
      "read": {},
      "write": {
        "snowflake": "NOT REGEXP_LIKE('foo', 'bar')",
        "postgres": "NOT 'foo' ~ 'bar'",
        "mysql": "NOT REGEXP_LIKE('foo', 'bar')",
        "bigquery": "NOT REGEXP_CONTAINS('foo', 'bar')"
      }
    },
    {
      "sql": "SELECT a FROM test pivot",
      "read": {},
      "write": {
        "snowflake": "SELECT a FROM test AS pivot"
      }
    },
    {
      "sql": "SELECT a FROM test unpivot",
      "read": {},
      "write": {
        "snowflake": "SELECT a FROM test AS unpivot"
      }
    },
    {
      "sql": "trim(date_column, 'UTC')",
      "read": {},
      "write": {
        "bigquery": "TRIM(date_column, 'UTC')",
        "snowflake": "TRIM(date_column, 'UTC')",
        "postgres": "TRIM('UTC' FROM date_column)"
      }
    },
    {
      "sql": "trim(date_column)",
      "read": {},
      "write": {
        "snowflake": "TRIM(date_column)",
        "bigquery": "TRIM(date_column)"
      }
    },
    {
      "sql": "DECODE(x, a, b, c, d, e)",
      "read": {},
      "write": {
        "duckdb": "CASE WHEN x = a OR (x IS NULL AND a IS NULL) THEN b WHEN x = c OR (x IS NULL AND c IS NULL) THEN d ELSE e END",
        "snowflake": "DECODE(x, a, b, c, d, e)"
      }
    },
    {
      "sql": "DECODE(TRUE, a.b = 'value', 'value')",
      "read": {},
      "write": {
        "duckdb": "CASE WHEN TRUE = (a.b = 'value') OR (TRUE IS NULL AND (a.b = 'value') IS NULL) THEN 'value' END",
        "snowflake": "DECODE(TRUE, a.b = 'value', 'value')"
      }
    },
    {
      "sql": "SELECT BOOLAND(1, -2)",
      "read": {
        "snowflake": "SELECT BOOLAND(1, -2)"
      },
      "write": {
        "snowflake": "SELECT BOOLAND(1, -2)",
        "duckdb": "SELECT ((1) AND (-2))"
      }
    },
    {
      "sql": "SELECT BOOLOR(1, 0)",
      "read": {
        "snowflake": "SELECT BOOLOR(1, 0)"
      },
      "write": {
        "snowflake": "SELECT BOOLOR(1, 0)",
        "duckdb": "SELECT ((1) OR (0))"
      }
    },
    {
      "sql": "SELECT APPROX_PERCENTILE(a, 0.5) FROM t",
      "read": {
        "trino": "SELECT APPROX_PERCENTILE(a, 1, 0.5, 0.001) FROM t",
        "presto": "SELECT APPROX_PERCENTILE(a, 1, 0.5, 0.001) FROM t"
      },
      "write": {
        "trino": "SELECT APPROX_PERCENTILE(a, 0.5) FROM t",
        "presto": "SELECT APPROX_PERCENTILE(a, 0.5) FROM t",
        "snowflake": "SELECT APPROX_PERCENTILE(a, 0.5) FROM t"
      }
    },
    {
      "sql": "SELECT OBJECT_INSERT(OBJECT_INSERT(OBJECT_INSERT(OBJECT_CONSTRUCT('key5', 'value5'), 'key1', 5), 'key2', 2.2), 'key3', 'value3')",
      "read": {},
      "write": {
        "snowflake": "SELECT OBJECT_INSERT(OBJECT_INSERT(OBJECT_INSERT(OBJECT_CONSTRUCT('key5', 'value5'), 'key1', 5), 'key2', 2.2), 'key3', 'value3')",
        "duckdb": "SELECT STRUCT_INSERT(STRUCT_INSERT(STRUCT_INSERT({'key5': 'value5'}, key1 := 5), key2 := 2.2), key3 := 'value3')"
      }
    },
    {
      "sql": "SELECT OBJECT_INSERT(OBJECT_INSERT(OBJECT_INSERT(OBJECT_CONSTRUCT(), 'key1', 5), 'key2', 2.2), 'key3', 'value3')",
      "read": {},
      "write": {
        "snowflake": "SELECT OBJECT_INSERT(OBJECT_INSERT(OBJECT_INSERT(OBJECT_CONSTRUCT(), 'key1', 5), 'key2', 2.2), 'key3', 'value3')",
        "duckdb": "SELECT STRUCT_INSERT(STRUCT_INSERT(STRUCT_PACK(key1 := 5), key2 := 2.2), key3 := 'value3')"
      }
    },
    {
      "sql": "SELECT CONVERT_TIMEZONE('America/New_York', '2024-08-06 09:10:00.000')",
      "read": {},
      "write": {
        "snowflake": "SELECT CONVERT_TIMEZONE('America/New_York', '2024-08-06 09:10:00.000')",
        "spark": "SELECT CONVERT_TIMEZONE('America/New_York', '2024-08-06 09:10:00.000')",
        "databricks": "SELECT CONVERT_TIMEZONE('America/New_York', '2024-08-06 09:10:00.000')",
        "redshift": "SELECT CONVERT_TIMEZONE('America/New_York', '2024-08-06 09:10:00.000')"
      }
    },
    {
      "sql": "SELECT CONVERT_TIMEZONE('America/Los_Angeles', 'America/New_York', '2024-08-06 09:10:00.000')",
      "read": {},
      "write": {
        "snowflake": "SELECT CONVERT_TIMEZONE('America/Los_Angeles', 'America/New_York', '2024-08-06 09:10:00.000')",
        "spark": "SELECT CONVERT_TIMEZONE('America/Los_Angeles', 'America/New_York', '2024-08-06 09:10:00.000')",
        "databricks": "SELECT CONVERT_TIMEZONE('America/Los_Angeles', 'America/New_York', '2024-08-06 09:10:00.000')",
        "redshift": "SELECT CONVERT_TIMEZONE('America/Los_Angeles', 'America/New_York', '2024-08-06 09:10:00.000')",
        "mysql": "SELECT CONVERT_TZ('2024-08-06 09:10:00.000', 'America/Los_Angeles', 'America/New_York')",
        "duckdb": "SELECT CAST('2024-08-06 09:10:00.000' AS TIMESTAMP) AT TIME ZONE 'America/Los_Angeles' AT TIME ZONE 'America/New_York'"
      }
    },
    {
      "sql": "UUID_STRING('fe971b24-9572-4005-b22f-351e9c09274d', 'foo')",
      "read": {
        "snowflake": "UUID_STRING('fe971b24-9572-4005-b22f-351e9c09274d', 'foo')"
      },
      "write": {
        "hive": "UUID()",
        "spark2": "UUID()",
        "spark": "UUID()",
        "databricks": "UUID()",
        "duckdb": "UUID()",
        "presto": "UUID()",
        "trino": "UUID()",
        "postgres": "GEN_RANDOM_UUID()",
        "bigquery": "GENERATE_UUID()"
      }
    },
    {
      "sql": "SELECT TRY_TO_TIMESTAMP('2024-01-15 12:30:00.000')",
      "read": {},
      "write": {
        "snowflake": "SELECT TRY_CAST('2024-01-15 12:30:00.000' AS TIMESTAMP)",
        "duckdb": "SELECT TRY_CAST('2024-01-15 12:30:00.000' AS TIMESTAMP)"
      }
    },
    {
      "sql": "SELECT TRY_TO_TIMESTAMP('invalid')",
      "read": {},
      "write": {
        "snowflake": "SELECT TRY_CAST('invalid' AS TIMESTAMP)",
        "duckdb": "SELECT TRY_CAST('invalid' AS TIMESTAMP)"
      }
    },
    {
      "sql": "SELECT TRY_TO_TIMESTAMP('04/05/2013 01:02:03', 'mm/DD/yyyy hh24:mi:ss')",
      "read": {},
      "write": {
        "snowflake": "SELECT TRY_TO_TIMESTAMP('04/05/2013 01:02:03', 'mm/DD/yyyy hh24:mi:ss')",
        "duckdb": "SELECT CAST(TRY_STRPTIME('04/05/2013 01:02:03', '%m/%d/%Y %H:%M:%S') AS TIMESTAMP)"
      }
    },
    {
      "sql": "EDITDISTANCE(col1, col2, 3)",
      "read": {},
      "write": {
        "bigquery": "EDIT_DISTANCE(col1, col2, max_distance => 3)",
        "postgres": "LEVENSHTEIN_LESS_EQUAL(col1, col2, 3)",
        "snowflake": "EDITDISTANCE(col1, col2, 3)"
      }
    },
    {
      "sql": "SELECT BITNOT(-1)",
      "read": {},
      "write": {
        "duckdb": "SELECT ~(-1)",
        "snowflake": "SELECT BITNOT(-1)"
      }
    },
    {
      "sql": "SELECT BITOR(BITSHIFTLEFT(5, 16), BITSHIFTLEFT(3, 8))",
      "read": {},
      "write": {
        "duckdb": "SELECT (CAST(5 AS INT128) << 16) | (CAST(3 AS INT128) << 8)"
      }
    },
    {
      "sql": "SELECT BITAND(BITSHIFTLEFT(255, 4), BITSHIFTLEFT(15, 2))",
      "read": {},
      "write": {
        "snowflake": "SELECT BITAND(BITSHIFTLEFT(255, 4), BITSHIFTLEFT(15, 2))",
        "duckdb": "SELECT (CAST(255 AS INT128) << 4) & (CAST(15 AS INT128) << 2)"
      }
    },
    {
      "sql": "SELECT BITSHIFTLEFT(255, 4)",
      "read": {},
      "write": {
        "snowflake": "SELECT BITSHIFTLEFT(255, 4)",
        "duckdb": "SELECT CAST(255 AS INT128) << 4"
      }
    },
    {
      "sql": "SELECT BITSHIFTRIGHT(255, 4)",
      "read": {},
      "write": {
        "snowflake": "SELECT BITSHIFTRIGHT(255, 4)",
        "duckdb": "SELECT CAST(255 AS INT128) >> 4"
      }
    },
    {
      "sql": "SELECT BITSHIFTLEFT(X'002A'::BINARY, 1)",
      "read": {},
      "write": {
        "snowflake": "SELECT BITSHIFTLEFT(CAST(x'002A' AS BINARY), 1)",
        "duckdb": "SELECT CAST(CAST(CAST(UNHEX('002A') AS BLOB) AS BIT) << 1 AS BLOB)"
      }
    },
    {
      "sql": "SELECT BITSHIFTRIGHT(X'002A'::BINARY, 1)",
      "read": {},
      "write": {
        "snowflake": "SELECT BITSHIFTRIGHT(CAST(x'002A' AS BINARY), 1)",
        "duckdb": "SELECT CAST(CAST(CAST(UNHEX('002A') AS BLOB) AS BIT) >> 1 AS BLOB)"
      }
    },
    {
      "sql": "OCTET_LENGTH('A')",
      "read": {
        "bigquery": "BYTE_LENGTH('A')",
        "snowflake": "OCTET_LENGTH('A')"
      },
      "write": {}
    },
    {
      "sql": "SELECT HEX_DECODE_BINARY('65')",
      "read": {},
      "write": {
        "bigquery": "SELECT FROM_HEX('65')",
        "duckdb": "SELECT UNHEX('65')",
        "snowflake": "SELECT HEX_DECODE_BINARY('65')"
      }
    },
    {
      "sql": "DAYOFWEEKISO(foo)",
      "read": {
        "snowflake": "DAYOFWEEKISO(foo)",
        "presto": "DAY_OF_WEEK(foo)",
        "trino": "DAY_OF_WEEK(foo)"
      },
      "write": {
        "duckdb": "ISODOW(foo)"
      }
    },
    {
      "sql": "DAYOFWEEKISO(foo)",
      "read": {
        "presto": "DOW(foo)",
        "trino": "DOW(foo)"
      },
      "write": {}
    },
    {
      "sql": "DAYOFYEAR(foo)",
      "read": {
        "presto": "DOY(foo)",
        "trino": "DOY(foo)"
      },
      "write": {
        "snowflake": "DAYOFYEAR(foo)"
      }
    },
    {
      "sql": "SELECT CAST(1 AS DOUBLE), CAST(1 AS DOUBLE)",
      "read": {
        "bigquery": "SELECT CAST(1 AS BIGDECIMAL), CAST(1 AS BIGNUMERIC)"
      },
      "write": {
        "snowflake": "SELECT CAST(1 AS DOUBLE), CAST(1 AS DOUBLE)"
      }
    },
    {
      "sql": "SELECT DATE_PART(WEEKISO, CAST('2013-12-25' AS DATE))",
      "read": {
        "bigquery": "SELECT EXTRACT(ISOWEEK FROM CAST('2013-12-25' AS DATE))",
        "snowflake": "SELECT DATE_PART(WEEKISO, CAST('2013-12-25' AS DATE))"
      },
      "write": {
        "duckdb": "SELECT CAST(STRFTIME(CAST('2013-12-25' AS DATE), '%V') AS INT)"
      }
    },
    {
      "sql": "SELECT DATE_PART(YEAROFWEEK, CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(YEAROFWEEK, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT CAST(STRFTIME(CAST('2026-01-06' AS DATE), '%G') AS INT)"
      }
    },
    {
      "sql": "SELECT DATE_PART(YEAROFWEEKISO, CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(YEAROFWEEKISO, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT CAST(STRFTIME(CAST('2026-01-06' AS DATE), '%G') AS INT)"
      }
    },
    {
      "sql": "SELECT DATE_PART(NANOSECOND, CAST('2026-01-06 11:45:00.123456789' AS TIMESTAMPNTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(NANOSECOND, CAST('2026-01-06 11:45:00.123456789' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT CAST(STRFTIME(CAST(CAST('2026-01-06 11:45:00.123456789' AS TIMESTAMP) AS TIMESTAMP_NS), '%n') AS BIGINT)"
      }
    },
    {
      "sql": "SELECT EXTRACT(YEAR FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(YEAR, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(YEAR FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(QUARTER FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(QUARTER, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(QUARTER FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(MONTH FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(MONTH, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(MONTH FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(WEEK FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(WEEK, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(WEEK FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(WEEKISO FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(WEEKISO, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT CAST(STRFTIME(CAST('2026-01-06 11:45:00' AS TIMESTAMP), '%V') AS INT)"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAY FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAY, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(DAY FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAYOFMONTH FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAY, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(DAY FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAYOFWEEK FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAYOFWEEK, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(DAYOFWEEK FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAYOFWEEKISO FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAYOFWEEKISO, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(ISODOW FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAYOFYEAR FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAYOFYEAR, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(DAYOFYEAR FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(YEAROFWEEK FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(YEAROFWEEK, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT CAST(STRFTIME(CAST('2026-01-06 11:45:00' AS TIMESTAMP), '%G') AS INT)"
      }
    },
    {
      "sql": "SELECT EXTRACT(YEAROFWEEKISO FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(YEAROFWEEKISO, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT CAST(STRFTIME(CAST('2026-01-06 11:45:00' AS TIMESTAMP), '%G') AS INT)"
      }
    },
    {
      "sql": "SELECT EXTRACT(HOUR FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(HOUR, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(HOUR FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(MINUTE FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(MINUTE, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(MINUTE FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(SECOND FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(SECOND, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EXTRACT(SECOND FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(NANOSECOND FROM CAST('2026-01-06 11:45:00.123456789' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(NANOSECOND, CAST('2026-01-06 11:45:00.123456789' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT CAST(STRFTIME(CAST(CAST('2026-01-06 11:45:00.123456789' AS TIMESTAMP) AS TIMESTAMP_NS), '%n') AS BIGINT)"
      }
    },
    {
      "sql": "SELECT EXTRACT(EPOCH_SECOND FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(EPOCH_SECOND, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT CAST(EPOCH(CAST('2026-01-06 11:45:00' AS TIMESTAMP)) AS BIGINT)"
      }
    },
    {
      "sql": "SELECT EXTRACT(EPOCH_MILLISECOND FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(EPOCH_MILLISECOND, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EPOCH_MS(CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(EPOCH_MICROSECOND FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(EPOCH_MICROSECOND, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EPOCH_US(CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(EPOCH_NANOSECOND FROM CAST('2026-01-06 11:45:00' AS TIMESTAMP_NTZ))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(EPOCH_NANOSECOND, CAST('2026-01-06 11:45:00' AS TIMESTAMPNTZ))",
        "duckdb": "SELECT EPOCH_NS(CAST('2026-01-06 11:45:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT EXTRACT(YEAR FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(YEAR, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT EXTRACT(YEAR FROM CAST('2026-01-06' AS DATE))"
      }
    },
    {
      "sql": "SELECT EXTRACT(QUARTER FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(QUARTER, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT EXTRACT(QUARTER FROM CAST('2026-01-06' AS DATE))"
      }
    },
    {
      "sql": "SELECT EXTRACT(MONTH FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(MONTH, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT EXTRACT(MONTH FROM CAST('2026-01-06' AS DATE))"
      }
    },
    {
      "sql": "SELECT EXTRACT(WEEK FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(WEEK, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT EXTRACT(WEEK FROM CAST('2026-01-06' AS DATE))"
      }
    },
    {
      "sql": "SELECT EXTRACT(WEEKISO FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(WEEKISO, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT CAST(STRFTIME(CAST('2026-01-06' AS DATE), '%V') AS INT)"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAY FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAY, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT EXTRACT(DAY FROM CAST('2026-01-06' AS DATE))"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAYOFMONTH FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAY, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT EXTRACT(DAY FROM CAST('2026-01-06' AS DATE))"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAYOFWEEK FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAYOFWEEK, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT EXTRACT(DAYOFWEEK FROM CAST('2026-01-06' AS DATE))"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAYOFWEEKISO FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAYOFWEEKISO, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT EXTRACT(ISODOW FROM CAST('2026-01-06' AS DATE))"
      }
    },
    {
      "sql": "SELECT EXTRACT(DAYOFYEAR FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAYOFYEAR, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT EXTRACT(DAYOFYEAR FROM CAST('2026-01-06' AS DATE))"
      }
    },
    {
      "sql": "SELECT EXTRACT(YEAROFWEEK FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(YEAROFWEEK, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT CAST(STRFTIME(CAST('2026-01-06' AS DATE), '%G') AS INT)"
      }
    },
    {
      "sql": "SELECT EXTRACT(YEAROFWEEKISO FROM CAST('2026-01-06' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(YEAROFWEEKISO, CAST('2026-01-06' AS DATE))",
        "duckdb": "SELECT CAST(STRFTIME(CAST('2026-01-06' AS DATE), '%G') AS INT)"
      }
    },
    {
      "sql": "SELECT EXTRACT(HOUR FROM CAST('11:45:00.123456789' AS TIME))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(HOUR, CAST('11:45:00.123456789' AS TIME))",
        "duckdb": "SELECT EXTRACT(HOUR FROM CAST('11:45:00.123456789' AS TIME))"
      }
    },
    {
      "sql": "SELECT EXTRACT(MINUTE FROM CAST('11:45:00.123456789' AS TIME))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(MINUTE, CAST('11:45:00.123456789' AS TIME))",
        "duckdb": "SELECT EXTRACT(MINUTE FROM CAST('11:45:00.123456789' AS TIME))"
      }
    },
    {
      "sql": "SELECT EXTRACT(SECOND FROM CAST('11:45:00.123456789' AS TIME))",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(SECOND, CAST('11:45:00.123456789' AS TIME))",
        "duckdb": "SELECT EXTRACT(SECOND FROM CAST('11:45:00.123456789' AS TIME))"
      }
    },
    {
      "sql": "SELECT ST_MAKEPOINT(10, 20)",
      "read": {},
      "write": {
        "snowflake": "SELECT ST_MAKEPOINT(10, 20)",
        "starrocks": "SELECT ST_POINT(10, 20)"
      }
    },
    {
      "sql": "LAST_DAY(CAST('2023-04-15' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "LAST_DAY(CAST('2023-04-15' AS DATE))",
        "duckdb": "LAST_DAY(CAST('2023-04-15' AS DATE))"
      }
    },
    {
      "sql": "LAST_DAY(CAST('2023-04-15' AS DATE), MONTH)",
      "read": {},
      "write": {
        "snowflake": "LAST_DAY(CAST('2023-04-15' AS DATE), MONTH)",
        "duckdb": "LAST_DAY(CAST('2023-04-15' AS DATE))"
      }
    },
    {
      "sql": "LAST_DAY(CAST('2024-06-15' AS DATE), YEAR)",
      "read": {},
      "write": {
        "snowflake": "LAST_DAY(CAST('2024-06-15' AS DATE), YEAR)",
        "duckdb": "MAKE_DATE(EXTRACT(YEAR FROM CAST('2024-06-15' AS DATE)), 12, 31)"
      }
    },
    {
      "sql": "LAST_DAY(CAST('2024-01-15' AS DATE), QUARTER)",
      "read": {},
      "write": {
        "snowflake": "LAST_DAY(CAST('2024-01-15' AS DATE), QUARTER)",
        "duckdb": "LAST_DAY(MAKE_DATE(EXTRACT(YEAR FROM CAST('2024-01-15' AS DATE)), EXTRACT(QUARTER FROM CAST('2024-01-15' AS DATE)) * 3, 1))"
      }
    },
    {
      "sql": "LAST_DAY(CAST('2025-12-15' AS DATE), WEEK)",
      "read": {},
      "write": {
        "snowflake": "LAST_DAY(CAST('2025-12-15' AS DATE), WEEK)",
        "duckdb": "CAST(CAST('2025-12-15' AS DATE) + INTERVAL ((7 - EXTRACT(DAYOFWEEK FROM CAST('2025-12-15' AS DATE))) % 7) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT ST_DISTANCE(a, b)",
      "read": {},
      "write": {
        "snowflake": "SELECT ST_DISTANCE(a, b)",
        "starrocks": "SELECT ST_DISTANCE_SPHERE(ST_X(a), ST_Y(a), ST_X(b), ST_Y(b))"
      }
    },
    {
      "sql": "SELECT DATE_PART(DAYOFWEEKISO, foo)",
      "read": {
        "snowflake": "SELECT DATE_PART(WEEKDAY_ISO, foo)"
      },
      "write": {
        "snowflake": "SELECT DATE_PART(DAYOFWEEKISO, foo)",
        "duckdb": "SELECT EXTRACT(ISODOW FROM foo)"
      }
    },
    {
      "sql": "SELECT DATE_PART(DAYOFWEEK_ISO, foo)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(DAYOFWEEKISO, foo)",
        "duckdb": "SELECT EXTRACT(ISODOW FROM foo)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2023-01-31', 1)",
      "read": {},
      "write": {
        "duckdb": "SELECT CASE WHEN LAST_DAY(CAST('2023-01-31' AS TIMESTAMP)) = CAST('2023-01-31' AS TIMESTAMP) THEN LAST_DAY(CAST('2023-01-31' AS TIMESTAMP) + INTERVAL 1 MONTH) ELSE CAST('2023-01-31' AS TIMESTAMP) + INTERVAL 1 MONTH END",
        "snowflake": "SELECT ADD_MONTHS('2023-01-31', 1)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2023-01-31'::date, 1)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2023-01-31' AS DATE)) = CAST('2023-01-31' AS DATE) THEN LAST_DAY(CAST('2023-01-31' AS DATE) + INTERVAL 1 MONTH) ELSE CAST('2023-01-31' AS DATE) + INTERVAL 1 MONTH END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2023-01-31' AS DATE), 1)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2023-01-31'::timestamptz, 1)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2023-01-31' AS TIMESTAMPTZ)) = CAST('2023-01-31' AS TIMESTAMPTZ) THEN LAST_DAY(CAST('2023-01-31' AS TIMESTAMPTZ) + INTERVAL 1 MONTH) ELSE CAST('2023-01-31' AS TIMESTAMPTZ) + INTERVAL 1 MONTH END AS TIMESTAMPTZ)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2023-01-31' AS TIMESTAMPTZ), 1)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2016-05-15'::DATE, 2.7)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2016-05-15' AS DATE)) = CAST('2016-05-15' AS DATE) THEN LAST_DAY(CAST('2016-05-15' AS DATE) + TO_MONTHS(CAST(ROUND(2.7) AS INT))) ELSE CAST('2016-05-15' AS DATE) + TO_MONTHS(CAST(ROUND(2.7) AS INT)) END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2016-05-15' AS DATE), 2.7)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2016-05-15'::DATE, -2.3)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2016-05-15' AS DATE)) = CAST('2016-05-15' AS DATE) THEN LAST_DAY(CAST('2016-05-15' AS DATE) + TO_MONTHS(CAST(ROUND(-2.3) AS INT))) ELSE CAST('2016-05-15' AS DATE) + TO_MONTHS(CAST(ROUND(-2.3) AS INT)) END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2016-05-15' AS DATE), -2.3)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2016-05-15'::DATE, 3.2::DECIMAL(10,2))",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2016-05-15' AS DATE)) = CAST('2016-05-15' AS DATE) THEN LAST_DAY(CAST('2016-05-15' AS DATE) + TO_MONTHS(CAST(ROUND(CAST(3.2 AS DECIMAL(10, 2))) AS INT))) ELSE CAST('2016-05-15' AS DATE) + TO_MONTHS(CAST(ROUND(CAST(3.2 AS DECIMAL(10, 2))) AS INT)) END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2016-05-15' AS DATE), CAST(3.2 AS DECIMAL(10, 2)))"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2016-02-29'::DATE, 1)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2016-02-29' AS DATE)) = CAST('2016-02-29' AS DATE) THEN LAST_DAY(CAST('2016-02-29' AS DATE) + INTERVAL 1 MONTH) ELSE CAST('2016-02-29' AS DATE) + INTERVAL 1 MONTH END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2016-02-29' AS DATE), 1)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2016-05-31'::DATE, 1)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2016-05-31' AS DATE)) = CAST('2016-05-31' AS DATE) THEN LAST_DAY(CAST('2016-05-31' AS DATE) + INTERVAL 1 MONTH) ELSE CAST('2016-05-31' AS DATE) + INTERVAL 1 MONTH END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2016-05-31' AS DATE), 1)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2016-05-31'::DATE, -1)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2016-05-31' AS DATE)) = CAST('2016-05-31' AS DATE) THEN LAST_DAY(CAST('2016-05-31' AS DATE) + INTERVAL (-1) MONTH) ELSE CAST('2016-05-31' AS DATE) + INTERVAL (-1) MONTH END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2016-05-31' AS DATE), -1)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2016-05-15'::DATE, 1)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2016-05-15' AS DATE)) = CAST('2016-05-15' AS DATE) THEN LAST_DAY(CAST('2016-05-15' AS DATE) + INTERVAL 1 MONTH) ELSE CAST('2016-05-15' AS DATE) + INTERVAL 1 MONTH END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2016-05-15' AS DATE), 1)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS(NULL::DATE, 2)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST(NULL AS DATE)) = CAST(NULL AS DATE) THEN LAST_DAY(CAST(NULL AS DATE) + INTERVAL 2 MONTH) ELSE CAST(NULL AS DATE) + INTERVAL 2 MONTH END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST(NULL AS DATE), 2)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2016-05-15'::DATE, NULL)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2016-05-15' AS DATE)) = CAST('2016-05-15' AS DATE) THEN LAST_DAY(CAST('2016-05-15' AS DATE) + INTERVAL (NULL) MONTH) ELSE CAST('2016-05-15' AS DATE) + INTERVAL (NULL) MONTH END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2016-05-15' AS DATE), NULL)"
      }
    },
    {
      "sql": "SELECT ADD_MONTHS('2016-05-15'::DATE, 0)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CASE WHEN LAST_DAY(CAST('2016-05-15' AS DATE)) = CAST('2016-05-15' AS DATE) THEN LAST_DAY(CAST('2016-05-15' AS DATE) + INTERVAL 0 MONTH) ELSE CAST('2016-05-15' AS DATE) + INTERVAL 0 MONTH END AS DATE)",
        "snowflake": "SELECT ADD_MONTHS(CAST('2016-05-15' AS DATE), 0)"
      }
    },
    {
      "sql": "SELECT DAYNAME(TO_DATE('2025-01-15'))",
      "read": {},
      "write": {
        "duckdb": "SELECT STRFTIME(CAST('2025-01-15' AS DATE), '%a')",
        "snowflake": "SELECT DAYNAME(CAST('2025-01-15' AS DATE))"
      }
    },
    {
      "sql": "SELECT DAYNAME(TO_TIMESTAMP('2025-02-28 10:30:45'))",
      "read": {},
      "write": {
        "duckdb": "SELECT STRFTIME(CAST('2025-02-28 10:30:45' AS TIMESTAMP), '%a')",
        "snowflake": "SELECT DAYNAME(CAST('2025-02-28 10:30:45' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT MONTHNAME(TO_DATE('2025-01-15'))",
      "read": {},
      "write": {
        "duckdb": "SELECT STRFTIME(CAST('2025-01-15' AS DATE), '%b')",
        "snowflake": "SELECT MONTHNAME(CAST('2025-01-15' AS DATE))"
      }
    },
    {
      "sql": "SELECT MONTHNAME(TO_TIMESTAMP('2025-02-28 10:30:45'))",
      "read": {},
      "write": {
        "duckdb": "SELECT STRFTIME(CAST('2025-02-28 10:30:45' AS TIMESTAMP), '%b')",
        "snowflake": "SELECT MONTHNAME(CAST('2025-02-28 10:30:45' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT TIME_SLICE(TIMESTAMP '2024-03-15 14:37:42', 1, 'HOUR')",
      "read": {},
      "write": {
        "snowflake": "SELECT TIME_SLICE(CAST('2024-03-15 14:37:42' AS TIMESTAMP), 1, 'HOUR')",
        "duckdb": "SELECT TIME_BUCKET(INTERVAL 1 HOUR, CAST('2024-03-15 14:37:42' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT TIME_SLICE(TIMESTAMP '2024-03-15 14:37:42', 1, 'HOUR', 'END')",
      "read": {},
      "write": {
        "snowflake": "SELECT TIME_SLICE(CAST('2024-03-15 14:37:42' AS TIMESTAMP), 1, 'HOUR', 'END')",
        "duckdb": "SELECT TIME_BUCKET(INTERVAL 1 HOUR, CAST('2024-03-15 14:37:42' AS TIMESTAMP)) + INTERVAL 1 HOUR"
      }
    },
    {
      "sql": "SELECT TIME_SLICE(DATE '2024-03-15', 1, 'DAY')",
      "read": {},
      "write": {
        "snowflake": "SELECT TIME_SLICE(CAST('2024-03-15' AS DATE), 1, 'DAY')",
        "duckdb": "SELECT TIME_BUCKET(INTERVAL 1 DAY, CAST('2024-03-15' AS DATE))"
      }
    },
    {
      "sql": "SELECT TIME_SLICE(DATE '2024-03-15', 1, 'DAY', 'END')",
      "read": {},
      "write": {
        "snowflake": "SELECT TIME_SLICE(CAST('2024-03-15' AS DATE), 1, 'DAY', 'END')",
        "duckdb": "SELECT CAST(TIME_BUCKET(INTERVAL 1 DAY, CAST('2024-03-15' AS DATE)) + INTERVAL 1 DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT TIME_SLICE(TIMESTAMP '2024-03-15 14:37:42', 15, 'MINUTE')",
      "read": {},
      "write": {
        "snowflake": "SELECT TIME_SLICE(CAST('2024-03-15 14:37:42' AS TIMESTAMP), 15, 'MINUTE')",
        "duckdb": "SELECT TIME_BUCKET(INTERVAL 15 MINUTE, CAST('2024-03-15 14:37:42' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT TIME_SLICE(TIMESTAMP '2024-03-15 14:37:42', 1, 'QUARTER')",
      "read": {},
      "write": {
        "snowflake": "SELECT TIME_SLICE(CAST('2024-03-15 14:37:42' AS TIMESTAMP), 1, 'QUARTER')",
        "duckdb": "SELECT TIME_BUCKET(INTERVAL 1 QUARTER, CAST('2024-03-15 14:37:42' AS TIMESTAMP))"
      }
    },
    {
      "sql": "SELECT TIME_SLICE(DATE '2024-03-15', 1, 'WEEK', 'END')",
      "read": {},
      "write": {
        "snowflake": "SELECT TIME_SLICE(CAST('2024-03-15' AS DATE), 1, 'WEEK', 'END')",
        "duckdb": "SELECT CAST(TIME_BUCKET(INTERVAL 1 WEEK, CAST('2024-03-15' AS DATE)) + INTERVAL 1 WEEK AS DATE)"
      }
    },
    {
      "sql": "WITH foo AS (SELECT [1] AS arr_1) SELECT (SELECT unnested_arr FROM TABLE(FLATTEN(INPUT => arr_1)) AS _t0(seq, key, path, index, unnested_arr, this)) AS f FROM foo",
      "read": {
        "bigquery": "WITH foo AS (SELECT [1] AS arr_1) SELECT (SELECT unnested_arr FROM UNNEST(arr_1) AS unnested_arr) AS f FROM foo"
      },
      "write": {}
    },
    {
      "sql": "SELECT BASE64_ENCODE(x)",
      "read": {},
      "write": {
        "duckdb": "SELECT TO_BASE64(x)",
        "snowflake": "SELECT BASE64_ENCODE(x)"
      }
    },
    {
      "sql": "SELECT BASE64_ENCODE(x, 76)",
      "read": {},
      "write": {
        "duckdb": "SELECT RTRIM(REGEXP_REPLACE(TO_BASE64(x), '(.{76})', '\\1' || CHR(10), 'g'), CHR(10))",
        "snowflake": "SELECT BASE64_ENCODE(x, 76)"
      }
    },
    {
      "sql": "SELECT BASE64_ENCODE(x, 76, '+/=')",
      "read": {},
      "write": {
        "duckdb": "SELECT RTRIM(REGEXP_REPLACE(TO_BASE64(x), '(.{76})', '\\1' || CHR(10), 'g'), CHR(10))",
        "snowflake": "SELECT BASE64_ENCODE(x, 76, '+/=')"
      }
    },
    {
      "sql": "SELECT ARRAY_CONTAINS(CAST('1' AS VARIANT), ['1'])",
      "read": {
        "presto": "SELECT CONTAINS(ARRAY['1'], '1')",
        "snowflake": "SELECT ARRAY_CONTAINS(CAST('1' AS VARIANT), ['1'])"
      },
      "write": {}
    },
    {
      "sql": "SELECT ARRAY_CONTAINS(CAST(CAST('2020-10-10' AS DATE) AS VARIANT), [CAST('2020-10-10' AS DATE)])",
      "read": {
        "presto": "SELECT CONTAINS(ARRAY[DATE '2020-10-10'], DATE '2020-10-10')",
        "snowflake": "SELECT ARRAY_CONTAINS(CAST(CAST('2020-10-10' AS DATE) AS VARIANT), [CAST('2020-10-10' AS DATE)])"
      },
      "write": {}
    },
    {
      "sql": "SELECT x'ABCD'",
      "read": {},
      "write": {
        "snowflake": "SELECT x'ABCD'",
        "duckdb": "SELECT UNHEX('ABCD')"
      }
    },
    {
      "sql": "SET a = 1",
      "read": {},
      "write": {
        "snowflake": "SET a = 1",
        "bigquery": "SET a = 1",
        "duckdb": "SET VARIABLE a = 1"
      }
    },
    {
      "sql": "CAST(6.43 AS FLOAT)",
      "read": {},
      "write": {
        "snowflake": "CAST(6.43 AS DOUBLE)",
        "duckdb": "CAST(6.43 AS DOUBLE)"
      }
    },
    {
      "sql": "UNIFORM(1, 10, RANDOM(5))",
      "read": {},
      "write": {
        "snowflake": "UNIFORM(1, 10, RANDOM(5))",
        "databricks": "UNIFORM(1, 10, 5)",
        "duckdb": "CAST(FLOOR(1 + RANDOM() * (10 - 1 + 1)) AS BIGINT)"
      }
    },
    {
      "sql": "UNIFORM(1, 10, RANDOM())",
      "read": {},
      "write": {
        "snowflake": "UNIFORM(1, 10, RANDOM())",
        "databricks": "UNIFORM(1, 10)",
        "duckdb": "CAST(FLOOR(1 + RANDOM() * (10 - 1 + 1)) AS BIGINT)"
      }
    },
    {
      "sql": "UNIFORM(1, 10, 5)",
      "read": {},
      "write": {
        "snowflake": "UNIFORM(1, 10, 5)",
        "databricks": "UNIFORM(1, 10, 5)",
        "duckdb": "CAST(FLOOR(1 + (ABS(HASH(5)) % 1000000) / 1000000.0 * (10 - 1 + 1)) AS BIGINT)"
      }
    },
    {
      "sql": "NORMAL(0, 1, 42)",
      "read": {},
      "write": {
        "snowflake": "NORMAL(0, 1, 42)",
        "duckdb": "0 + (1 * SQRT(-2 * LN(GREATEST((ABS(HASH(42)) % 1000000) / 1000000.0, 1e-10))) * COS(2 * PI() * (ABS(HASH(42 + 1)) % 1000000) / 1000000.0))"
      }
    },
    {
      "sql": "NORMAL(10.5, 2.5, RANDOM())",
      "read": {},
      "write": {
        "snowflake": "NORMAL(10.5, 2.5, RANDOM())",
        "duckdb": "10.5 + (2.5 * SQRT(-2 * LN(GREATEST(RANDOM(), 1e-10))) * COS(2 * PI() * RANDOM()))"
      }
    },
    {
      "sql": "NORMAL(10.5, 2.5, RANDOM(5))",
      "read": {},
      "write": {
        "snowflake": "NORMAL(10.5, 2.5, RANDOM(5))",
        "duckdb": "10.5 + (2.5 * SQRT(-2 * LN(GREATEST((ABS(HASH(5)) % 1000000) / 1000000.0, 1e-10))) * COS(2 * PI() * (ABS(HASH(5 + 1)) % 1000000) / 1000000.0))"
      }
    },
    {
      "sql": "SYSDATE()",
      "read": {},
      "write": {
        "snowflake": "SYSDATE()",
        "duckdb": "CURRENT_TIMESTAMP AT TIME ZONE 'UTC'"
      }
    },
    {
      "sql": "SELECT DATE_FROM_PARTS(2026, 1, 100)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_FROM_PARTS(2026, 1, 100)",
        "duckdb": "SELECT CAST(MAKE_DATE(2026, 1, 1) + INTERVAL (1 - 1) MONTH + INTERVAL (100 - 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT DATE_FROM_PARTS(2026, 14, 32)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_FROM_PARTS(2026, 14, 32)",
        "duckdb": "SELECT CAST(MAKE_DATE(2026, 1, 1) + INTERVAL (14 - 1) MONTH + INTERVAL (32 - 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT DATE_FROM_PARTS(2026, 0, 0)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_FROM_PARTS(2026, 0, 0)",
        "duckdb": "SELECT CAST(MAKE_DATE(2026, 1, 1) + INTERVAL (0 - 1) MONTH + INTERVAL (0 - 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT DATE_FROM_PARTS(2026, -14, -32)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_FROM_PARTS(2026, -14, -32)",
        "duckdb": "SELECT CAST(MAKE_DATE(2026, 1, 1) + INTERVAL (-14 - 1) MONTH + INTERVAL (-32 - 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT DATE_FROM_PARTS(2024, 1, 60)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_FROM_PARTS(2024, 1, 60)",
        "duckdb": "SELECT CAST(MAKE_DATE(2024, 1, 1) + INTERVAL (1 - 1) MONTH + INTERVAL (60 - 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT DATE_FROM_PARTS(2026, NULL, 100)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_FROM_PARTS(2026, NULL, 100)",
        "duckdb": "SELECT CAST(MAKE_DATE(2026, 1, 1) + INTERVAL (NULL - 1) MONTH + INTERVAL (100 - 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT DATE_FROM_PARTS(2024 + 2, 1 + 2, 2 + 3)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_FROM_PARTS(2024 + 2, 1 + 2, 2 + 3)",
        "duckdb": "SELECT CAST(MAKE_DATE(2024 + 2, 1, 1) + INTERVAL ((1 + 2) - 1) MONTH + INTERVAL ((2 + 3) - 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT DATE_FROM_PARTS(year, month, date)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_FROM_PARTS(year, month, date)",
        "duckdb": "SELECT CAST(MAKE_DATE(year, 1, 1) + INTERVAL (month - 1) MONTH + INTERVAL (date - 1) DAY AS DATE)"
      }
    },
    {
      "sql": "EQUAL_NULL(a, b)",
      "read": {},
      "write": {
        "snowflake": "EQUAL_NULL(a, b)",
        "duckdb": "a IS NOT DISTINCT FROM b"
      }
    },
    {
      "sql": "SELECT FIRST_VALUE(TABLE1.COLUMN1) OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1",
      "read": {},
      "write": {
        "snowflake": "SELECT FIRST_VALUE(TABLE1.COLUMN1) OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1"
      }
    },
    {
      "sql": "SELECT FIRST_VALUE(TABLE1.COLUMN1 RESPECT NULLS) OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1",
      "read": {},
      "write": {
        "snowflake": "SELECT FIRST_VALUE(TABLE1.COLUMN1) RESPECT NULLS OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1"
      }
    },
    {
      "sql": "SELECT FIRST_VALUE(TABLE1.COLUMN1) RESPECT NULLS OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1",
      "read": {},
      "write": {
        "snowflake": "SELECT FIRST_VALUE(TABLE1.COLUMN1) RESPECT NULLS OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1"
      }
    },
    {
      "sql": "SELECT FIRST_VALUE(TABLE1.COLUMN1 IGNORE NULLS) OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1",
      "read": {},
      "write": {
        "snowflake": "SELECT FIRST_VALUE(TABLE1.COLUMN1) IGNORE NULLS OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1"
      }
    },
    {
      "sql": "SELECT FIRST_VALUE(TABLE1.COLUMN1) IGNORE NULLS OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1",
      "read": {},
      "write": {
        "snowflake": "SELECT FIRST_VALUE(TABLE1.COLUMN1) IGNORE NULLS OVER (PARTITION BY RANDOM_COLUMN1, RANDOM_COLUMN2 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS MY_ALIAS FROM TABLE1"
      }
    },
    {
      "sql": "SELECT * FROM foo WHERE 'str' IN (SELECT value FROM TABLE(FLATTEN(INPUT => vals)) AS _u(seq, key, path, index, value, this))",
      "read": {
        "bigquery": "SELECT * FROM foo WHERE 'str' IN UNNEST(vals)"
      },
      "write": {
        "snowflake": "SELECT * FROM foo WHERE 'str' IN (SELECT value FROM TABLE(FLATTEN(INPUT => vals)) AS _u(seq, key, path, index, value, this))"
      }
    },
    {
      "sql": "SELECT * FROM example TABLESAMPLE BERNOULLI (3) SEED (82)",
      "read": {
        "duckdb": "SELECT * FROM example TABLESAMPLE BERNOULLI (3 PERCENT) REPEATABLE (82)"
      },
      "write": {
        "databricks": "SELECT * FROM example TABLESAMPLE (3 PERCENT) REPEATABLE (82)",
        "duckdb": "SELECT * FROM example TABLESAMPLE BERNOULLI (3 PERCENT) REPEATABLE (82)",
        "snowflake": "SELECT * FROM example TABLESAMPLE BERNOULLI (3) SEED (82)"
      }
    },
    {
      "sql": "SELECT * FROM test AS _tmp TABLESAMPLE (5)",
      "read": {},
      "write": {
        "postgres": "SELECT * FROM test AS _tmp TABLESAMPLE BERNOULLI (5)",
        "snowflake": "SELECT * FROM test AS _tmp TABLESAMPLE BERNOULLI (5)"
      }
    },
    {
      "sql": "\n            SELECT i, j\n                FROM\n                     table1 AS t1 SAMPLE (25)     -- 25% of rows in table1\n                         INNER JOIN\n                     table2 AS t2 SAMPLE (50)     -- 50% of rows in table2\n                WHERE t2.j = t1.i",
      "read": {},
      "write": {
        "snowflake": "SELECT i, j FROM table1 AS t1 TABLESAMPLE BERNOULLI (25) /* 25% of rows in table1 */ INNER JOIN table2 AS t2 TABLESAMPLE BERNOULLI (50) /* 50% of rows in table2 */ WHERE t2.j = t1.i"
      }
    },
    {
      "sql": "SELECT * FROM testtable SAMPLE BLOCK (0.012) REPEATABLE (99992)",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM testtable TABLESAMPLE BLOCK (0.012) SEED (99992)"
      }
    },
    {
      "sql": "SELECT * FROM (SELECT * FROM t1 join t2 on t1.a = t2.c) SAMPLE (1)",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM (SELECT * FROM t1 JOIN t2 ON t1.a = t2.c) TABLESAMPLE BERNOULLI (1)",
        "spark": "SELECT * FROM (SELECT * FROM t1 JOIN t2 ON t1.a = t2.c) TABLESAMPLE (1 PERCENT)"
      }
    },
    {
      "sql": "TO_DOUBLE(expr)",
      "read": {},
      "write": {
        "snowflake": "TO_DOUBLE(expr)",
        "duckdb": "CAST(expr AS DOUBLE)"
      }
    },
    {
      "sql": "TO_DOUBLE(expr, fmt)",
      "read": {},
      "write": {
        "snowflake": "TO_DOUBLE(expr, fmt)"
      }
    },
    {
      "sql": "SELECT a::TIMESTAMP_LTZ(9)",
      "read": {},
      "write": {
        "snowflake": "SELECT CAST(a AS TIMESTAMPLTZ(9))"
      }
    },
    {
      "sql": "SELECT a::TIMESTAMPLTZ",
      "read": {},
      "write": {
        "snowflake": "SELECT CAST(a AS TIMESTAMPLTZ)"
      }
    },
    {
      "sql": "SELECT a::TIMESTAMP WITH LOCAL TIME ZONE",
      "read": {},
      "write": {
        "snowflake": "SELECT CAST(a AS TIMESTAMPLTZ)"
      }
    },
    {
      "sql": "SELECT EXTRACT('month', a)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART('month', a)"
      }
    },
    {
      "sql": "SELECT DATE_PART('month', a)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART('month', a)"
      }
    },
    {
      "sql": "SELECT DATE_PART(month, a::DATETIME)",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(month, CAST(a AS DATETIME))"
      }
    },
    {
      "sql": "SELECT DATE_PART(epoch_second, foo) as ddate from table_name",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(EPOCH_SECOND, foo) AS ddate FROM table_name",
        "duckdb": "SELECT CAST(EPOCH(foo) AS BIGINT) AS ddate FROM table_name",
        "presto": "SELECT TO_UNIXTIME(CAST(foo AS TIMESTAMP)) AS ddate FROM table_name"
      }
    },
    {
      "sql": "SELECT DATE_PART(epoch_milliseconds, foo) as ddate from table_name",
      "read": {},
      "write": {
        "snowflake": "SELECT DATE_PART(EPOCH_MILLISECOND, foo) AS ddate FROM table_name",
        "duckdb": "SELECT EPOCH_MS(foo) AS ddate FROM table_name",
        "presto": "SELECT TO_UNIXTIME(CAST(foo AS TIMESTAMP)) * 1000 AS ddate FROM table_name"
      }
    },
    {
      "sql": "DATEADD(DAY, 5, CAST('2008-12-25' AS DATE))",
      "read": {
        "snowflake": "TIMESTAMPADD(DAY, 5, CAST('2008-12-25' AS DATE))"
      },
      "write": {
        "bigquery": "DATE_ADD(CAST('2008-12-25' AS DATE), INTERVAL 5 DAY)",
        "snowflake": "DATEADD(DAY, 5, CAST('2008-12-25' AS DATE))"
      }
    },
    {
      "sql": "DATEDIFF(WEEK, '2024-12-13', '2024-12-17')",
      "read": {},
      "write": {
        "duckdb": "DATE_DIFF('WEEK', DATE_TRUNC('WEEK', CAST('2024-12-13' AS DATE)), DATE_TRUNC('WEEK', CAST('2024-12-17' AS DATE)))",
        "snowflake": "DATEDIFF(WEEK, '2024-12-13', '2024-12-17')"
      }
    },
    {
      "sql": "DATEDIFF(WEEK, '2024-12-15', '2024-12-16')",
      "read": {},
      "write": {
        "duckdb": "DATE_DIFF('WEEK', DATE_TRUNC('WEEK', CAST('2024-12-15' AS DATE)), DATE_TRUNC('WEEK', CAST('2024-12-16' AS DATE)))",
        "snowflake": "DATEDIFF(WEEK, '2024-12-15', '2024-12-16')"
      }
    },
    {
      "sql": "DATEDIFF(YEAR, '2020-01-15', '2023-06-20')",
      "read": {},
      "write": {
        "duckdb": "DATE_DIFF('YEAR', CAST('2020-01-15' AS DATE), CAST('2023-06-20' AS DATE))",
        "snowflake": "DATEDIFF(YEAR, '2020-01-15', '2023-06-20')"
      }
    },
    {
      "sql": "DATEDIFF(MONTH, '2020-01-15', '2023-06-20')",
      "read": {},
      "write": {
        "duckdb": "DATE_DIFF('MONTH', CAST('2020-01-15' AS DATE), CAST('2023-06-20' AS DATE))",
        "snowflake": "DATEDIFF(MONTH, '2020-01-15', '2023-06-20')"
      }
    },
    {
      "sql": "DATEDIFF(QUARTER, '2020-01-15', '2023-06-20')",
      "read": {},
      "write": {
        "duckdb": "DATE_DIFF('QUARTER', CAST('2020-01-15' AS DATE), CAST('2023-06-20' AS DATE))",
        "snowflake": "DATEDIFF(QUARTER, '2020-01-15', '2023-06-20')"
      }
    },
    {
      "sql": "DATEDIFF(NANOSECOND, '2023-01-01 10:00:00.000000000', '2023-01-01 10:00:00.123456789')",
      "read": {},
      "write": {
        "duckdb": "EPOCH_NS(CAST('2023-01-01 10:00:00.123456789' AS TIMESTAMP_NS)) - EPOCH_NS(CAST('2023-01-01 10:00:00.000000000' AS TIMESTAMP_NS))",
        "snowflake": "DATEDIFF(NANOSECOND, '2023-01-01 10:00:00.000000000', '2023-01-01 10:00:00.123456789')"
      }
    },
    {
      "sql": "DATEDIFF(NANOSECOND, start_time, end_time)",
      "read": {},
      "write": {
        "duckdb": "EPOCH_NS(CAST(end_time AS TIMESTAMP_NS)) - EPOCH_NS(CAST(start_time AS TIMESTAMP_NS))",
        "snowflake": "DATEDIFF(NANOSECOND, start_time, end_time)"
      }
    },
    {
      "sql": "DATEADD(NANOSECOND, 123456789, '2023-01-01 10:00:00.000000000')",
      "read": {},
      "write": {
        "duckdb": "MAKE_TIMESTAMP_NS(EPOCH_NS(CAST('2023-01-01 10:00:00.000000000' AS TIMESTAMP_NS)) + 123456789)",
        "snowflake": "DATEADD(NANOSECOND, 123456789, '2023-01-01 10:00:00.000000000')"
      }
    },
    {
      "sql": "DATEADD(NANOSECOND, nano_offset, timestamp_col)",
      "read": {},
      "write": {
        "duckdb": "MAKE_TIMESTAMP_NS(EPOCH_NS(CAST(timestamp_col AS TIMESTAMP_NS)) + nano_offset)",
        "snowflake": "DATEADD(NANOSECOND, nano_offset, timestamp_col)"
      }
    },
    {
      "sql": "DATEADD(NANOSECOND, -123456789, '2023-01-01 10:00:00.500000000')",
      "read": {},
      "write": {
        "duckdb": "MAKE_TIMESTAMP_NS(EPOCH_NS(CAST('2023-01-01 10:00:00.500000000' AS TIMESTAMP_NS)) + -123456789)",
        "snowflake": "DATEADD(NANOSECOND, -123456789, '2023-01-01 10:00:00.500000000')"
      }
    },
    {
      "sql": "TIMESTAMPDIFF(NANOSECOND, '2023-01-01 10:00:00.000000000', '2023-01-01 10:00:00.123456789')",
      "read": {},
      "write": {
        "duckdb": "EPOCH_NS(CAST('2023-01-01 10:00:00.123456789' AS TIMESTAMP_NS)) - EPOCH_NS(CAST('2023-01-01 10:00:00.000000000' AS TIMESTAMP_NS))",
        "snowflake": "DATEDIFF(NANOSECOND, '2023-01-01 10:00:00.000000000', '2023-01-01 10:00:00.123456789')"
      }
    },
    {
      "sql": "TIMESTAMPADD(NANOSECOND, 123456789, '2023-01-01 10:00:00.000000000')",
      "read": {},
      "write": {
        "duckdb": "MAKE_TIMESTAMP_NS(EPOCH_NS(CAST('2023-01-01 10:00:00.000000000' AS TIMESTAMP_NS)) + 123456789)",
        "snowflake": "DATEADD(NANOSECOND, 123456789, '2023-01-01 10:00:00.000000000')"
      }
    },
    {
      "sql": "DATE_TRUNC('YEAR', CAST('2024-06-15' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "DATE_TRUNC('YEAR', CAST('2024-06-15' AS DATE))",
        "duckdb": "DATE_TRUNC('YEAR', CAST('2024-06-15' AS DATE))"
      }
    },
    {
      "sql": "DATE_TRUNC('HOUR', CAST('2026-01-01 00:00:00' AS TIMESTAMP))",
      "read": {},
      "write": {
        "snowflake": "DATE_TRUNC('HOUR', CAST('2026-01-01 00:00:00' AS TIMESTAMP))",
        "duckdb": "DATE_TRUNC('HOUR', CAST('2026-01-01 00:00:00' AS TIMESTAMP))"
      }
    },
    {
      "sql": "DATE_TRUNC(YEAR, TIMESTAMP '2026-01-01 00:00:00')",
      "read": {},
      "write": {
        "snowflake": "DATE_TRUNC('YEAR', CAST('2026-01-01 00:00:00' AS TIMESTAMP))",
        "duckdb": "CAST(DATE_TRUNC('YEAR', CAST('2026-01-01 00:00:00' AS TIMESTAMP)) AS TIMESTAMP)"
      }
    },
    {
      "sql": "DATE_TRUNC(MONTH, CAST('2024-06-15 14:23:45' AS TIMESTAMPTZ))",
      "read": {},
      "write": {
        "snowflake": "DATE_TRUNC('MONTH', CAST('2024-06-15 14:23:45' AS TIMESTAMPTZ))",
        "duckdb": "CAST(DATE_TRUNC('MONTH', CAST('2024-06-15 14:23:45' AS TIMESTAMPTZ)) AS TIMESTAMPTZ)"
      }
    },
    {
      "sql": "DATE_TRUNC('WEEK', CURRENT_DATE)",
      "read": {},
      "write": {
        "snowflake": "DATE_TRUNC('WEEK', CURRENT_DATE)",
        "duckdb": "DATE_TRUNC('WEEK', CURRENT_DATE)"
      }
    },
    {
      "sql": "DATE_TRUNC('HOUR', CAST('2026-01-01' AS DATE))",
      "read": {},
      "write": {
        "snowflake": "DATE_TRUNC('HOUR', CAST('2026-01-01' AS DATE))",
        "duckdb": "CAST(DATE_TRUNC('HOUR', CAST('2026-01-01' AS DATE)) AS DATE)"
      }
    },
    {
      "sql": "DATE_TRUNC('HOUR', CAST('14:23:45.123456' AS TIME))",
      "read": {},
      "write": {
        "snowflake": "DATE_TRUNC('HOUR', CAST('14:23:45.123456' AS TIME))",
        "duckdb": "CAST(DATE_TRUNC('HOUR', CAST('1970-01-01' AS DATE) + CAST('14:23:45.123456' AS TIME)) AS TIME)"
      }
    },
    {
      "sql": "DATE(x)",
      "read": {},
      "write": {
        "duckdb": "CAST(x AS DATE)",
        "snowflake": "TO_DATE(x)"
      }
    },
    {
      "sql": "DATE('01-01-2000', 'MM-DD-YYYY')",
      "read": {},
      "write": {
        "snowflake": "TO_DATE('01-01-2000', 'mm-DD-yyyy')",
        "duckdb": "CAST(STRPTIME('01-01-2000', '%m-%d-%Y') AS DATE)"
      }
    },
    {
      "sql": "SELECT TO_TIME('12:05:00')",
      "read": {},
      "write": {
        "bigquery": "SELECT CAST('12:05:00' AS TIME)",
        "snowflake": "SELECT CAST('12:05:00' AS TIME)",
        "duckdb": "SELECT CAST('12:05:00' AS TIME)"
      }
    },
    {
      "sql": "SELECT TO_TIME('2024-01-15 14:30:00'::TIMESTAMP)",
      "read": {},
      "write": {
        "bigquery": "SELECT TIME(CAST('2024-01-15 14:30:00' AS DATETIME))",
        "snowflake": "SELECT TO_TIME(CAST('2024-01-15 14:30:00' AS TIMESTAMP))",
        "duckdb": "SELECT CAST(CAST('2024-01-15 14:30:00' AS TIMESTAMP) AS TIME)"
      }
    },
    {
      "sql": "SELECT TO_TIME(CONVERT_TIMEZONE('UTC', 'US/Pacific', '2024-08-06 09:10:00.000')) AS pst_time",
      "read": {},
      "write": {
        "snowflake": "SELECT TO_TIME(CONVERT_TIMEZONE('UTC', 'US/Pacific', '2024-08-06 09:10:00.000')) AS pst_time",
        "duckdb": "SELECT CAST(CAST('2024-08-06 09:10:00.000' AS TIMESTAMP) AT TIME ZONE 'UTC' AT TIME ZONE 'US/Pacific' AS TIME) AS pst_time"
      }
    },
    {
      "sql": "SELECT TO_TIME('11.15.00', 'hh24.mi.ss')",
      "read": {},
      "write": {
        "snowflake": "SELECT TO_TIME('11.15.00', 'hh24.mi.ss')",
        "duckdb": "SELECT CAST(STRPTIME('11.15.00', '%H.%M.%S') AS TIME)"
      }
    },
    {
      "sql": "SELECT TO_TIME('093000', 'HH24MISS')",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(STRPTIME('093000', '%H%M%S') AS TIME)",
        "snowflake": "SELECT TO_TIME('093000', 'hh24miss')"
      }
    },
    {
      "sql": "SELECT TRY_TO_TIME('093000', 'HH24MISS')",
      "read": {},
      "write": {
        "snowflake": "SELECT TRY_TO_TIME('093000', 'hh24miss')",
        "duckdb": "SELECT TRY_CAST(TRY_STRPTIME('093000', '%H%M%S') AS TIME)"
      }
    },
    {
      "sql": "SELECT TRY_TO_TIME('11.15.00')",
      "read": {},
      "write": {
        "snowflake": "SELECT TRY_CAST('11.15.00' AS TIME)",
        "duckdb": "SELECT TRY_CAST('11.15.00' AS TIME)"
      }
    },
    {
      "sql": "SELECT TRY_TO_TIME('11.15.00', 'hh24.mi.ss')",
      "read": {},
      "write": {
        "snowflake": "SELECT TRY_TO_TIME('11.15.00', 'hh24.mi.ss')",
        "duckdb": "SELECT TRY_CAST(TRY_STRPTIME('11.15.00', '%H.%M.%S') AS TIME)"
      }
    },
    {
      "sql": "TO_DATE('01-01-2000', 'MM-DD-YYYY')",
      "read": {},
      "write": {
        "snowflake": "TO_DATE('01-01-2000', 'mm-DD-yyyy')",
        "duckdb": "CAST(STRPTIME('01-01-2000', '%m-%d-%Y') AS DATE)"
      }
    },
    {
      "sql": "TO_DATE(x, 'MM-DD-YYYY')",
      "read": {},
      "write": {
        "snowflake": "TO_DATE(x, 'mm-DD-yyyy')",
        "duckdb": "CAST(STRPTIME(x, '%m-%d-%Y') AS DATE)"
      }
    },
    {
      "sql": "TRY_TO_DATE('2024-01-31')",
      "read": {},
      "write": {
        "snowflake": "TRY_CAST('2024-01-31' AS DATE)",
        "duckdb": "TRY_CAST('2024-01-31' AS DATE)"
      }
    },
    {
      "sql": "TRY_TO_DATE('01-01-2000', 'MM-DD-YYYY')",
      "read": {},
      "write": {
        "snowflake": "TRY_TO_DATE('01-01-2000', 'mm-DD-yyyy')",
        "duckdb": "CAST(CAST(TRY_STRPTIME('01-01-2000', '%m-%d-%Y') AS TIMESTAMP) AS DATE)"
      }
    },
    {
      "sql": "TRY_TO_DATE('2013-04-28T20:57:01.888', 'yyyy-mm-DDThh24:mi:ss.ff')",
      "read": {},
      "write": {
        "snowflake": "TRY_TO_DATE('2013-04-28T20:57:01.888', 'yyyy-mm-DDThh24:mi:ss.ff9')",
        "duckdb": "CAST(CAST(TRY_STRPTIME('2013-04-28T20:57:01.888', '%Y-%m-%dT%H:%M:%S.%n') AS TIMESTAMP) AS DATE)"
      }
    },
    {
      "sql": "TRY_TO_DATE('2013-04-28T20:57', 'YYYY-MM-DD\"T\"HH24:MI:SS')",
      "read": {},
      "write": {
        "snowflake": "TRY_TO_DATE('2013-04-28T20:57', 'yyyy-mm-DDThh24:mi:ss')",
        "duckdb": "CAST(CAST(TRY_STRPTIME('2013-04-28T20:57', '%Y-%m-%dT%H:%M:%S') AS TIMESTAMP) AS DATE)"
      }
    },
    {
      "sql": "SELECT a::VARIANT",
      "read": {},
      "write": {
        "snowflake": "SELECT CAST(a AS VARIANT)",
        "tsql": "SELECT CAST(a AS SQL_VARIANT)"
      }
    },
    {
      "sql": "ARRAY_CONSTRUCT(0, 1, 2)",
      "read": {},
      "write": {
        "snowflake": "[0, 1, 2]",
        "bigquery": "[0, 1, 2]",
        "duckdb": "[0, 1, 2]",
        "presto": "ARRAY[0, 1, 2]",
        "spark": "ARRAY(0, 1, 2)"
      }
    },
    {
      "sql": "SELECT a::OBJECT",
      "read": {},
      "write": {
        "snowflake": "SELECT CAST(a AS OBJECT)"
      }
    },
    {
      "sql": "SELECT NEXT_DAY(CAST('2024-01-01' AS DATE), 'Monday')",
      "read": {},
      "write": {
        "snowflake": "SELECT NEXT_DAY(CAST('2024-01-01' AS DATE), 'Monday')",
        "duckdb": "SELECT CAST(CAST('2024-01-01' AS DATE) + INTERVAL ((((1 - ISODOW(CAST('2024-01-01' AS DATE))) + 6) % 7) + 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT NEXT_DAY(CAST('2024-01-05' AS DATE), 'Friday')",
      "read": {},
      "write": {
        "snowflake": "SELECT NEXT_DAY(CAST('2024-01-05' AS DATE), 'Friday')",
        "duckdb": "SELECT CAST(CAST('2024-01-05' AS DATE) + INTERVAL ((((5 - ISODOW(CAST('2024-01-05' AS DATE))) + 6) % 7) + 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT NEXT_DAY(CAST('2024-01-05' AS DATE), 'WE')",
      "read": {},
      "write": {
        "snowflake": "SELECT NEXT_DAY(CAST('2024-01-05' AS DATE), 'WE')",
        "duckdb": "SELECT CAST(CAST('2024-01-05' AS DATE) + INTERVAL ((((3 - ISODOW(CAST('2024-01-05' AS DATE))) + 6) % 7) + 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT NEXT_DAY(CAST('2024-01-01 10:30:45' AS TIMESTAMP), 'Friday')",
      "read": {},
      "write": {
        "snowflake": "SELECT NEXT_DAY(CAST('2024-01-01 10:30:45' AS TIMESTAMP), 'Friday')",
        "duckdb": "SELECT CAST(CAST('2024-01-01 10:30:45' AS TIMESTAMP) + INTERVAL ((((5 - ISODOW(CAST('2024-01-01 10:30:45' AS TIMESTAMP))) + 6) % 7) + 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT NEXT_DAY(CAST('2024-01-01' AS DATE), day_column)",
      "read": {},
      "write": {
        "snowflake": "SELECT NEXT_DAY(CAST('2024-01-01' AS DATE), day_column)",
        "duckdb": "SELECT CAST(CAST('2024-01-01' AS DATE) + INTERVAL ((((CASE WHEN STARTS_WITH(UPPER(day_column), 'MO') THEN 1 WHEN STARTS_WITH(UPPER(day_column), 'TU') THEN 2 WHEN STARTS_WITH(UPPER(day_column), 'WE') THEN 3 WHEN STARTS_WITH(UPPER(day_column), 'TH') THEN 4 WHEN STARTS_WITH(UPPER(day_column), 'FR') THEN 5 WHEN STARTS_WITH(UPPER(day_column), 'SA') THEN 6 WHEN STARTS_WITH(UPPER(day_column), 'SU') THEN 7 END - ISODOW(CAST('2024-01-01' AS DATE))) + 6) % 7) + 1) DAY AS DATE)"
      }
    },
    {
      "sql": "SELECT PREVIOUS_DAY(DATE '2024-01-15', 'Monday')",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CAST('2024-01-15' AS DATE) - INTERVAL ((((ISODOW(CAST('2024-01-15' AS DATE)) - 1) + 6) % 7) + 1) DAY AS DATE)",
        "snowflake": "SELECT PREVIOUS_DAY(CAST('2024-01-15' AS DATE), 'Monday')"
      }
    },
    {
      "sql": "SELECT PREVIOUS_DAY(DATE '2024-01-15', 'Fr')",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CAST('2024-01-15' AS DATE) - INTERVAL ((((ISODOW(CAST('2024-01-15' AS DATE)) - 5) + 6) % 7) + 1) DAY AS DATE)",
        "snowflake": "SELECT PREVIOUS_DAY(CAST('2024-01-15' AS DATE), 'Fr')"
      }
    },
    {
      "sql": "SELECT PREVIOUS_DAY(TIMESTAMP '2024-01-15 10:30:45', 'Monday')",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CAST('2024-01-15 10:30:45' AS TIMESTAMP) - INTERVAL ((((ISODOW(CAST('2024-01-15 10:30:45' AS TIMESTAMP)) - 1) + 6) % 7) + 1) DAY AS DATE)",
        "snowflake": "SELECT PREVIOUS_DAY(CAST('2024-01-15 10:30:45' AS TIMESTAMP), 'Monday')"
      }
    },
    {
      "sql": "SELECT PREVIOUS_DAY(DATE '2024-01-15', day_column)",
      "read": {},
      "write": {
        "duckdb": "SELECT CAST(CAST('2024-01-15' AS DATE) - INTERVAL ((((ISODOW(CAST('2024-01-15' AS DATE)) - CASE WHEN STARTS_WITH(UPPER(day_column), 'MO') THEN 1 WHEN STARTS_WITH(UPPER(day_column), 'TU') THEN 2 WHEN STARTS_WITH(UPPER(day_column), 'WE') THEN 3 WHEN STARTS_WITH(UPPER(day_column), 'TH') THEN 4 WHEN STARTS_WITH(UPPER(day_column), 'FR') THEN 5 WHEN STARTS_WITH(UPPER(day_column), 'SA') THEN 6 WHEN STARTS_WITH(UPPER(day_column), 'SU') THEN 7 END) + 6) % 7) + 1) DAY AS DATE)",
        "snowflake": "SELECT PREVIOUS_DAY(CAST('2024-01-15' AS DATE), day_column)"
      }
    },
    {
      "sql": "CREATE TABLE orders_clone CLONE orders",
      "read": {
        "bigquery": "CREATE TABLE orders_clone CLONE orders"
      },
      "write": {
        "bigquery": "CREATE TABLE orders_clone CLONE orders",
        "snowflake": "CREATE TABLE orders_clone CLONE orders"
      }
    },
    {
      "sql": "CREATE OR REPLACE TRANSIENT TABLE a (id INT)",
      "read": {
        "postgres": "CREATE OR REPLACE TRANSIENT TABLE a (id INT)",
        "snowflake": "CREATE OR REPLACE TRANSIENT TABLE a (id INT)"
      },
      "write": {
        "postgres": "CREATE OR REPLACE TABLE a (id INT)",
        "mysql": "CREATE OR REPLACE TABLE a (id INT)",
        "snowflake": "CREATE OR REPLACE TRANSIENT TABLE a (id INT)"
      }
    },
    {
      "sql": "CREATE TABLE a (b INT)",
      "read": {
        "teradata": "CREATE MULTISET TABLE a (b INT)"
      },
      "write": {
        "snowflake": "CREATE TABLE a (b INT)"
      }
    },
    {
      "sql": "CREATE TABLE a TAG (key1='value_1')",
      "read": {
        "snowflake": "CREATE TABLE a WITH TAG (key1='value_1')"
      },
      "write": {}
    },
    {
      "sql": "CREATE FUNCTION a(x DATE, y BIGINT) RETURNS ARRAY LANGUAGE JAVASCRIPT AS $$ SELECT 1 $$",
      "read": {},
      "write": {
        "snowflake": "CREATE FUNCTION a(x DATE, y BIGINT) RETURNS ARRAY LANGUAGE JAVASCRIPT AS ' SELECT 1 '"
      }
    },
    {
      "sql": "CREATE FUNCTION a() RETURNS TABLE (b INT) AS 'SELECT 1'",
      "read": {},
      "write": {
        "snowflake": "CREATE FUNCTION a() RETURNS TABLE (b INT) AS 'SELECT 1'",
        "bigquery": "CREATE TABLE FUNCTION a() RETURNS TABLE <b INT64> AS SELECT 1"
      }
    },
    {
      "sql": "CREATE FUNCTION a() RETURNS INT IMMUTABLE AS 'SELECT 1'",
      "read": {},
      "write": {
        "snowflake": "CREATE FUNCTION a() RETURNS INT IMMUTABLE AS 'SELECT 1'"
      }
    },
    {
      "sql": "\n            select\n              dag_report.acct_id,\n              dag_report.report_date,\n              dag_report.report_uuid,\n              dag_report.airflow_name,\n              dag_report.dag_id,\n              f.value::varchar as operator\n            from cs.telescope.dag_report,\n            table(flatten(input=>split(operators, ','))) f\n            ",
      "read": {},
      "write": {
        "snowflake": "SELECT\n  dag_report.acct_id,\n  dag_report.report_date,\n  dag_report.report_uuid,\n  dag_report.airflow_name,\n  dag_report.dag_id,\n  CAST(f.value AS VARCHAR) AS operator\nFROM cs.telescope.dag_report, TABLE(FLATTEN(input => SPLIT(operators, ','))) AS f"
      }
    },
    {
      "sql": "\n            SELECT\n              uc.user_id,\n              uc.start_ts AS ts,\n              CASE\n                WHEN uc.start_ts::DATE >= '2023-01-01' AND uc.country_code IN ('US') AND uc.user_id NOT IN (\n                  SELECT DISTINCT\n                    _id\n                  FROM\n                    users,\n                    LATERAL FLATTEN(INPUT => PARSE_JSON(flags)) datasource\n                  WHERE datasource.value:name = 'something'\n                )\n                  THEN 'Sample1'\n                  ELSE 'Sample2'\n              END AS entity\n            FROM user_countries AS uc\n            LEFT JOIN (\n              SELECT user_id, MAX(IFF(service_entity IS NULL,1,0)) AS le_null\n              FROM accepted_user_agreements\n              GROUP BY 1\n            ) AS aua\n              ON uc.user_id = aua.user_id\n            ",
      "read": {},
      "write": {
        "snowflake": "SELECT\n  uc.user_id,\n  uc.start_ts AS ts,\n  CASE\n    WHEN CAST(uc.start_ts AS DATE) >= '2023-01-01'\n    AND uc.country_code IN ('US')\n    AND uc.user_id <> ALL (\n      SELECT DISTINCT\n        _id\n      FROM users, LATERAL IFF(_u.pos = _u_2.pos_2, _u_2.entity, NULL) AS datasource(SEQ, KEY, PATH, INDEX, VALUE, THIS)\n      WHERE\n        GET_PATH(datasource.value, 'name') = 'something'\n    )\n    THEN 'Sample1'\n    ELSE 'Sample2'\n  END AS entity\nFROM user_countries AS uc\nLEFT JOIN (\n  SELECT\n    user_id,\n    MAX(IFF(service_entity IS NULL, 1, 0)) AS le_null\n  FROM accepted_user_agreements\n  GROUP BY\n    1\n) AS aua\n  ON uc.user_id = aua.user_id\nCROSS JOIN TABLE(FLATTEN(INPUT => ARRAY_GENERATE_RANGE(0, (\n  GREATEST(ARRAY_SIZE(INPUT => PARSE_JSON(flags))) - 1\n) + 1))) AS _u(seq, key, path, index, pos, this)\nCROSS JOIN TABLE(FLATTEN(INPUT => PARSE_JSON(flags))) AS _u_2(seq, key, path, pos_2, entity, this)\nWHERE\n  _u.pos = _u_2.pos_2\n  OR (\n    _u.pos > (\n      ARRAY_SIZE(INPUT => PARSE_JSON(flags)) - 1\n    )\n    AND _u_2.pos_2 = (\n      ARRAY_SIZE(INPUT => PARSE_JSON(flags)) - 1\n    )\n  )"
      }
    },
    {
      "sql": "SELECT * FROM TABLE(FLATTEN(input => parse_json('[1, ,77]'))) f",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM TABLE(FLATTEN(input => PARSE_JSON('[1, ,77]'))) AS f"
      }
    },
    {
      "sql": "SELECT * FROM TABLE(FLATTEN(input => parse_json('{\"a\":1, \"b\":[77,88]}'), outer => true)) f",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM TABLE(FLATTEN(input => PARSE_JSON('{\"a\":1, \"b\":[77,88]}'), outer => TRUE)) AS f"
      }
    },
    {
      "sql": "SELECT * FROM TABLE(FLATTEN(input => parse_json('{\"a\":1, \"b\":[77,88]}'), path => 'b')) f",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM TABLE(FLATTEN(input => PARSE_JSON('{\"a\":1, \"b\":[77,88]}'), path => 'b')) AS f"
      }
    },
    {
      "sql": "SELECT * FROM TABLE(FLATTEN(input => parse_json('[]'))) f",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM TABLE(FLATTEN(input => PARSE_JSON('[]'))) AS f"
      }
    },
    {
      "sql": "SELECT * FROM TABLE(FLATTEN(input => parse_json('[]'), outer => true)) f",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM TABLE(FLATTEN(input => PARSE_JSON('[]'), outer => TRUE)) AS f"
      }
    },
    {
      "sql": "SELECT * FROM TABLE(FLATTEN(input => parse_json('{\"a\":1, \"b\":[77,88], \"c\": {\"d\":\"X\"}}'))) f",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM TABLE(FLATTEN(input => PARSE_JSON('{\"a\":1, \"b\":[77,88], \"c\": {\"d\":\"X\"}}'))) AS f"
      }
    },
    {
      "sql": "SELECT * FROM TABLE(FLATTEN(input => parse_json('{\"a\":1, \"b\":[77,88], \"c\": {\"d\":\"X\"}}'), recursive => true)) f",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM TABLE(FLATTEN(input => PARSE_JSON('{\"a\":1, \"b\":[77,88], \"c\": {\"d\":\"X\"}}'), recursive => TRUE)) AS f"
      }
    },
    {
      "sql": "SELECT * FROM TABLE(FLATTEN(input => parse_json('{\"a\":1, \"b\":[77,88], \"c\": {\"d\":\"X\"}}'), recursive => true, mode => 'object')) f",
      "read": {},
      "write": {
        "snowflake": "SELECT * FROM TABLE(FLATTEN(input => PARSE_JSON('{\"a\":1, \"b\":[77,88], \"c\": {\"d\":\"X\"}}'), recursive => TRUE, mode => 'object')) AS f"
      }
    },
    {
      "sql": "\n            SELECT id as \"ID\",\n              f.value AS \"Contact\",\n              f1.value:type AS \"Type\",\n              f1.value:content AS \"Details\"\n            FROM persons p,\n              lateral flatten(input => p.c, path => 'contact') f,\n              lateral flatten(input => f.value:business) f1\n            ",
      "read": {},
      "write": {
        "snowflake": "SELECT\n  id AS \"ID\",\n  f.value AS \"Contact\",\n  GET_PATH(f1.value, 'type') AS \"Type\",\n  GET_PATH(f1.value, 'content') AS \"Details\"\nFROM persons AS p, LATERAL FLATTEN(input => p.c, path => 'contact') AS f(SEQ, KEY, PATH, INDEX, VALUE, THIS), LATERAL FLATTEN(input => GET_PATH(f.value, 'business')) AS f1(SEQ, KEY, PATH, INDEX, VALUE, THIS)"
      }
    },
    {
      "sql": "\n            SELECT id as \"ID\",\n              value AS \"Contact\"\n            FROM persons p,\n              lateral flatten(input => p.c, path => 'contact')\n            ",
      "read": {},
      "write": {
        "snowflake": "SELECT\n  id AS \"ID\",\n  value AS \"Contact\"\nFROM persons AS p, LATERAL FLATTEN(input => p.c, path => 'contact') AS _flattened(SEQ, KEY, PATH, INDEX, VALUE, THIS)"
      }
    },
    {
      "sql": "SELECT 1 EXCEPT SELECT 1",
      "read": {
        "oracle": "SELECT 1 MINUS SELECT 1",
        "snowflake": "SELECT 1 MINUS SELECT 1"
      },
      "write": {}
    },
    {
      "sql": "SELECT \"c0\", \"c1\" FROM (VALUES (1, 2), (3, 4)) AS \"t0\"(\"c0\", \"c1\")",
      "read": {
        "spark": "SELECT `c0`, `c1` FROM (VALUES (1, 2), (3, 4)) AS `t0`(`c0`, `c1`)"
      },
      "write": {}
    },
    {
      "sql": "SELECT $1 AS \"_1\" FROM VALUES ('a'), ('b')",
      "read": {},
      "write": {
        "snowflake": "SELECT $1 AS \"_1\" FROM (VALUES ('a'), ('b'))",
        "spark": "SELECT ${1} AS `_1` FROM VALUES ('a'), ('b')"
      }
    },
    {
      "sql": "SELECT * FROM (SELECT OBJECT_CONSTRUCT('a', 1) AS x) AS t",
      "read": {
        "duckdb": "SELECT * FROM (VALUES ({'a': 1})) AS t(x)"
      },
      "write": {}
    },
    {
      "sql": "SELECT * FROM (SELECT OBJECT_CONSTRUCT('a', 1) AS x UNION ALL SELECT OBJECT_CONSTRUCT('a', 2)) AS t",
      "read": {
        "duckdb": "SELECT * FROM (VALUES ({'a': 1}), ({'a': 2})) AS t(x)"
      },
      "write": {}
    },
    {
      "sql": "DESCRIBE TABLE db.table",
      "read": {},
      "write": {
        "snowflake": "DESCRIBE TABLE db.table",
        "spark": "DESCRIBE db.table"
      }
    },
    {
      "sql": "DESCRIBE db.table",
      "read": {},
      "write": {
        "snowflake": "DESCRIBE TABLE db.table",
        "spark": "DESCRIBE db.table"
      }
    },
    {
      "sql": "DESC TABLE db.table",
      "read": {},
      "write": {
        "snowflake": "DESCRIBE TABLE db.table",
        "spark": "DESCRIBE db.table"
      }
    },
    {
      "sql": "DESC VIEW db.table",
      "read": {},
      "write": {
        "snowflake": "DESCRIBE VIEW db.table",
        "spark": "DESCRIBE db.table"
      }
    },
    {
      "sql": "ENDSWITH('abc', 'c')",
      "read": {
        "bigquery": "ENDS_WITH('abc', 'c')",
        "clickhouse": "endsWith('abc', 'c')",
        "databricks": "ENDSWITH('abc', 'c')",
        "duckdb": "ENDS_WITH('abc', 'c')",
        "presto": "ENDS_WITH('abc', 'c')",
        "spark": "ENDSWITH('abc', 'c')"
      },
      "write": {
        "bigquery": "ENDS_WITH('abc', 'c')",
        "clickhouse": "endsWith('abc', 'c')",
        "databricks": "ENDSWITH('abc', 'c')",
        "duckdb": "ENDS_WITH('abc', 'c')",
        "presto": "ENDS_WITH('abc', 'c')",
        "snowflake": "ENDSWITH('abc', 'c')",
        "spark": "ENDSWITH('abc', 'c')"
      }
    },
    {
      "sql": "REGEXP_SUBSTR(subject, pattern, pos, occ, params, group)",
      "read": {},
      "write": {
        "bigquery": "REGEXP_EXTRACT(subject, pattern, pos, occ)",
        "hive": "REGEXP_EXTRACT(subject, pattern, group)",
        "presto": "REGEXP_EXTRACT(subject, pattern, \"group\")",
        "snowflake": "REGEXP_SUBSTR(subject, pattern, pos, occ, params, group)",
        "spark": "REGEXP_EXTRACT(subject, pattern, group)"
      }
    },
    {
      "sql": "REGEXP_SUBSTR(subject, pattern)",
      "read": {
        "bigquery": "REGEXP_EXTRACT(subject, pattern)"
      },
      "write": {
        "bigquery": "REGEXP_EXTRACT(subject, pattern)",
        "snowflake": "REGEXP_SUBSTR(subject, pattern)"
      }
    },
    {
      "sql": "REGEXP_SUBSTR(subject, pattern, 1, 1, 'c', 1)",
      "read": {
        "hive": "REGEXP_EXTRACT(subject, pattern)",
        "spark2": "REGEXP_EXTRACT(subject, pattern)",
        "spark": "REGEXP_EXTRACT(subject, pattern)",
        "databricks": "REGEXP_EXTRACT(subject, pattern)"
      },
      "write": {
        "hive": "REGEXP_EXTRACT(subject, pattern)",
        "spark2": "REGEXP_EXTRACT(subject, pattern)",
        "spark": "REGEXP_EXTRACT(subject, pattern)",
        "databricks": "REGEXP_EXTRACT(subject, pattern)",
        "snowflake": "REGEXP_SUBSTR(subject, pattern, 1, 1, 'c', 1)"
      }
    },
    {
      "sql": "REGEXP_SUBSTR(subject, pattern, 1, 1, 'c', group)",
      "read": {
        "duckdb": "REGEXP_EXTRACT(subject, pattern, group)",
        "hive": "REGEXP_EXTRACT(subject, pattern, group)",
        "presto": "REGEXP_EXTRACT(subject, pattern, group)",
        "snowflake": "REGEXP_SUBSTR(subject, pattern, 1, 1, 'c', group)",
        "spark": "REGEXP_EXTRACT(subject, pattern, group)"
      },
      "write": {}
    },
    {
      "sql": "REGEXP_REPLACE(subject, pattern)",
      "read": {},
      "write": {
        "bigquery": "REGEXP_REPLACE(subject, pattern, '')",
        "duckdb": "REGEXP_REPLACE(subject, pattern, '', 'g')",
        "hive": "REGEXP_REPLACE(subject, pattern, '')",
        "snowflake": "REGEXP_REPLACE(subject, pattern, '')",
        "spark": "REGEXP_REPLACE(subject, pattern, '')"
      }
    },
    {
      "sql": "REGEXP_REPLACE(subject, pattern, replacement)",
      "read": {
        "bigquery": "REGEXP_REPLACE(subject, pattern, replacement)",
        "duckdb": "REGEXP_REPLACE(subject, pattern, replacement)",
        "hive": "REGEXP_REPLACE(subject, pattern, replacement)",
        "spark": "REGEXP_REPLACE(subject, pattern, replacement)"
      },
      "write": {
        "bigquery": "REGEXP_REPLACE(subject, pattern, replacement)",
        "duckdb": "REGEXP_REPLACE(subject, pattern, replacement, 'g')",
        "postgres": "REGEXP_REPLACE(subject, pattern, replacement, 'g')",
        "hive": "REGEXP_REPLACE(subject, pattern, replacement)",
        "snowflake": "REGEXP_REPLACE(subject, pattern, replacement)",
        "spark": "REGEXP_REPLACE(subject, pattern, replacement)"
      }
    },
    {
      "sql": "REGEXP_REPLACE(subject, pattern, replacement, position)",
      "read": {
        "spark": "REGEXP_REPLACE(subject, pattern, replacement, position)"
      },
      "write": {
        "bigquery": "REGEXP_REPLACE(subject, pattern, replacement)",
        "duckdb": "REGEXP_REPLACE(subject, pattern, replacement, 'g')",
        "postgres": "REGEXP_REPLACE(subject, pattern, replacement, position, 'g')",
        "hive": "REGEXP_REPLACE(subject, pattern, replacement)",
        "snowflake": "REGEXP_REPLACE(subject, pattern, replacement, position)",
        "spark": "REGEXP_REPLACE(subject, pattern, replacement, position)"
      }
    },
    {
      "sql": "REGEXP_REPLACE(subject, pattern, replacement, position, occurrence, 'c')",
      "read": {},
      "write": {
        "bigquery": "REGEXP_REPLACE(subject, pattern, replacement)",
        "duckdb": "REGEXP_REPLACE(subject, pattern, replacement, 'c')",
        "postgres": "REGEXP_REPLACE(subject, pattern, replacement, position, occurrence, 'c')",
        "hive": "REGEXP_REPLACE(subject, pattern, replacement)",
        "snowflake": "REGEXP_REPLACE(subject, pattern, replacement, position, occurrence, 'c')",
        "spark": "REGEXP_REPLACE(subject, pattern, replacement, position)"
      }
    },
    {
      "sql": "REGEXP_REPLACE(subject, pattern, replacement, 1, 0, 'c')",
      "read": {},
      "write": {
        "snowflake": "REGEXP_REPLACE(subject, pattern, replacement, 1, 0, 'c')",
        "duckdb": "REGEXP_REPLACE(subject, pattern, replacement, 'cg')",
        "postgres": "REGEXP_REPLACE(subject, pattern, replacement, 1, 0, 'cg')"
      }
    },
    {
      "sql": "REPLACE(subject, pattern)",
      "read": {},
      "write": {
        "bigquery": "REPLACE(subject, pattern, '')",
        "duckdb": "REPLACE(subject, pattern, '')",
        "hive": "REPLACE(subject, pattern, '')",
        "snowflake": "REPLACE(subject, pattern, '')",
        "spark": "REPLACE(subject, pattern, '')"
      }
    },
    {
      "sql": "REPLACE(subject, pattern, replacement)",
      "read": {
        "bigquery": "REPLACE(subject, pattern, replacement)",
        "duckdb": "REPLACE(subject, pattern, replacement)",
        "hive": "REPLACE(subject, pattern, replacement)",
        "spark": "REPLACE(subject, pattern, replacement)"
      },
      "write": {
        "bigquery": "REPLACE(subject, pattern, replacement)",
        "duckdb": "REPLACE(subject, pattern, replacement)",
        "hive": "REPLACE(subject, pattern, replacement)",
        "snowflake": "REPLACE(subject, pattern, replacement)",
        "spark": "REPLACE(subject, pattern, replacement)"
      }
    },
    {
      "sql": "TRY_CAST('foo' AS VARCHAR)",
      "read": {
        "hive": "CAST('foo' AS STRING)"
      },
      "write": {}
    },
    {
      "sql": "CAST(5 + 5 AS VARCHAR)",
      "read": {
        "hive": "CAST(5 + 5 AS STRING)"
      },
      "write": {}
    },
    {
      "sql": "CAST(TRY_CAST('2020-01-01' AS DATE) AS VARCHAR)",
      "read": {
        "hive": "CAST(CAST('2020-01-01' AS DATE) AS STRING)",
        "snowflake": "CAST(TRY_CAST('2020-01-01' AS DATE) AS VARCHAR)"
      },
      "write": {}
    },
    {
      "sql": "TRY_CAST('val' AS VARCHAR)",
      "read": {
        "hive": "CAST('val' AS STRING)",
        "snowflake": "TRY_CAST('val' AS VARCHAR)"
      },
      "write": {}
    },
    {
      "sql": "SELECT CAST(1.5 AS DECFLOAT)",
      "read": {},
      "write": {
        "snowflake": "SELECT CAST(1.5 AS DECFLOAT)",
        "duckdb": "SELECT CAST(1.5 AS DECIMAL(38, 5))"
      }
    },
    {
      "sql": "CREATE TABLE t (x DECFLOAT)",
      "read": {},
      "write": {
        "snowflake": "CREATE TABLE t (x DECFLOAT)",
        "duckdb": "CREATE TABLE t (x DECIMAL(38, 5))"
      }
    },
    {
      "sql": "COPY INTO 's3://example/data.csv'\n    FROM EXTRA.EXAMPLE.TABLE\n    CREDENTIALS = ()\n    FILE_FORMAT = (TYPE = CSV COMPRESSION = NONE NULL_IF = ('') FIELD_OPTIONALLY_ENCLOSED_BY = '\"')\n    HEADER = TRUE\n    OVERWRITE = TRUE\n    SINGLE = TRUE\n            ",
      "read": {},
      "write": {
        "snowflake": "COPY INTO 's3://example/data.csv'\nFROM EXTRA.EXAMPLE.TABLE\nCREDENTIALS = ()\nFILE_FORMAT = (TYPE=CSV COMPRESSION=NONE NULL_IF=(\n  ''\n) FIELD_OPTIONALLY_ENCLOSED_BY='\"')\nHEADER = TRUE\nOVERWRITE = TRUE\nSINGLE = TRUE"
      }
    },
    {
      "sql": "COPY INTO 's3://example/data.csv'\n    FROM EXTRA.EXAMPLE.TABLE\n    STORAGE_INTEGRATION = S3_INTEGRATION\n    FILE_FORMAT = (TYPE=CSV COMPRESSION=NONE NULL_IF=('') FIELD_OPTIONALLY_ENCLOSED_BY='\"')\n    HEADER = TRUE\n    OVERWRITE = TRUE\n    SINGLE = TRUE\n            ",
      "read": {},
      "write": {
        "snowflake": "COPY INTO 's3://example/data.csv' FROM EXTRA.EXAMPLE.TABLE STORAGE_INTEGRATION = S3_INTEGRATION FILE_FORMAT = (TYPE=CSV COMPRESSION=NONE NULL_IF=('') FIELD_OPTIONALLY_ENCLOSED_BY='\"') HEADER = TRUE OVERWRITE = TRUE SINGLE = TRUE"
      }
    },
    {
      "sql": "\n            SELECT col:\"customer's department\"\n            ",
      "read": {},
      "write": {
        "snowflake": "SELECT GET_PATH(col, '[\"customer\\'s department\"]')",
        "postgres": "SELECT JSON_EXTRACT_PATH(col, 'customer''s department')"
      }
    },
    {
      "sql": "SELECT 1 ORDER BY 1 LIMIT NULL OFFSET 0",
      "read": {
        "trino": "SELECT 1 ORDER BY 1 OFFSET 0"
      },
      "write": {}
    },
    {
      "sql": "SELECT MAX_BY(a, b) FROM t",
      "read": {},
      "write": {
        "snowflake": "SELECT MAX_BY(a, b) FROM t",
        "duckdb": "SELECT ARG_MAX(a, b) FROM t"
      }
    },
    {
      "sql": "SELECT MIN_BY(a, b) FROM t",
      "read": {},
      "write": {
        "snowflake": "SELECT MIN_BY(a, b) FROM t",
        "duckdb": "SELECT ARG_MIN(a, b) FROM t"
      }
    },
    {
      "sql": "SELECT GET([4, 5, 6], 1)",
      "read": {},
      "write": {
        "snowflake": "SELECT GET([4, 5, 6], 1)",
        "duckdb": "SELECT [4, 5, 6][2]"
      }
    },
    {
      "sql": "SELECT GET(col::MAP(INTEGER, VARCHAR), 1)",
      "read": {},
      "write": {
        "snowflake": "SELECT GET(CAST(col AS MAP(INT, VARCHAR)), 1)",
        "duckdb": "SELECT CAST(col AS MAP(INT, TEXT))[1]"
      }
    },
    {
      "sql": "SELECT GET(v, 'field')",
      "read": {},
      "write": {
        "snowflake": "SELECT GET(v, 'field')",
        "duckdb": "SELECT v -> '$.field'"
      }
    },
    {
      "sql": "CREATE SEQUENCE seq WITH START=1 INCREMENT=1",
      "read": {},
      "write": {
        "snowflake": "CREATE SEQUENCE seq START WITH 1 INCREMENT BY 1",
        "duckdb": "CREATE SEQUENCE seq START WITH 1 INCREMENT BY 1"
      }
    },
    {
      "sql": "SELECT ROUND(2.25) AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25) AS value",
        "duckdb": "SELECT ROUND(2.25) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(2.25, 1) AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25, 1) AS value",
        "duckdb": "SELECT ROUND(2.25, 1) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(EXPR => 2.25, SCALE => 1) AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25, 1) AS value",
        "duckdb": "SELECT ROUND(2.25, 1) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(SCALE => 1, EXPR => 2.25) AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25, 1) AS value",
        "duckdb": "SELECT ROUND(2.25, 1) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(2.25, 1, 'HALF_AWAY_FROM_ZERO') AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25, 1, 'HALF_AWAY_FROM_ZERO') AS value",
        "duckdb": "SELECT ROUND(2.25, 1) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(EXPR => 2.25, SCALE => 1, ROUNDING_MODE => 'HALF_AWAY_FROM_ZERO') AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25, 1, 'HALF_AWAY_FROM_ZERO') AS value",
        "duckdb": "SELECT ROUND(2.25, 1) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(2.25, 1, 'HALF_TO_EVEN') AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25, 1, 'HALF_TO_EVEN') AS value",
        "duckdb": "SELECT ROUND_EVEN(2.25, 1) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(ROUNDING_MODE => 'HALF_TO_EVEN', EXPR => 2.25, SCALE => 1) AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25, 1, 'HALF_TO_EVEN') AS value",
        "duckdb": "SELECT ROUND_EVEN(2.25, 1) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(SCALE => 1, EXPR => 2.25, , ROUNDING_MODE => 'HALF_TO_EVEN') AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25, 1, 'HALF_TO_EVEN') AS value",
        "duckdb": "SELECT ROUND_EVEN(2.25, 1) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(EXPR => 2.25, SCALE => 1, ROUNDING_MODE => 'HALF_TO_EVEN') AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.25, 1, 'HALF_TO_EVEN') AS value",
        "duckdb": "SELECT ROUND_EVEN(2.25, 1) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(2.256, 1.8) AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.256, 1.8) AS value",
        "duckdb": "SELECT ROUND(2.256, CAST(1.8 AS INT)) AS value"
      }
    },
    {
      "sql": "SELECT ROUND(2.256, CAST(1.8 AS DECIMAL(38, 0))) AS value",
      "read": {},
      "write": {
        "snowflake": "SELECT ROUND(2.256, CAST(1.8 AS DECIMAL(38, 0))) AS value",
        "duckdb": "SELECT ROUND(2.256, CAST(CAST(1.8 AS DECIMAL(38, 0)) AS INT)) AS value"
      }
    },
    {
      "sql": "SELECT GETBIT(11, 1)",
      "read": {},
      "write": {
        "snowflake": "SELECT GETBIT(11, 1)",
        "databricks": "SELECT GETBIT(11, 1)",
        "redshift": "SELECT GETBIT(11, 1)"
      }
    },
    {
      "sql": "SELECT FLOOR(1.753, 2)",
      "read": {},
      "write": {
        "duckdb": "SELECT ROUND(FLOOR(1.753 * POWER(10, 2)) / POWER(10, 2), 2)"
      }
    },
    {
      "sql": "SELECT FLOOR(123.45, -1)",
      "read": {},
      "write": {
        "duckdb": "SELECT ROUND(FLOOR(123.45 * POWER(10, -1)) / POWER(10, -1), -1)"
      }
    },
    {
      "sql": "SELECT FLOOR(a + b, 2)",
      "read": {},
      "write": {
        "duckdb": "SELECT ROUND(FLOOR((a + b) * POWER(10, 2)) / POWER(10, 2), 2)"
      }
    },
    {
      "sql": "SELECT FLOOR(1.234, 1.5)",
      "read": {},
      "write": {
        "duckdb": "SELECT ROUND(FLOOR(1.234 * POWER(10, CAST(1.5 AS INT))) / POWER(10, CAST(1.5 AS INT)), CAST(1.5 AS INT))"
      }
    },
    {
      "sql": "SELECT SEQ1() FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 256 FROM test",
        "snowflake": "SELECT SEQ1() FROM test"
      }
    },
    {
      "sql": "SELECT SEQ1(0) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 256 FROM test",
        "snowflake": "SELECT SEQ1(0) FROM test"
      }
    },
    {
      "sql": "SELECT SEQ1(1) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (CASE WHEN (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 256 >= 128 THEN (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 256 - 256 ELSE (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 256 END) FROM test",
        "snowflake": "SELECT SEQ1(1) FROM test"
      }
    },
    {
      "sql": "SELECT SEQ2() FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 65536 FROM test",
        "snowflake": "SELECT SEQ2() FROM test"
      }
    },
    {
      "sql": "SELECT SEQ2(0) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 65536 FROM test",
        "snowflake": "SELECT SEQ2(0) FROM test"
      }
    },
    {
      "sql": "SELECT SEQ2(1) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (CASE WHEN (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 65536 >= 32768 THEN (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 65536 - 65536 ELSE (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 65536 END) FROM test",
        "snowflake": "SELECT SEQ2(1) FROM test"
      }
    },
    {
      "sql": "SELECT SEQ4() FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 4294967296 FROM test",
        "snowflake": "SELECT SEQ4() FROM test"
      }
    },
    {
      "sql": "SELECT SEQ4(0) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 4294967296 FROM test",
        "snowflake": "SELECT SEQ4(0) FROM test"
      }
    },
    {
      "sql": "SELECT SEQ4(1) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (CASE WHEN (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 4294967296 >= 2147483648 THEN (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 4294967296 - 4294967296 ELSE (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 4294967296 END) FROM test",
        "snowflake": "SELECT SEQ4(1) FROM test"
      }
    },
    {
      "sql": "SELECT SEQ8() FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 18446744073709551616 FROM test",
        "snowflake": "SELECT SEQ8() FROM test"
      }
    },
    {
      "sql": "SELECT SEQ8(0) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 18446744073709551616 FROM test",
        "snowflake": "SELECT SEQ8(0) FROM test"
      }
    },
    {
      "sql": "SELECT SEQ8(1) FROM test",
      "read": {},
      "write": {
        "duckdb": "SELECT (CASE WHEN (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 18446744073709551616 >= 9223372036854775808 THEN (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 18446744073709551616 - 18446744073709551616 ELSE (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 18446744073709551616 END) FROM test",
        "snowflake": "SELECT SEQ8(1) FROM test"
      }
    },
    {
      "sql": "SELECT 1 FROM TABLE(GENERATOR(ROWCOUNT => 5))",
      "read": {},
      "write": {
        "duckdb": "SELECT 1 FROM RANGE(5)",
        "snowflake": "SELECT 1 FROM TABLE(GENERATOR(ROWCOUNT => 5))"
      }
    },
    {
      "sql": "SELECT SEQ8() FROM TABLE(GENERATOR(ROWCOUNT => 5))",
      "read": {},
      "write": {
        "duckdb": "SELECT (ROW_NUMBER() OVER (ORDER BY 1 NULLS FIRST) - 1) % 18446744073709551616 FROM RANGE(5)",
        "snowflake": "SELECT SEQ8() FROM TABLE(GENERATOR(ROWCOUNT => 5))"
      }
    },
    {
      "sql": "SELECT * FROM (TABLE(GENERATOR(ROWCOUNT => 5)) JOIN other ON 1 = 1)",
      "read": {},
      "write": {
        "duckdb": "SELECT * FROM (RANGE(5) JOIN other ON 1 = 1)",
        "snowflake": "SELECT * FROM (TABLE(GENERATOR(ROWCOUNT => 5)) JOIN other ON 1 = 1)"
      }
    },
    {
      "sql": "SELECT CEIL(1.753, 2)",
      "read": {},
      "write": {
        "duckdb": "SELECT ROUND(CEIL(1.753 * POWER(10, 2)) / POWER(10, 2), 2)"
      }
    },
    {
      "sql": "SELECT CEIL(123.45, -1)",
      "read": {},
      "write": {
        "duckdb": "SELECT ROUND(CEIL(123.45 * POWER(10, -1)) / POWER(10, -1), -1)"
      }
    },
    {
      "sql": "SELECT CEIL(a + b, 2)",
      "read": {},
      "write": {
        "duckdb": "SELECT ROUND(CEIL((a + b) * POWER(10, 2)) / POWER(10, 2), 2)"
      }
    },
    {
      "sql": "SELECT CEIL(1.234, 1.5)",
      "read": {},
      "write": {
        "duckdb": "SELECT ROUND(CEIL(1.234 * POWER(10, CAST(1.5 AS INT))) / POWER(10, CAST(1.5 AS INT)), CAST(1.5 AS INT))"
      }
    },
    {
      "sql": "SELECT CORR(a, b)",
      "read": {
        "snowflake": "SELECT CORR(a, b)",
        "postgres": "SELECT CORR(a, b)"
      },
      "write": {
        "snowflake": "SELECT CORR(a, b)",
        "postgres": "SELECT CORR(a, b)",
        "duckdb": "SELECT CASE WHEN ISNAN(CORR(a, b)) THEN NULL ELSE CORR(a, b) END"
      }
    },
    {
      "sql": "SELECT CORR(a, b) OVER (PARTITION BY c)",
      "read": {
        "snowflake": "SELECT CORR(a, b) OVER (PARTITION BY c)",
        "postgres": "SELECT CORR(a, b) OVER (PARTITION BY c)"
      },
      "write": {
        "snowflake": "SELECT CORR(a, b) OVER (PARTITION BY c)",
        "postgres": "SELECT CORR(a, b) OVER (PARTITION BY c)",
        "duckdb": "SELECT CASE WHEN ISNAN(CORR(a, b) OVER (PARTITION BY c)) THEN NULL ELSE CORR(a, b) OVER (PARTITION BY c) END"
      }
    },
    {
      "sql": "SELECT CORR(a, b) FILTER(WHERE c > 0)",
      "read": {},
      "write": {
        "duckdb": "SELECT CASE WHEN ISNAN(CORR(a, b) FILTER(WHERE c > 0)) THEN NULL ELSE CORR(a, b) FILTER(WHERE c > 0) END"
      }
    },
    {
      "sql": "SELECT CORR(a, b) FILTER(WHERE c > 0) OVER (PARTITION BY d)",
      "read": {},
      "write": {
        "duckdb": "SELECT CASE WHEN ISNAN(CORR(a, b) FILTER(WHERE c > 0) OVER (PARTITION BY d)) THEN NULL ELSE CORR(a, b) FILTER(WHERE c > 0) OVER (PARTITION BY d) END"
      }
    }
  ]
}